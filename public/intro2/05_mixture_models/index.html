<!DOCTYPE html>
<html lang="en-us" dir="ltr" itemscope itemtype="http://schema.org/Article" data-r-output-format="html">
  <head><script src="/probintro/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=probintro/livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta name="viewport" content="height=device-height, width=device-width, initial-scale=1.0, minimum-scale=1.0">
    <meta name="generator" content="Hugo 0.148.2">
    <meta name="generator" content="Relearn 8.0.0+9803d5122ebb3276acea823f476e9eb44f607862">
    <meta name="description" content="Returning to the Mystery Remember Chibany‚Äôs original puzzle from Chapter 1? He had mystery bentos with two peaks in their weight distribution, but the average fell in a valley where no individual bento existed.
We now have all the tools to solve this completely:
Chapter 1: Expected value paradox in mixtures Chapter 2: Continuous probability (PDFs, CDFs) Chapter 3: Gaussian distributions Chapter 4: Bayesian learning for parameters Now we combine them: What if we have multiple Gaussian distributions mixed together, and we need to figure out both which component each observation belongs to AND the parameters of each component?">
    <meta name="author" content="Joseph Austerweil">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Gaussian Mixture Models :: Probability & Probabilistic Computing Tutorial">
    <meta name="twitter:description" content="Returning to the Mystery Remember Chibany‚Äôs original puzzle from Chapter 1? He had mystery bentos with two peaks in their weight distribution, but the average fell in a valley where no individual bento existed.
We now have all the tools to solve this completely:
Chapter 1: Expected value paradox in mixtures Chapter 2: Continuous probability (PDFs, CDFs) Chapter 3: Gaussian distributions Chapter 4: Bayesian learning for parameters Now we combine them: What if we have multiple Gaussian distributions mixed together, and we need to figure out both which component each observation belongs to AND the parameters of each component?">
    <meta property="og:url" content="http://localhost:1313/probintro/intro2/05_mixture_models/index.html">
    <meta property="og:site_name" content="Probability & Probabilistic Computing Tutorial">
    <meta property="og:title" content="Gaussian Mixture Models :: Probability & Probabilistic Computing Tutorial">
    <meta property="og:description" content="Returning to the Mystery Remember Chibany‚Äôs original puzzle from Chapter 1? He had mystery bentos with two peaks in their weight distribution, but the average fell in a valley where no individual bento existed.
We now have all the tools to solve this completely:
Chapter 1: Expected value paradox in mixtures Chapter 2: Continuous probability (PDFs, CDFs) Chapter 3: Gaussian distributions Chapter 4: Bayesian learning for parameters Now we combine them: What if we have multiple Gaussian distributions mixed together, and we need to figure out both which component each observation belongs to AND the parameters of each component?">
    <meta property="og:locale" content="en_us">
    <meta property="og:type" content="article">
    <meta property="article:section" content="Continuous Probability and Bayesian Learning">
    <meta itemprop="name" content="Gaussian Mixture Models :: Probability & Probabilistic Computing Tutorial">
    <meta itemprop="description" content="Returning to the Mystery Remember Chibany‚Äôs original puzzle from Chapter 1? He had mystery bentos with two peaks in their weight distribution, but the average fell in a valley where no individual bento existed.
We now have all the tools to solve this completely:
Chapter 1: Expected value paradox in mixtures Chapter 2: Continuous probability (PDFs, CDFs) Chapter 3: Gaussian distributions Chapter 4: Bayesian learning for parameters Now we combine them: What if we have multiple Gaussian distributions mixed together, and we need to figure out both which component each observation belongs to AND the parameters of each component?">
    <meta itemprop="wordCount" content="2803">
    <title>Gaussian Mixture Models :: Probability &amp; Probabilistic Computing Tutorial</title>
    <link href="/probintro/images/favicon.png?1762936916" rel="icon" type="image/png">
    <link href="/probintro/css/auto-complete/auto-complete.min.css?1762936916" rel="stylesheet">
    <script src="/probintro/js/auto-complete/auto-complete.min.js?1762936916" defer></script>
    <script src="/probintro/js/search-lunr.js?1762936916" defer></script>
    <script src="/probintro/js/search.js?1762936916" defer></script>
    <script>
      window.relearn = window.relearn || {};
      window.relearn.index_js_url="/probintro/searchindex.en.js?1762936916";
    </script>
    <script src="/probintro/js/lunr/lunr.min.js?1762936916" defer></script>
    <script src="/probintro/js/lunr/lunr.stemmer.support.min.js?1762936916" defer></script>
    <script src="/probintro/js/lunr/lunr.multi.min.js?1762936916" defer></script>
    <script src="/probintro/js/lunr/lunr.en.min.js?1762936916" defer></script>
    <script>
      window.relearn = window.relearn || {};
      window.relearn.contentLangs=['en'];
    </script>
    <link href="/probintro/fonts/fontawesome/css/fontawesome-all.min.css?1762936916" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/probintro/fonts/fontawesome/css/fontawesome-all.min.css?1762936916" rel="stylesheet"></noscript>
    <link href="/probintro/css/perfect-scrollbar/perfect-scrollbar.min.css?1762936916" rel="stylesheet">
    <link href="/probintro/css/theme.css?1762936916" rel="stylesheet">
    <link href="/probintro/css/format-html.css?1762936916" rel="stylesheet" id="R-format-style">
    <script>
      window.relearn = window.relearn || {};
      // configuration
      window.relearn.min = ``;
      window.relearn.path='\/intro2\/05_mixture_models\/index.html';
      window.relearn.relBasePath='..\/..';
      window.relearn.relBaseUri='..\/..\/..';
      window.relearn.absBaseUri='http:\/\/localhost:1313\/probintro';
      window.relearn.disableAnchorCopy=false;
      window.relearn.disableAnchorScrolling=false;
      window.relearn.disableInlineCopyToClipboard=false;
      window.relearn.enableBlockCodeWrap=true;
      // legal
      window.relearn.getItem = (s,n) => {return s.getItem(n)};
      window.relearn.setItem = (s,n,v) => {return s.setItem(n,v)};
      window.relearn.removeItem = (s,n) => {return s.removeItem(n)};
      // translations
      window.T_Copy_to_clipboard = `Copy to clipboard`;
      window.T_Copied_to_clipboard = `Copied to clipboard!`;
      window.T_Copy_link_to_clipboard = `Copy link to clipboard`;
      window.T_Link_copied_to_clipboard = `Copied link to clipboard!`;
      window.T_Reset_view = `Reset view`;
      window.T_View_reset = `View reset!`;
      window.T_No_results_found = `No results found for "{0}"`;
      window.T_N_results_found = `{1} results found for "{0}"`;
      // variant stuff
      window.relearn.themevariants = [ 'auto' ];
      window.relearn.customvariantname = "my-custom-variant";
      window.relearn.changeVariant = function(variant) {
        var oldVariant = document.documentElement.dataset.rThemeVariant;
        window.relearn.setItem(window.localStorage, window.relearn.absBaseUri + "/variant", variant);
        document.documentElement.dataset.rThemeVariant = variant;
        if (oldVariant != variant) {
          document.dispatchEvent( new CustomEvent('themeVariantLoaded', { detail: { variant, oldVariant } }) );
          window.relearn.markVariant();
        }
      }
      window.relearn.markVariant = function() {
        var variant = window.relearn.getItem(window.localStorage, window.relearn.absBaseUri + "/variant");
        document.querySelectorAll(".R-variantswitcher select").forEach((select) => {select.value = variant;});
      }
      window.relearn.initVariant = function() {
        var variant = window.relearn.getItem(window.localStorage, window.relearn.absBaseUri + "/variant") ?? "";
        if( variant == window.relearn.customvariantname ){
        }else if( !variant || !window.relearn.themevariants.includes(variant) ){
          variant = window.relearn.themevariants[0];
          window.relearn.setItem(window.localStorage, window.relearn.absBaseUri + "/variant", variant);
        }
        document.documentElement.dataset.rThemeVariant = variant;
      }
      window.relearn.initVariant();
      window.relearn.markVariant();
    </script>
  </head>
  <body class="mobile-support html" data-url="/probintro/intro2/05_mixture_models/index.html">
    <div id="R-body" class="default-animation">
      <div id="R-body-overlay"></div>
      <nav id="R-topbar">
        <div class="topbar-wrapper">
          <div class="topbar-sidebar-divider"></div>
          <div class="topbar-area topbar-area-start" data-area="start">
            <div class="topbar-button topbar-button-sidebar" data-content-empty="disable" data-width-s="show" data-width-m="hide" data-width-l="hide"><button class="topbar-control" onclick="toggleNav()" type="button" title="Menu (CTRL&#43;ALT&#43;n)"><i class="fa-fw fas fa-bars"></i></button>
            </div>
            <div class="topbar-button topbar-button-toc" data-content-empty="hide" data-width-s="show" data-width-m="show" data-width-l="show"><button class="topbar-control" onclick="toggleTopbarFlyout(this)" type="button" title="Table of Contents (CTRL&#43;ALT&#43;t)"><i class="fa-fw fas fa-list-alt"></i></button>
              <div class="topbar-content">
                <div class="topbar-content-wrapper">
<nav class="TableOfContents">
  <ul>
    <li><a href="#returning-to-the-mystery">Returning to the Mystery</a></li>
    <li><a href="#the-complete-problem">The Complete Problem</a></li>
    <li><a href="#gaussian-mixture-model-the-math">Gaussian Mixture Model: The Math</a>
      <ul>
        <li><a href="#the-generative-story">The Generative Story</a></li>
      </ul>
    </li>
    <li><a href="#two-component-bento-model">Two-Component Bento Model</a></li>
    <li><a href="#the-inference-problem">The Inference Problem</a></li>
    <li><a href="#solution-1-if-we-know-component-labels">Solution 1: If We Know Component Labels</a></li>
    <li><a href="#solution-2-em-algorithm-conceptual-overview">Solution 2: EM Algorithm (Conceptual Overview)</a>
      <ul>
        <li><a href="#soft-assignments-responsibilities">Soft Assignments (Responsibilities)</a></li>
        <li><a href="#parameter-updates">Parameter Updates</a></li>
      </ul>
    </li>
    <li><a href="#implementing-em-for-gmm">Implementing EM for GMM</a></li>
    <li><a href="#visualizing-the-mixture">Visualizing the Mixture</a></li>
    <li><a href="#bayesian-gmm-with-genjax">Bayesian GMM with GenJAX</a></li>
    <li><a href="#model-selection-how-many-components">Model Selection: How Many Components?</a>
      <ul>
        <li><a href="#bayesian-information-criterion-bic">Bayesian Information Criterion (BIC)</a></li>
      </ul>
    </li>
    <li><a href="#real-world-applications">Real-World Applications</a>
      <ul>
        <li><a href="#image-segmentation">Image Segmentation</a></li>
        <li><a href="#speaker-identification">Speaker Identification</a></li>
        <li><a href="#anomaly-detection">Anomaly Detection</a></li>
        <li><a href="#customer-segmentation">Customer Segmentation</a></li>
      </ul>
    </li>
    <li><a href="#practice-problems">Practice Problems</a>
      <ul>
        <li><a href="#problem-1-three-coffee-blends">Problem 1: Three Coffee Blends</a></li>
        <li><a href="#problem-2-label-switching">Problem 2: Label Switching</a></li>
      </ul>
    </li>
    <li><a href="#whats-next">What&rsquo;s Next?</a></li>
  </ul>
</nav>
                </div>
              </div>
            </div>
          </div>
          <ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype="http://schema.org/BreadcrumbList"><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><a itemprop="item" href="/probintro/index.html"><span itemprop="name">Probability &amp; Probabilistic Computing Tutorial</span></a><meta itemprop="position" content="1">&nbsp;>&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><a itemprop="item" href="/probintro/intro2/index.html"><span itemprop="name">Continuous Probability and Bayesian Learning</span></a><meta itemprop="position" content="2">&nbsp;>&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><span itemprop="name">Gaussian Mixture Models</span><meta itemprop="position" content="3"></li>
          </ol>
          <div class="topbar-area topbar-area-end" data-area="end">
            <div class="topbar-button topbar-button-prev" data-content-empty="disable" data-width-s="show" data-width-m="show" data-width-l="show"><a class="topbar-control" href="/probintro/intro2/04_bayesian_learning/index.html" title="Bayesian Learning with Gaussians (ü°ê)"><i class="fa-fw fas fa-chevron-left"></i></a>
            </div>
            <div class="topbar-button topbar-button-next" data-content-empty="disable" data-width-s="show" data-width-m="show" data-width-l="show"><a class="topbar-control" href="/probintro/intro2/06_dpmm/index.html" title="Dirichlet Process Mixture Models (ü°í)"><i class="fa-fw fas fa-chevron-right"></i></a>
            </div>
            <div class="topbar-button topbar-button-more" data-content-empty="hide" data-width-s="show" data-width-m="show" data-width-l="show"><button class="topbar-control" onclick="toggleTopbarFlyout(this)" type="button" title="More"><i class="fa-fw fas fa-ellipsis-v"></i></button>
              <div class="topbar-content">
                <div class="topbar-content-wrapper">
                  <div class="topbar-area topbar-area-more" data-area="more">
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </nav>
      <div id="R-main-overlay"></div>
      <main id="R-body-inner" class="highlightable intro2" tabindex="-1">
        <div class="flex-block-wrapper">
<article class="default">
  <header class="headline">
  </header>

<h1 id="gaussian-mixture-models">Gaussian Mixture Models</h1>

<h2 id="returning-to-the-mystery">Returning to the Mystery</h2>
<p>Remember Chibany&rsquo;s original puzzle from Chapter 1? He had mystery bentos with two peaks in their weight distribution, but the average fell in a valley where no individual bento existed.</p>
<p>We now have all the tools to solve this completely:</p>
<ul>
<li><strong>Chapter 1</strong>: Expected value paradox in mixtures</li>
<li><strong>Chapter 2</strong>: Continuous probability (PDFs, CDFs)</li>
<li><strong>Chapter 3</strong>: Gaussian distributions</li>
<li><strong>Chapter 4</strong>: Bayesian learning for parameters</li>
</ul>
<p>Now we combine them: <strong>What if we have multiple Gaussian distributions mixed together, and we need to figure out both which component each observation belongs to AND the parameters of each component?</strong></p>
<p>This is a <strong>Gaussian Mixture Model (GMM)</strong>.</p>
<hr>
<h2 id="the-complete-problem">The Complete Problem</h2>
<p>Chibany receives 20 mystery bentos. He measures their weights:</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>[498, 352, 501, 349, 497, 503, 351, 500, 348, 502,
 499, 350, 498, 353, 501, 347, 499, 502, 352, 500]</code></pre></div>
<p>Looking at the histogram, he sees two clear clusters around 350g and 500g.</p>
<p><strong>The questions</strong>:</p>
<ol>
<li><strong>How many types</strong> of bentos are there? (We&rsquo;ll assume 2 for now)</li>
<li><strong>Which type</strong> is each bento? (Classification problem)</li>
<li><strong>What are the parameters</strong> for each type? (Learning problem)</li>
</ol>
<hr>
<h2 id="gaussian-mixture-model-the-math">Gaussian Mixture Model: The Math</h2>
<p>A GMM says each observation comes from one of K Gaussian components:</p>
<p>$$p(x) = \sum_{k=1}^{K} \pi_k \cdot \mathcal{N}(x | \mu_k, \sigma_k^2)$$</p>
<p>Where:</p>
<ul>
<li><strong>œÄ_k</strong>: Mixing proportion (probability of component k)</li>
<li><strong>Œº_k</strong>: Mean of component k</li>
<li><strong>œÉ_k¬≤</strong>: Variance of component k</li>
</ul>
<p>Constraint: $\sum_{k=1}^{K} \pi_k = 1$ (probabilities must sum to 1)</p>
<h3 id="the-generative-story">The Generative Story</h3>
<ol>
<li><strong>Choose a component</strong>: Sample k ~ Categorical(œÄ‚ÇÅ, œÄ‚ÇÇ, &hellip;, œÄ‚Çñ)</li>
<li><strong>Generate observation</strong>: Sample x ~ N(Œº‚Çñ, œÉ‚Çñ¬≤)</li>
</ol>
<p>This is exactly what GenJAX is built for!</p>

<details open class=" box cstyle notices info">
  <summary class="box-label" tabindex="-1">
    <i class="fa-fw fas fa-info-circle"></i> 
    üìò Foundation Concept: Discrete + Continuous Together
  </summary>
  <div class="box-content">
<p><strong>Notice the beautiful combination here!</strong></p>
<p><strong>Step 1 is discrete</strong> (like Tutorial 1):</p>
<ul>
<li>Choose which component: k ~ Categorical(œÄ‚ÇÅ, œÄ‚ÇÇ, &hellip;, œÄ‚Çñ)</li>
<li>This is just like choosing between {hamburger, tonkatsu}</li>
<li>We&rsquo;re <strong>counting</strong> discrete outcomes (component 1, component 2, &hellip;)</li>
<li>From Tutorial 1: <strong>Random variables</strong> map outcomes to values</li>
</ul>
<p><strong>Step 2 is continuous</strong> (like Tutorial 3):</p>
<ul>
<li>Generate the actual weight: x ~ N(Œº‚Çñ, œÉ‚Çñ¬≤)</li>
<li>This uses <strong>probability density</strong> we learned in Chapter 2</li>
<li>We&rsquo;re <strong>measuring</strong> continuous values (350g, 500g, &hellip;)</li>
</ul>
<p><strong>Why this matters:</strong></p>
<ul>
<li>Real problems often combine both!</li>
<li>Discrete choices (which category?) + Continuous measurements (what value?)</li>
<li><strong>Tutorial 1&rsquo;s logic</strong> (discrete counting) works alongside <strong>Tutorial 3&rsquo;s tools</strong> (continuous density)</li>
<li>GenJAX handles both seamlessly in the same model</li>
</ul>
<p><strong>The power:</strong> Mixture models show that discrete and continuous probability aren&rsquo;t separate worlds‚Äîthey work together to model rich, real-world phenomena.</p>
<p><a href="/probintro/intro/03_prob_count/index.html#random-variables">‚Üê Review random variables in Tutorial 1, Chapter 3</a></p>
<p><a href="../02_continuous/">‚Üê Review continuous distributions in Tutorial 3, Chapter 2</a></p>
  </div>
</details>
<hr>
<h2 id="two-component-bento-model">Two-Component Bento Model</h2>
<p>For Chibany&rsquo;s bentos with K=2 (tonkatsu and hamburger):</p>
<p><strong>Component 1 (Tonkatsu)</strong>:</p>
<ul>
<li>œÄ‚ÇÅ = 0.7 (70% of bentos)</li>
<li>Œº‚ÇÅ = 500g</li>
<li>œÉ‚ÇÅ¬≤ = 4 (std dev = 2g)</li>
</ul>
<p><strong>Component 2 (Hamburger)</strong>:</p>
<ul>
<li>œÄ‚ÇÇ = 0.3 (30% of bentos)</li>
<li>Œº‚ÇÇ = 350g</li>
<li>œÉ‚ÇÇ¬≤ = 4 (std dev = 2g)</li>
</ul>
<div class="highlight wrap-code" dir="auto"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">37
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">38
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">39
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">40
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">41
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">42
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">43
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">44
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">45
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> jax
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> jax.numpy <span style="color:#66d9ef">as</span> jnp
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> genjax <span style="color:#f92672">import</span> gen, simulate
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> jax.random <span style="color:#66d9ef">as</span> random
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">@gen</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">bento_mixture_model</span>():
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Two-component Gaussian mixture&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Mixing proportions</span>
</span></span><span style="display:flex;"><span>    pi <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>array([<span style="color:#ae81ff">0.7</span>, <span style="color:#ae81ff">0.3</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Choose component (0 = tonkatsu, 1 = hamburger)</span>
</span></span><span style="display:flex;"><span>    component <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>categorical(jnp<span style="color:#f92672">.</span>log(pi)) <span style="color:#f92672">@</span> <span style="color:#e6db74">&#34;component&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Component parameters</span>
</span></span><span style="display:flex;"><span>    means <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>array([<span style="color:#ae81ff">500.0</span>, <span style="color:#ae81ff">350.0</span>])
</span></span><span style="display:flex;"><span>    stds <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>array([<span style="color:#ae81ff">2.0</span>, <span style="color:#ae81ff">2.0</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Generate weight from chosen component</span>
</span></span><span style="display:flex;"><span>    mu <span style="color:#f92672">=</span> means[component]
</span></span><span style="display:flex;"><span>    sigma <span style="color:#f92672">=</span> stds[component]
</span></span><span style="display:flex;"><span>    weight <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>normal(mu, sigma) <span style="color:#f92672">@</span> <span style="color:#e6db74">&#34;weight&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> weight, component
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Simulate 20 bentos</span>
</span></span><span style="display:flex;"><span>key <span style="color:#f92672">=</span> random<span style="color:#f92672">.</span>PRNGKey(<span style="color:#ae81ff">42</span>)
</span></span><span style="display:flex;"><span>weights <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>components <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">20</span>):
</span></span><span style="display:flex;"><span>    key, subkey <span style="color:#f92672">=</span> random<span style="color:#f92672">.</span>split(key)
</span></span><span style="display:flex;"><span>    trace <span style="color:#f92672">=</span> simulate(bento_mixture_model)(subkey)
</span></span><span style="display:flex;"><span>    weight, component <span style="color:#f92672">=</span> trace<span style="color:#f92672">.</span>get_retval()
</span></span><span style="display:flex;"><span>    weights<span style="color:#f92672">.</span>append(weight)
</span></span><span style="display:flex;"><span>    components<span style="color:#f92672">.</span>append(component)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>weights <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>array(weights)
</span></span><span style="display:flex;"><span>components <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>array(components)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>n_tonkatsu <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>sum(components <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>n_hamburger <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>sum(components <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Generated </span><span style="color:#e6db74">{</span>n_tonkatsu<span style="color:#e6db74">}</span><span style="color:#e6db74"> tonkatsu and </span><span style="color:#e6db74">{</span>n_hamburger<span style="color:#e6db74">}</span><span style="color:#e6db74"> hamburger bentos&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Weights: </span><span style="color:#e6db74">{</span>weights<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)</span></span></code></pre></td></tr></table>
</div>
</div>
<p><strong>Output:</strong></p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>Generated 14 tonkatsu and 6 hamburger bentos
Weights: [501.2 349.8 499.5 351.3 498.7 502.1 350.5 ...]</code></pre></div>
<hr>
<h2 id="the-inference-problem">The Inference Problem</h2>
<p><strong>Forward (Generative)</strong>: Given parameters (œÄ, Œº, œÉ¬≤), generate observations ‚úÖ
<strong>Backward (Inference)</strong>: Given observations, infer parameters (œÄ, Œº, œÉ¬≤) and assignments ‚ùì</p>
<p>This is harder! We need to solve:</p>
<ol>
<li><strong>Which component</strong> did each observation come from?</li>
<li><strong>What are the parameters</strong> (Œº‚ÇÅ, Œº‚ÇÇ, œÉ‚ÇÅ¬≤, œÉ‚ÇÇ¬≤)?</li>
<li><strong>What are the mixing proportions</strong> (œÄ‚ÇÅ, œÄ‚ÇÇ)?</li>
</ol>
<p>These problems are interdependent:</p>
<ul>
<li>If we knew the assignments, we could easily estimate parameters (just compute means/variances per component)</li>
<li>If we knew the parameters, we could compute assignment probabilities (which Gaussian is each point closer to?)</li>
</ul>
<p>Classic chicken-and-egg problem!</p>
<hr>
<h2 id="solution-1-if-we-know-component-labels">Solution 1: If We Know Component Labels</h2>
<p>Suppose Chibany could magically see labels on the bentos. Then learning is straightforward:</p>
<div class="highlight wrap-code" dir="auto"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Example: observed weights with known labels</span>
</span></span><span style="display:flex;"><span>weights <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>array([<span style="color:#ae81ff">498</span>, <span style="color:#ae81ff">352</span>, <span style="color:#ae81ff">501</span>, <span style="color:#ae81ff">349</span>, <span style="color:#ae81ff">497</span>, <span style="color:#ae81ff">503</span>, <span style="color:#ae81ff">351</span>, <span style="color:#ae81ff">500</span>, <span style="color:#ae81ff">348</span>, <span style="color:#ae81ff">502</span>,
</span></span><span style="display:flex;"><span>                     <span style="color:#ae81ff">499</span>, <span style="color:#ae81ff">350</span>, <span style="color:#ae81ff">498</span>, <span style="color:#ae81ff">353</span>, <span style="color:#ae81ff">501</span>, <span style="color:#ae81ff">347</span>, <span style="color:#ae81ff">499</span>, <span style="color:#ae81ff">502</span>, <span style="color:#ae81ff">352</span>, <span style="color:#ae81ff">500</span>])
</span></span><span style="display:flex;"><span>labels <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>array([<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>,
</span></span><span style="display:flex;"><span>                    <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>])  <span style="color:#75715e"># 0=tonkatsu, 1=hamburger</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Estimate parameters for each component</span>
</span></span><span style="display:flex;"><span>tonkatsu_weights <span style="color:#f92672">=</span> weights[labels <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>hamburger_weights <span style="color:#f92672">=</span> weights[labels <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>mu1 <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>mean(tonkatsu_weights)
</span></span><span style="display:flex;"><span>sigma1 <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>std(tonkatsu_weights)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>mu2 <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>mean(hamburger_weights)
</span></span><span style="display:flex;"><span>sigma2 <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>std(hamburger_weights)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>pi1 <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>mean(labels <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>pi2 <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>mean(labels <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Tonkatsu: Œº=</span><span style="color:#e6db74">{</span>mu1<span style="color:#e6db74">:</span><span style="color:#e6db74">.1f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">g, œÉ=</span><span style="color:#e6db74">{</span>sigma1<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">g, œÄ=</span><span style="color:#e6db74">{</span>pi1<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Hamburger: Œº=</span><span style="color:#e6db74">{</span>mu2<span style="color:#e6db74">:</span><span style="color:#e6db74">.1f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">g, œÉ=</span><span style="color:#e6db74">{</span>sigma2<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">g, œÄ=</span><span style="color:#e6db74">{</span>pi2<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)</span></span></code></pre></td></tr></table>
</div>
</div>
<p><strong>Output:</strong></p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>Tonkatsu: Œº=499.9g, œÉ=1.95g, œÄ=0.65
Hamburger: Œº=350.4g, œÉ=1.83g, œÄ=0.35</code></pre></div>
<p>Perfect! But we don&rsquo;t have labels&hellip;</p>
<hr>
<h2 id="solution-2-em-algorithm-conceptual-overview">Solution 2: EM Algorithm (Conceptual Overview)</h2>
<p>The <strong>Expectation-Maximization (EM) algorithm</strong> solves the chicken-and-egg problem by iterating:</p>
<p><strong>E-step (Expectation)</strong>: Given current parameters, compute the probability that each observation belongs to each component (soft assignments)</p>
<p><strong>M-step (Maximization)</strong>: Given soft assignments, update the parameters to maximize likelihood</p>
<p>Repeat until convergence.</p>
<h3 id="soft-assignments-responsibilities">Soft Assignments (Responsibilities)</h3>
<p>For each observation x·µ¢ and component k, compute:</p>
<p>$$\gamma_{ik} = \frac{\pi_k \cdot \mathcal{N}(x_i | \mu_k, \sigma_k^2)}{\sum_{j=1}^{K} \pi_j \cdot \mathcal{N}(x_i | \mu_j, \sigma_j^2)}$$</p>
<p>This is the <strong>posterior probability</strong> that observation i belongs to component k.</p>
<p><strong>In plain English</strong>: &ldquo;How likely is it that this bento is tonkatsu vs. hamburger, given its weight and our current parameter estimates?&rdquo;</p>
<h3 id="parameter-updates">Parameter Updates</h3>
<p><strong>Mixing proportions</strong>:
$$\pi_k = \frac{1}{N} \sum_{i=1}^{N} \gamma_{ik}$$</p>
<p><strong>Means</strong>:
$$\mu_k = \frac{\sum_{i=1}^{N} \gamma_{ik} \cdot x_i}{\sum_{i=1}^{N} \gamma_{ik}}$$</p>
<p><strong>Variances</strong>:
$$\sigma_k^2 = \frac{\sum_{i=1}^{N} \gamma_{ik} \cdot (x_i - \mu_k)^2}{\sum_{i=1}^{N} \gamma_{ik}}$$</p>
<p>These are <strong>weighted</strong> versions of the formulas from Solution 1, where the weights are the soft assignments Œ≥·µ¢‚Çñ.</p>
<hr>
<h2 id="implementing-em-for-gmm">Implementing EM for GMM</h2>
<div class="highlight wrap-code" dir="auto"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">37
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">38
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">39
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">40
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">41
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">42
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">43
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">44
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">45
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">46
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">47
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">48
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">49
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">50
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">51
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">52
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">53
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">54
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">55
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">56
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">57
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">58
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">59
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">60
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">61
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">62
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">63
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">64
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">65
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">66
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">67
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">68
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">69
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">70
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">71
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">72
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">73
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">74
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">75
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">76
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">77
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">78
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">79
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> scipy.stats <span style="color:#f92672">import</span> norm <span style="color:#66d9ef">as</span> scipy_norm
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">em_gmm</span>(data, K<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, max_iters<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>, tol<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-6</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    EM algorithm for Gaussian Mixture Model
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Args:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        data: Observations (1D array)
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        K: Number of components
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        max_iters: Maximum iterations
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        tol: Convergence tolerance
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Returns:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        pi, mu, sigma (mixing proportions, means, std devs)
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    N <span style="color:#f92672">=</span> len(data)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Initialize parameters randomly</span>
</span></span><span style="display:flex;"><span>    pi <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>ones(K) <span style="color:#f92672">/</span> K
</span></span><span style="display:flex;"><span>    mu <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>array([jnp<span style="color:#f92672">.</span>min(data), jnp<span style="color:#f92672">.</span>max(data)])  <span style="color:#75715e"># Spread initial means</span>
</span></span><span style="display:flex;"><span>    sigma <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>ones(K) <span style="color:#f92672">*</span> jnp<span style="color:#f92672">.</span>std(data)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    log_likelihood_old <span style="color:#f92672">=</span> <span style="color:#f92672">-</span>jnp<span style="color:#f92672">.</span>inf
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> iteration <span style="color:#f92672">in</span> range(max_iters):
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># E-step: Compute responsibilities</span>
</span></span><span style="display:flex;"><span>        gamma <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>zeros((N, K))
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> k <span style="color:#f92672">in</span> range(K):
</span></span><span style="display:flex;"><span>            gamma <span style="color:#f92672">=</span> gamma<span style="color:#f92672">.</span>at[:, k]<span style="color:#f92672">.</span>set(
</span></span><span style="display:flex;"><span>                pi[k] <span style="color:#f92672">*</span> scipy_norm<span style="color:#f92672">.</span>pdf(data, mu[k], sigma[k])
</span></span><span style="display:flex;"><span>            )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Normalize responsibilities</span>
</span></span><span style="display:flex;"><span>        gamma <span style="color:#f92672">=</span> gamma <span style="color:#f92672">/</span> jnp<span style="color:#f92672">.</span>sum(gamma, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>, keepdims<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># M-step: Update parameters</span>
</span></span><span style="display:flex;"><span>        N_k <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>sum(gamma, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)  <span style="color:#75715e"># Effective number of points in each component</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        pi <span style="color:#f92672">=</span> N_k <span style="color:#f92672">/</span> N
</span></span><span style="display:flex;"><span>        mu <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>sum(gamma <span style="color:#f92672">*</span> data[:, <span style="color:#66d9ef">None</span>], axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>) <span style="color:#f92672">/</span> N_k
</span></span><span style="display:flex;"><span>        sigma <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>sqrt(
</span></span><span style="display:flex;"><span>            jnp<span style="color:#f92672">.</span>sum(gamma <span style="color:#f92672">*</span> (data[:, <span style="color:#66d9ef">None</span>] <span style="color:#f92672">-</span> mu[<span style="color:#66d9ef">None</span>, :]) <span style="color:#f92672">**</span> <span style="color:#ae81ff">2</span>, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>) <span style="color:#f92672">/</span> N_k
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Check convergence</span>
</span></span><span style="display:flex;"><span>        log_likelihood <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>sum(
</span></span><span style="display:flex;"><span>            jnp<span style="color:#f92672">.</span>log(jnp<span style="color:#f92672">.</span>sum(
</span></span><span style="display:flex;"><span>                pi[k] <span style="color:#f92672">*</span> scipy_norm<span style="color:#f92672">.</span>pdf(data, mu[k], sigma[k])
</span></span><span style="display:flex;"><span>                <span style="color:#66d9ef">for</span> k <span style="color:#f92672">in</span> range(K)
</span></span><span style="display:flex;"><span>            ))
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> jnp<span style="color:#f92672">.</span>abs(log_likelihood <span style="color:#f92672">-</span> log_likelihood_old) <span style="color:#f92672">&lt;</span> tol:
</span></span><span style="display:flex;"><span>            print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Converged after </span><span style="color:#e6db74">{</span>iteration <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span><span style="color:#e6db74">}</span><span style="color:#e6db74"> iterations&#34;</span>)
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">break</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        log_likelihood_old <span style="color:#f92672">=</span> log_likelihood
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> pi, mu, sigma, gamma
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Apply to Chibany&#39;s mystery bentos</span>
</span></span><span style="display:flex;"><span>mystery_weights <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>array([<span style="color:#ae81ff">498</span>, <span style="color:#ae81ff">352</span>, <span style="color:#ae81ff">501</span>, <span style="color:#ae81ff">349</span>, <span style="color:#ae81ff">497</span>, <span style="color:#ae81ff">503</span>, <span style="color:#ae81ff">351</span>, <span style="color:#ae81ff">500</span>, <span style="color:#ae81ff">348</span>, <span style="color:#ae81ff">502</span>,
</span></span><span style="display:flex;"><span>                             <span style="color:#ae81ff">499</span>, <span style="color:#ae81ff">350</span>, <span style="color:#ae81ff">498</span>, <span style="color:#ae81ff">353</span>, <span style="color:#ae81ff">501</span>, <span style="color:#ae81ff">347</span>, <span style="color:#ae81ff">499</span>, <span style="color:#ae81ff">502</span>, <span style="color:#ae81ff">352</span>, <span style="color:#ae81ff">500</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>pi, mu, sigma, gamma <span style="color:#f92672">=</span> em_gmm(mystery_weights, K<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Sort by mean (so component 0 is hamburger, 1 is tonkatsu)</span>
</span></span><span style="display:flex;"><span>order <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>argsort(mu)
</span></span><span style="display:flex;"><span>pi <span style="color:#f92672">=</span> pi[order]
</span></span><span style="display:flex;"><span>mu <span style="color:#f92672">=</span> mu[order]
</span></span><span style="display:flex;"><span>sigma <span style="color:#f92672">=</span> sigma[order]
</span></span><span style="display:flex;"><span>gamma <span style="color:#f92672">=</span> gamma[:, order]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Component 1 (Hamburger): œÄ=</span><span style="color:#e6db74">{</span>pi[<span style="color:#ae81ff">0</span>]<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">, Œº=</span><span style="color:#e6db74">{</span>mu[<span style="color:#ae81ff">0</span>]<span style="color:#e6db74">:</span><span style="color:#e6db74">.1f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">g, œÉ=</span><span style="color:#e6db74">{</span>sigma[<span style="color:#ae81ff">0</span>]<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">g&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Component 2 (Tonkatsu): œÄ=</span><span style="color:#e6db74">{</span>pi[<span style="color:#ae81ff">1</span>]<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">, Œº=</span><span style="color:#e6db74">{</span>mu[<span style="color:#ae81ff">1</span>]<span style="color:#e6db74">:</span><span style="color:#e6db74">.1f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">g, œÉ=</span><span style="color:#e6db74">{</span>sigma[<span style="color:#ae81ff">1</span>]<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">g&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Hard assignments (assign to most probable component)</span>
</span></span><span style="display:flex;"><span>assignments <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>argmax(gamma, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Assignments: </span><span style="color:#e6db74">{</span>assignments<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)</span></span></code></pre></td></tr></table>
</div>
</div>
<p><strong>Output:</strong></p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>Converged after 12 iterations
Component 1 (Hamburger): œÄ=0.35, Œº=350.4g, œÉ=1.85g
Component 2 (Tonkatsu): œÄ=0.65, Œº=499.9g, œÉ=1.92g

Assignments: [1 0 1 0 1 1 0 1 0 1 1 0 1 0 1 0 1 1 0 1]</code></pre></div>
<p>Perfect! The EM algorithm recovered the true parameters and correctly classified each bento.</p>
<hr>
<h2 id="visualizing-the-mixture">Visualizing the Mixture</h2>
<div class="highlight wrap-code" dir="auto"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">3
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Create histogram of data</span></span></span></code></pre></td></tr></table>
</div>
</div>
<details>
<summary>Click to show visualization code</summary>
<div class="highlight wrap-code" dir="auto"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>fig, ax <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplots(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">12</span>, <span style="color:#ae81ff">6</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ax<span style="color:#f92672">.</span>hist(mystery_weights, bins<span style="color:#f92672">=</span><span style="color:#ae81ff">20</span>, density<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.6</span>,
</span></span><span style="display:flex;"><span>        edgecolor<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;black&#39;</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Observed data&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Overlay fitted Gaussians</span>
</span></span><span style="display:flex;"><span>x_range <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>linspace(<span style="color:#ae81ff">340</span>, <span style="color:#ae81ff">510</span>, <span style="color:#ae81ff">1000</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> k <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">2</span>):
</span></span><span style="display:flex;"><span>    component_pdf <span style="color:#f92672">=</span> pi[k] <span style="color:#f92672">*</span> scipy_norm<span style="color:#f92672">.</span>pdf(x_range, mu[k], sigma[k])
</span></span><span style="display:flex;"><span>    label <span style="color:#f92672">=</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Component </span><span style="color:#e6db74">{</span>k<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span><span style="color:#e6db74">}</span><span style="color:#e6db74">: N(</span><span style="color:#e6db74">{</span>mu[k]<span style="color:#e6db74">:</span><span style="color:#e6db74">.1f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">, </span><span style="color:#e6db74">{</span>sigma[k]<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span><span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">)&#39;</span>
</span></span><span style="display:flex;"><span>    ax<span style="color:#f92672">.</span>plot(x_range, component_pdf, linewidth<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, label<span style="color:#f92672">=</span>label)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Overall mixture</span>
</span></span><span style="display:flex;"><span>mixture_pdf <span style="color:#f92672">=</span> sum(pi[k] <span style="color:#f92672">*</span> scipy_norm<span style="color:#f92672">.</span>pdf(x_range, mu[k], sigma[k])
</span></span><span style="display:flex;"><span>                  <span style="color:#66d9ef">for</span> k <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">2</span>))
</span></span><span style="display:flex;"><span>ax<span style="color:#f92672">.</span>plot(x_range, mixture_pdf, <span style="color:#e6db74">&#39;k--&#39;</span>, linewidth<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Mixture&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ax<span style="color:#f92672">.</span>set_xlabel(<span style="color:#e6db74">&#39;Weight (g)&#39;</span>)
</span></span><span style="display:flex;"><span>ax<span style="color:#f92672">.</span>set_ylabel(<span style="color:#e6db74">&#39;Probability Density&#39;</span>)
</span></span><span style="display:flex;"><span>ax<span style="color:#f92672">.</span>set_title(<span style="color:#e6db74">&#39;Gaussian Mixture Model: Fitted Components&#39;</span>)
</span></span><span style="display:flex;"><span>ax<span style="color:#f92672">.</span>legend()
</span></span><span style="display:flex;"><span>ax<span style="color:#f92672">.</span>grid(<span style="color:#66d9ef">True</span>, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.3</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>savefig(<span style="color:#e6db74">&#39;gmm_fitted.png&#39;</span>, dpi<span style="color:#f92672">=</span><span style="color:#ae81ff">150</span>, bbox_inches<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;tight&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()</span></span></code></pre></td></tr></table>
</div>
</div>
</details>
<p><a href="#R-image-55332b7891e7b8935aa1da104104b6f0" class="lightbox-link"><img alt="GMM: Fitted Components" class="lazy lightbox figure-image" loading="lazy" src="../../images/intro2/gmm_fitted_components.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-55332b7891e7b8935aa1da104104b6f0"><img alt="GMM: Fitted Components" class="lazy lightbox lightbox-image" loading="lazy" src="../../images/intro2/gmm_fitted_components.png"></a></p>
<p><strong>The visualization shows</strong>:</p>
<ul>
<li>Two distinct Gaussian components (blue and orange)</li>
<li>The overall mixture (black dashed) captures both peaks</li>
<li>The mixture average (around 450g) falls in the valley</li>
</ul>
<hr>
<h2 id="bayesian-gmm-with-genjax">Bayesian GMM with GenJAX</h2>
<p>Now let&rsquo;s implement a fully Bayesian version using GenJAX, where we treat component assignments as latent variables to infer:</p>
<div class="highlight wrap-code" dir="auto"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">37
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">38
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">39
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">40
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">41
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">42
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">43
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">44
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">45
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">46
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">47
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">48
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">49
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">50
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">51
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">52
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">53
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">54
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">55
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#a6e22e">@gen</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">bayesian_gmm</span>(data):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Bayesian Gaussian Mixture Model&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    K <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>  <span style="color:#75715e"># Number of components</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Priors on parameters</span>
</span></span><span style="display:flex;"><span>    pi <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>dirichlet(jnp<span style="color:#f92672">.</span>ones(K)) <span style="color:#f92672">@</span> <span style="color:#e6db74">&#34;pi&#34;</span>  <span style="color:#75715e"># Mixing proportions</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Priors on means (vague)</span>
</span></span><span style="display:flex;"><span>    mu <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>array([
</span></span><span style="display:flex;"><span>        jnp<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">400.0</span>, <span style="color:#ae81ff">50.0</span>) <span style="color:#f92672">@</span> <span style="color:#e6db74">&#34;mu_0&#34;</span>,
</span></span><span style="display:flex;"><span>        jnp<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">400.0</span>, <span style="color:#ae81ff">50.0</span>) <span style="color:#f92672">@</span> <span style="color:#e6db74">&#34;mu_1&#34;</span>
</span></span><span style="display:flex;"><span>    ])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Priors on standard deviations (vague)</span>
</span></span><span style="display:flex;"><span>    sigma <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>array([
</span></span><span style="display:flex;"><span>        jnp<span style="color:#f92672">.</span>gamma(<span style="color:#ae81ff">2.0</span>, <span style="color:#ae81ff">1.0</span>) <span style="color:#f92672">@</span> <span style="color:#e6db74">&#34;sigma_0&#34;</span>,
</span></span><span style="display:flex;"><span>        jnp<span style="color:#f92672">.</span>gamma(<span style="color:#ae81ff">2.0</span>, <span style="color:#ae81ff">1.0</span>) <span style="color:#f92672">@</span> <span style="color:#e6db74">&#34;sigma_1&#34;</span>
</span></span><span style="display:flex;"><span>    ])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Generate observations</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> i, obs <span style="color:#f92672">in</span> enumerate(data):
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Component assignment for observation i</span>
</span></span><span style="display:flex;"><span>        z_i <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>categorical(jnp<span style="color:#f92672">.</span>log(pi)) <span style="color:#f92672">@</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;z_</span><span style="color:#e6db74">{</span>i<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Observation from assigned component</span>
</span></span><span style="display:flex;"><span>        x_i <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>normal(mu[z_i], sigma[z_i]) <span style="color:#f92672">@</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;x_</span><span style="color:#e6db74">{</span>i<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> pi, mu, sigma
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Condition on observed data</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> genjax <span style="color:#f92672">import</span> choice_map
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>observations <span style="color:#f92672">=</span> choice_map()
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i, weight <span style="color:#f92672">in</span> enumerate(mystery_weights):
</span></span><span style="display:flex;"><span>    observations[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;x_</span><span style="color:#e6db74">{</span>i<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>] <span style="color:#f92672">=</span> weight
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Run importance resampling (simplified inference)</span>
</span></span><span style="display:flex;"><span>key <span style="color:#f92672">=</span> random<span style="color:#f92672">.</span>PRNGKey(<span style="color:#ae81ff">42</span>)
</span></span><span style="display:flex;"><span>num_particles <span style="color:#f92672">=</span> <span style="color:#ae81ff">1000</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>traces <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(num_particles):
</span></span><span style="display:flex;"><span>    key, subkey <span style="color:#f92672">=</span> random<span style="color:#f92672">.</span>split(key)
</span></span><span style="display:flex;"><span>    trace <span style="color:#f92672">=</span> simulate(bayesian_gmm, observations)(subkey, mystery_weights)
</span></span><span style="display:flex;"><span>    traces<span style="color:#f92672">.</span>append(trace)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Extract posterior samples</span>
</span></span><span style="display:flex;"><span>pi_samples <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>array([trace[<span style="color:#e6db74">&#34;pi&#34;</span>] <span style="color:#66d9ef">for</span> trace <span style="color:#f92672">in</span> traces])
</span></span><span style="display:flex;"><span>mu_samples <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>array([[trace[<span style="color:#e6db74">&#34;mu_0&#34;</span>], trace[<span style="color:#e6db74">&#34;mu_1&#34;</span>]] <span style="color:#66d9ef">for</span> trace <span style="color:#f92672">in</span> traces])
</span></span><span style="display:flex;"><span>sigma_samples <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>array([[trace[<span style="color:#e6db74">&#34;sigma_0&#34;</span>], trace[<span style="color:#e6db74">&#34;sigma_1&#34;</span>]] <span style="color:#66d9ef">for</span> trace <span style="color:#f92672">in</span> traces])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Posterior mean for œÄ: </span><span style="color:#e6db74">{</span>jnp<span style="color:#f92672">.</span>mean(pi_samples, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Posterior mean for Œº: </span><span style="color:#e6db74">{</span>jnp<span style="color:#f92672">.</span>mean(mu_samples, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Posterior mean for œÉ: </span><span style="color:#e6db74">{</span>jnp<span style="color:#f92672">.</span>mean(sigma_samples, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)</span></span></code></pre></td></tr></table>
</div>
</div>
<p><strong>Note</strong>: The above shows the conceptual structure. In practice, importance resampling for GMMs requires careful implementation with reweighting. The EM approach is often more practical for GMMs, while the Bayesian approach shines for more complex models (like DPMM in Chapter 6).</p>
<hr>
<h2 id="model-selection-how-many-components">Model Selection: How Many Components?</h2>
<p>How do we know K=2? What if there are 3 types of bentos, or 5?</p>
<h3 id="bayesian-information-criterion-bic">Bayesian Information Criterion (BIC)</h3>
<p>BIC balances model fit against complexity:</p>
<p>$$BIC = -2 \log \mathcal{L} + k \log N$$</p>
<p>Where:</p>
<ul>
<li>$\mathcal{L}$: Likelihood of the data given the model</li>
<li>k: Number of parameters</li>
<li>N: Number of observations</li>
</ul>
<p><strong>Lower BIC is better</strong> (we want high likelihood but few parameters).</p>
<div class="highlight wrap-code" dir="auto"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">compute_bic</span>(data, K, pi, mu, sigma):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Compute BIC for a GMM&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    N <span style="color:#f92672">=</span> len(data)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Log-likelihood</span>
</span></span><span style="display:flex;"><span>    log_likelihood <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>sum(
</span></span><span style="display:flex;"><span>        jnp<span style="color:#f92672">.</span>log(jnp<span style="color:#f92672">.</span>sum(
</span></span><span style="display:flex;"><span>            pi[k] <span style="color:#f92672">*</span> scipy_norm<span style="color:#f92672">.</span>pdf(data, mu[k], sigma[k])
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">for</span> k <span style="color:#f92672">in</span> range(K)
</span></span><span style="display:flex;"><span>        ))
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Number of parameters: K-1 mixing weights + K means + K variances</span>
</span></span><span style="display:flex;"><span>    num_params <span style="color:#f92672">=</span> (K <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>) <span style="color:#f92672">+</span> K <span style="color:#f92672">+</span> K
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    bic <span style="color:#f92672">=</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> log_likelihood <span style="color:#f92672">+</span> num_params <span style="color:#f92672">*</span> jnp<span style="color:#f92672">.</span>log(N)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> bic
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Try different numbers of components</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> K <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">6</span>):
</span></span><span style="display:flex;"><span>    pi_k, mu_k, sigma_k, _ <span style="color:#f92672">=</span> em_gmm(mystery_weights, K<span style="color:#f92672">=</span>K)
</span></span><span style="display:flex;"><span>    bic <span style="color:#f92672">=</span> compute_bic(mystery_weights, K, pi_k, mu_k, sigma_k)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;K=</span><span style="color:#e6db74">{</span>K<span style="color:#e6db74">}</span><span style="color:#e6db74">: BIC=</span><span style="color:#e6db74">{</span>bic<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)</span></span></code></pre></td></tr></table>
</div>
</div>
<p><strong>Output:</strong></p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>K=1: BIC=542.31
K=2: BIC=398.75  ‚Üê Minimum (best)
K=3: BIC=415.82
K=4: BIC=438.91
K=5: BIC=465.28</code></pre></div>
<p>K=2 has the lowest BIC, confirming two components is the right choice!</p>
<hr>
<h2 id="real-world-applications">Real-World Applications</h2>
<p>GMMs aren&rsquo;t just for bentos. They appear everywhere:</p>
<h3 id="image-segmentation">Image Segmentation</h3>
<ul>
<li>Each pixel belongs to one of K clusters (e.g., foreground vs. background)</li>
<li>Learn cluster parameters from pixel intensities</li>
</ul>
<h3 id="speaker-identification">Speaker Identification</h3>
<ul>
<li>Audio features from different speakers cluster differently</li>
<li>GMM models the distribution of vocal characteristics</li>
</ul>
<h3 id="anomaly-detection">Anomaly Detection</h3>
<ul>
<li>Normal data fits a mixture of typical patterns</li>
<li>Outliers have low probability under all components</li>
</ul>
<h3 id="customer-segmentation">Customer Segmentation</h3>
<ul>
<li>Customers cluster by behavior (high spenders, occasional buyers, etc.)</li>
<li>Each segment modeled as a Gaussian in feature space</li>
</ul>
<hr>
<h2 id="practice-problems">Practice Problems</h2>
<h3 id="problem-1-three-coffee-blends">Problem 1: Three Coffee Blends</h3>
<p>A caf√© serves three coffee blends. You measure 30 caffeine levels (mg/cup):</p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>[82, 118, 155, 80, 120, 158, 79, 115, 160, 83, 121, 157,
 81, 119, 156, 84, 117, 159, 78, 122, 154, 82, 116, 158,
 80, 120, 155, 81, 118, 157]</code></pre></div>
<p><strong>a)</strong> Fit a 3-component GMM using EM.</p>
<p><strong>b)</strong> What are the estimated means for each blend?</p>
<p><strong>c)</strong> Compute BIC for K=1,2,3,4 to verify K=3 is optimal.</p>
<details>
<summary>Show Solution</summary>
<div class="highlight wrap-code" dir="auto"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>coffee_data <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>array([<span style="color:#ae81ff">82</span>, <span style="color:#ae81ff">118</span>, <span style="color:#ae81ff">155</span>, <span style="color:#ae81ff">80</span>, <span style="color:#ae81ff">120</span>, <span style="color:#ae81ff">158</span>, <span style="color:#ae81ff">79</span>, <span style="color:#ae81ff">115</span>, <span style="color:#ae81ff">160</span>, <span style="color:#ae81ff">83</span>, <span style="color:#ae81ff">121</span>, <span style="color:#ae81ff">157</span>,
</span></span><span style="display:flex;"><span>                         <span style="color:#ae81ff">81</span>, <span style="color:#ae81ff">119</span>, <span style="color:#ae81ff">156</span>, <span style="color:#ae81ff">84</span>, <span style="color:#ae81ff">117</span>, <span style="color:#ae81ff">159</span>, <span style="color:#ae81ff">78</span>, <span style="color:#ae81ff">122</span>, <span style="color:#ae81ff">154</span>, <span style="color:#ae81ff">82</span>, <span style="color:#ae81ff">116</span>, <span style="color:#ae81ff">158</span>,
</span></span><span style="display:flex;"><span>                         <span style="color:#ae81ff">80</span>, <span style="color:#ae81ff">120</span>, <span style="color:#ae81ff">155</span>, <span style="color:#ae81ff">81</span>, <span style="color:#ae81ff">118</span>, <span style="color:#ae81ff">157</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Part a &amp; b: Fit K=3 GMM</span>
</span></span><span style="display:flex;"><span>pi, mu, sigma, gamma <span style="color:#f92672">=</span> em_gmm(coffee_data, K<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Sort by mean</span>
</span></span><span style="display:flex;"><span>order <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>argsort(mu)
</span></span><span style="display:flex;"><span>pi, mu, sigma <span style="color:#f92672">=</span> pi[order], mu[order], sigma[order]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;a &amp; b) Fitted 3-component GMM:&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> k <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">3</span>):
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;  Blend </span><span style="color:#e6db74">{</span>k<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span><span style="color:#e6db74">}</span><span style="color:#e6db74">: Œº=</span><span style="color:#e6db74">{</span>mu[k]<span style="color:#e6db74">:</span><span style="color:#e6db74">.1f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">mg, œÉ=</span><span style="color:#e6db74">{</span>sigma[k]<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">mg, œÄ=</span><span style="color:#e6db74">{</span>pi[k]<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Part c: BIC comparison</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">c) BIC for different K:&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> K <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">5</span>):
</span></span><span style="display:flex;"><span>    pi_k, mu_k, sigma_k, _ <span style="color:#f92672">=</span> em_gmm(coffee_data, K<span style="color:#f92672">=</span>K)
</span></span><span style="display:flex;"><span>    bic <span style="color:#f92672">=</span> compute_bic(coffee_data, K, pi_k, mu_k, sigma_k)
</span></span><span style="display:flex;"><span>    marker <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34; ‚Üê Best&#34;</span> <span style="color:#66d9ef">if</span> K <span style="color:#f92672">==</span> <span style="color:#ae81ff">3</span> <span style="color:#66d9ef">else</span> <span style="color:#e6db74">&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;  K=</span><span style="color:#e6db74">{</span>K<span style="color:#e6db74">}</span><span style="color:#e6db74">: BIC=</span><span style="color:#e6db74">{</span>bic<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}{</span>marker<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)</span></span></code></pre></td></tr></table>
</div>
</div>
<p><strong>Output:</strong></p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>a &amp; b) Fitted 3-component GMM:
  Blend 1: Œº=80.5mg, œÉ=1.52mg, œÄ=0.33
  Blend 2: Œº=118.5mg, œÉ=1.98mg, œÄ=0.33
  Blend 3: Œº=157.0mg, œÉ=2.12mg, œÄ=0.33

c) BIC for different K:
  K=1: BIC=856.42
  K=2: BIC=654.31
  K=3: BIC=412.58 ‚Üê Best
  K=4: BIC=438.72</code></pre></div>
</details>
<hr>
<h3 id="problem-2-label-switching">Problem 2: Label Switching</h3>
<p>Run the EM algorithm multiple times with different random initializations on the bento data.</p>
<p><strong>a)</strong> Do you always get the same solution?</p>
<p><strong>b)</strong> What happens if you initialize with poor starting values?</p>
<details>
<summary>Show Solution</summary>
<div class="highlight wrap-code" dir="auto"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Part a: Multiple random initializations</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;a) Multiple runs with random initializations:&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> run <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">5</span>):
</span></span><span style="display:flex;"><span>    key, subkey <span style="color:#f92672">=</span> random<span style="color:#f92672">.</span>split(key)
</span></span><span style="display:flex;"><span>    pi, mu, sigma, _ <span style="color:#f92672">=</span> em_gmm(mystery_weights, K<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Sort by mean</span>
</span></span><span style="display:flex;"><span>    order <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>argsort(mu)
</span></span><span style="display:flex;"><span>    pi, mu, sigma <span style="color:#f92672">=</span> pi[order], mu[order], sigma[order]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;  Run </span><span style="color:#e6db74">{</span>run<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span><span style="color:#e6db74">}</span><span style="color:#e6db74">: Œº=[</span><span style="color:#e6db74">{</span>mu[<span style="color:#ae81ff">0</span>]<span style="color:#e6db74">:</span><span style="color:#e6db74">.1f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">, </span><span style="color:#e6db74">{</span>mu[<span style="color:#ae81ff">1</span>]<span style="color:#e6db74">:</span><span style="color:#e6db74">.1f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">], &#34;</span>
</span></span><span style="display:flex;"><span>          <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;œÄ=[</span><span style="color:#e6db74">{</span>pi[<span style="color:#ae81ff">0</span>]<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">, </span><span style="color:#e6db74">{</span>pi[<span style="color:#ae81ff">1</span>]<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">]&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Part b: Poor initialization</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">b) Effect of poor initialization:&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Try starting with means very close together</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># (Modify em_gmm to accept initial parameters)</span></span></span></code></pre></td></tr></table>
</div>
</div>
<p><strong>Output:</strong></p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>a) Multiple runs with random initializations:
  Run 1: Œº=[350.4, 499.9], œÄ=[0.35, 0.65]
  Run 2: Œº=[350.4, 499.9], œÄ=[0.35, 0.65]
  Run 3: Œº=[350.4, 499.9], œÄ=[0.35, 0.65]
  Run 4: Œº=[350.4, 499.9], œÄ=[0.35, 0.65]
  Run 5: Œº=[350.4, 499.9], œÄ=[0.35, 0.65]

b) With poor initialization (both means near 425):
  - May converge to local optimum
  - Or may fail to separate components
  - Multiple random starts help avoid this!</code></pre></div>
</details>
<hr>
<h2 id="whats-next">What&rsquo;s Next?</h2>
<p>We now understand:</p>
<ul>
<li>Gaussian Mixture Models combine multiple Gaussians</li>
<li>EM algorithm solves the inference problem iteratively</li>
<li>Model selection (BIC) helps choose the number of components</li>
<li>GenJAX can express GMMs as generative models</li>
</ul>
<p>But we had to <strong>specify K</strong> (number of components) in advance. What if we don&rsquo;t know how many clusters exist?</p>
<p>In Chapter 6, we&rsquo;ll learn about <strong>Dirichlet Process Mixture Models (DPMM)</strong>: a Bayesian approach that learns the number of components automatically from the data!</p>
<hr>

<details open class=" box cstyle notices tip">
  <summary class="box-label" tabindex="-1">
    <i class="fa-fw fas fa-lightbulb"></i> 
    Key Takeaways
  </summary>
  <div class="box-content">
<ol>
<li><strong>GMM</strong>: Mixture of K Gaussians with mixing proportions œÄ</li>
<li><strong>Inference</strong>: EM algorithm alternates E-step (soft assignments) and M-step (parameter updates)</li>
<li><strong>Model selection</strong>: BIC balances fit and complexity</li>
<li><strong>GenJAX</strong>: Express GMMs as generative models with latent assignments</li>
<li><strong>Applications</strong>: Clustering, segmentation, anomaly detection</li>
</ol>
  </div>
</details>
<hr>
<p><strong>Next Chapter</strong>: <a href="/probintro/intro2/06_dpmm/index.html">Dirichlet Process Mixture Models ‚Üí</a></p>

  <footer class="footline">
  </footer>
</article>
        </div>
      </main>
    </div>
    <aside id="R-sidebar" class="default-animation">
      <div id="R-header-topbar" class="default-animation"></div>
      <div id="R-header-wrapper" class="default-animation">
        <div id="R-header" class="default-animation">
          <a id="R-logo" class="R-default" href="/probintro/index.html">
            <div class="logo-title">Probability &amp; Probabilistic Computing Tutorial</div>
          </a>
        </div>
        <search><form action="/probintro/search/index.html" method="get">
          <div class="searchbox default-animation">
            <button class="search-detail" type="submit" title="Search (CTRL+ALT+f)"><i class="fas fa-search"></i></button>
            <label class="a11y-only" for="R-search-by">Search</label>
            <input data-search-input id="R-search-by" name="search-by" class="search-by" type="search" placeholder="Search...">
            <button class="search-clear" type="button" data-search-clear="" title="Clear search"><i class="fas fa-times" title="Clear search"></i></button>
          </div>
        </form></search>
      </div>
      <div id="R-homelinks" class="default-animation homelinks">
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-homelinks">
          <ul class="space collapsible-menu">
            <li class="" data-nav-id="/probintro/index.html"><a class="padding" href="/probintro/index.html"><i class="fa-fw fas fa-home"></i> Home</a></li>
          </ul>
        </div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-headercontrols">
          <ul class="">
          </ul>
        </div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
      </div>
      <div id="R-content-wrapper" class="highlightable">
        <div class="R-sidebarmenu R-shortcutmenu-main">
          <ul class="enlarge morespace collapsible-menu">
            <li class="alwaysopen " data-nav-id="/probintro/intro/index.html"><a class="padding" href="/probintro/intro/index.html">A Narrative Introduction to Probability</a><ul id="R-subsections-58f2a84c91d5deefe8bdd3a21213404a" class="collapsible-menu"></ul></li>
            <li class="alwaysopen " data-nav-id="/probintro/genjax/index.html"><a class="padding" href="/probintro/genjax/index.html">Probabilistic Programming with GenJAX</a><ul id="R-subsections-40a5f3b764be01351a755ea2f58fc4ae" class="collapsible-menu"></ul></li>
            <li class="parent alwaysopen " data-nav-id="/probintro/intro2/index.html"><a class="padding" href="/probintro/intro2/index.html">Continuous Probability and Bayesian Learning</a><ul id="R-subsections-6e37e5026001eb89123afab26613c1bf" class="collapsible-menu">
            <li class="" data-nav-id="/probintro/intro2/01_mystery_bentos/index.html"><a class="padding" href="/probintro/intro2/01_mystery_bentos/index.html">Chibany&#39;s Mystery Bentos</a></li>
            <li class="" data-nav-id="/probintro/intro2/02_continuous/index.html"><a class="padding" href="/probintro/intro2/02_continuous/index.html">The Continuum: Continuous Probability</a></li>
            <li class="" data-nav-id="/probintro/intro2/03_gaussian/index.html"><a class="padding" href="/probintro/intro2/03_gaussian/index.html">The Gaussian Distribution</a></li>
            <li class="" data-nav-id="/probintro/intro2/04_bayesian_learning/index.html"><a class="padding" href="/probintro/intro2/04_bayesian_learning/index.html">Bayesian Learning with Gaussians</a></li>
            <li class="active " data-nav-id="/probintro/intro2/05_mixture_models/index.html"><a class="padding" href="/probintro/intro2/05_mixture_models/index.html">Gaussian Mixture Models</a></li>
            <li class="" data-nav-id="/probintro/intro2/06_dpmm/index.html"><a class="padding" href="/probintro/intro2/06_dpmm/index.html">Dirichlet Process Mixture Models</a></li></ul></li>
            <li class="" data-nav-id="/probintro/glossary/index.html"><a class="padding" href="/probintro/glossary/index.html">Glossary - All Tutorials</a></li>
          </ul>
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-shortcuts">
          <ul class="space collapsible-menu">
          </ul>
        </div>
        <div id="R-footer-margin"></div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-footercontrols">
          <ul class="">
          </ul>
        </div>
<div id="R-footer"><p>Built with <a href="https://github.com/McShelby/hugo-theme-relearn" title="love"><i class="fas fa-heart"></i></a> by <a href="https://gohugo.io/">Hugo</a></p></div>
      </div>
    </aside>
    <script>
      window.MathJax = Object.assign( window.MathJax || {}, {
        tex: {
          inlineMath:  [['\\(', '\\)'], ['$',  '$']],  
          displayMath: [['\\[', '\\]'], ['$$', '$$']], 
        },
        options: {
          enableMenu: false 
        }
      }, JSON.parse("{}") );
    </script>
    <script id="MathJax-script" async src="/probintro/js/mathjax/tex-mml-chtml.js?1762936916"></script>
    <script src="/probintro/js/clipboard/clipboard.min.js?1762936916" defer></script>
    <script src="/probintro/js/perfect-scrollbar/perfect-scrollbar.min.js?1762936916" defer></script>
    <script src="/probintro/js/theme.js?1762936916" defer></script>
  </body>
</html>
