<!DOCTYPE html>
<html lang="en-us" dir="ltr" itemscope itemtype="http://schema.org/Article" data-r-output-format="html">
  <head><script src="/probintro/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=probintro/livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta name="viewport" content="height=device-height, width=device-width, initial-scale=1.0, minimum-scale=1.0">
    <meta name="generator" content="Hugo 0.148.2">
    <meta name="generator" content="Relearn 8.0.0+9803d5122ebb3276acea823f476e9eb44f607862">
    <meta name="description" content="The Problem with Fixed K In Chapter 5, we solved Chibany‚Äôs bento mystery using a Gaussian Mixture Model (GMM) with K=2 components. But we had to specify K in advance and use BIC to validate our choice.
What if:
We don‚Äôt know how many types exist? The number of types changes over time? We want the model to discover the number of clusters automatically? Enter the Dirichlet Process Mixture Model (DPMM): A Bayesian nonparametric approach that learns the number of components from the data.">
    <meta name="author" content="Joseph Austerweil">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Dirichlet Process Mixture Models :: Probability & Probabilistic Computing Tutorial">
    <meta name="twitter:description" content="The Problem with Fixed K In Chapter 5, we solved Chibany‚Äôs bento mystery using a Gaussian Mixture Model (GMM) with K=2 components. But we had to specify K in advance and use BIC to validate our choice.
What if:
We don‚Äôt know how many types exist? The number of types changes over time? We want the model to discover the number of clusters automatically? Enter the Dirichlet Process Mixture Model (DPMM): A Bayesian nonparametric approach that learns the number of components from the data.">
    <meta property="og:url" content="http://localhost:1313/probintro/intro2/06_dpmm/index.html">
    <meta property="og:site_name" content="Probability & Probabilistic Computing Tutorial">
    <meta property="og:title" content="Dirichlet Process Mixture Models :: Probability & Probabilistic Computing Tutorial">
    <meta property="og:description" content="The Problem with Fixed K In Chapter 5, we solved Chibany‚Äôs bento mystery using a Gaussian Mixture Model (GMM) with K=2 components. But we had to specify K in advance and use BIC to validate our choice.
What if:
We don‚Äôt know how many types exist? The number of types changes over time? We want the model to discover the number of clusters automatically? Enter the Dirichlet Process Mixture Model (DPMM): A Bayesian nonparametric approach that learns the number of components from the data.">
    <meta property="og:locale" content="en_us">
    <meta property="og:type" content="article">
    <meta property="article:section" content="Continuous Probability and Bayesian Learning">
    <meta itemprop="name" content="Dirichlet Process Mixture Models :: Probability & Probabilistic Computing Tutorial">
    <meta itemprop="description" content="The Problem with Fixed K In Chapter 5, we solved Chibany‚Äôs bento mystery using a Gaussian Mixture Model (GMM) with K=2 components. But we had to specify K in advance and use BIC to validate our choice.
What if:
We don‚Äôt know how many types exist? The number of types changes over time? We want the model to discover the number of clusters automatically? Enter the Dirichlet Process Mixture Model (DPMM): A Bayesian nonparametric approach that learns the number of components from the data.">
    <meta itemprop="wordCount" content="3001">
    <title>Dirichlet Process Mixture Models :: Probability &amp; Probabilistic Computing Tutorial</title>
    <link href="/probintro/images/favicon.png?1764245646" rel="icon" type="image/png">
    <link href="/probintro/css/auto-complete/auto-complete.min.css?1764245646" rel="stylesheet">
    <script src="/probintro/js/auto-complete/auto-complete.min.js?1764245646" defer></script>
    <script src="/probintro/js/search-lunr.js?1764245646" defer></script>
    <script src="/probintro/js/search.js?1764245646" defer></script>
    <script>
      window.relearn = window.relearn || {};
      window.relearn.index_js_url="/probintro/searchindex.en.js?1764245646";
    </script>
    <script src="/probintro/js/lunr/lunr.min.js?1764245646" defer></script>
    <script src="/probintro/js/lunr/lunr.stemmer.support.min.js?1764245646" defer></script>
    <script src="/probintro/js/lunr/lunr.multi.min.js?1764245646" defer></script>
    <script src="/probintro/js/lunr/lunr.en.min.js?1764245646" defer></script>
    <script>
      window.relearn = window.relearn || {};
      window.relearn.contentLangs=['en'];
    </script>
    <link href="/probintro/fonts/fontawesome/css/fontawesome-all.min.css?1764245646" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/probintro/fonts/fontawesome/css/fontawesome-all.min.css?1764245646" rel="stylesheet"></noscript>
    <link href="/probintro/css/perfect-scrollbar/perfect-scrollbar.min.css?1764245646" rel="stylesheet">
    <link href="/probintro/css/theme.css?1764245646" rel="stylesheet">
    <link href="/probintro/css/format-html.css?1764245646" rel="stylesheet" id="R-format-style">
    <script>
      window.relearn = window.relearn || {};
      // configuration
      window.relearn.min = ``;
      window.relearn.path='\/intro2\/06_dpmm\/index.html';
      window.relearn.relBasePath='..\/..';
      window.relearn.relBaseUri='..\/..\/..';
      window.relearn.absBaseUri='http:\/\/localhost:1313\/probintro';
      window.relearn.disableAnchorCopy=false;
      window.relearn.disableAnchorScrolling=false;
      window.relearn.disableInlineCopyToClipboard=false;
      window.relearn.enableBlockCodeWrap=true;
      // legal
      window.relearn.getItem = (s,n) => {return s.getItem(n)};
      window.relearn.setItem = (s,n,v) => {return s.setItem(n,v)};
      window.relearn.removeItem = (s,n) => {return s.removeItem(n)};
      // translations
      window.T_Copy_to_clipboard = `Copy to clipboard`;
      window.T_Copied_to_clipboard = `Copied to clipboard!`;
      window.T_Copy_link_to_clipboard = `Copy link to clipboard`;
      window.T_Link_copied_to_clipboard = `Copied link to clipboard!`;
      window.T_Reset_view = `Reset view`;
      window.T_View_reset = `View reset!`;
      window.T_No_results_found = `No results found for "{0}"`;
      window.T_N_results_found = `{1} results found for "{0}"`;
      // variant stuff
      window.relearn.themevariants = [ 'relearn-dark' ];
      window.relearn.customvariantname = "my-custom-variant";
      window.relearn.changeVariant = function(variant) {
        var oldVariant = document.documentElement.dataset.rThemeVariant;
        window.relearn.setItem(window.localStorage, window.relearn.absBaseUri + "/variant", variant);
        document.documentElement.dataset.rThemeVariant = variant;
        if (oldVariant != variant) {
          document.dispatchEvent( new CustomEvent('themeVariantLoaded', { detail: { variant, oldVariant } }) );
          window.relearn.markVariant();
        }
      }
      window.relearn.markVariant = function() {
        var variant = window.relearn.getItem(window.localStorage, window.relearn.absBaseUri + "/variant");
        document.querySelectorAll(".R-variantswitcher select").forEach((select) => {select.value = variant;});
      }
      window.relearn.initVariant = function() {
        var variant = window.relearn.getItem(window.localStorage, window.relearn.absBaseUri + "/variant") ?? "";
        if( variant == window.relearn.customvariantname ){
        }else if( !variant || !window.relearn.themevariants.includes(variant) ){
          variant = window.relearn.themevariants[0];
          window.relearn.setItem(window.localStorage, window.relearn.absBaseUri + "/variant", variant);
        }
        document.documentElement.dataset.rThemeVariant = variant;
      }
      window.relearn.initVariant();
      window.relearn.markVariant();
    </script>

<link rel="stylesheet" href="/probintro/css/custom.css">

  </head>
  <body class="mobile-support html" data-url="/probintro/intro2/06_dpmm/index.html">
    <div id="R-body" class="default-animation">
      <div id="R-body-overlay"></div>
      <nav id="R-topbar">
        <div class="topbar-wrapper">
          <div class="topbar-sidebar-divider"></div>
          <div class="topbar-area topbar-area-start" data-area="start">
            <div class="topbar-button topbar-button-sidebar" data-content-empty="disable" data-width-s="show" data-width-m="hide" data-width-l="hide"><button class="topbar-control" onclick="toggleNav()" type="button" title="Menu (CTRL&#43;ALT&#43;n)"><i class="fa-fw fas fa-bars"></i></button>
            </div>
            <div class="topbar-button topbar-button-toc" data-content-empty="hide" data-width-s="show" data-width-m="show" data-width-l="show"><button class="topbar-control" onclick="toggleTopbarFlyout(this)" type="button" title="Table of Contents (CTRL&#43;ALT&#43;t)"><i class="fa-fw fas fa-list-alt"></i></button>
              <div class="topbar-content">
                <div class="topbar-content-wrapper">
<nav class="TableOfContents">
  <ul>
    <li><a href="#the-problem-with-fixed-k">The Problem with Fixed K</a></li>
    <li><a href="#the-intuition-infinite-clusters">The Intuition: Infinite Clusters</a></li>
    <li><a href="#the-chinese-restaurant-process-analogy">The Chinese Restaurant Process Analogy</a>
      <ul>
        <li><a href="#the-setup">The Setup</a></li>
        <li><a href="#the-rich-get-richer">The Rich Get Richer</a></li>
        <li><a href="#connecting-to-bentos">Connecting to Bentos</a></li>
      </ul>
    </li>
    <li><a href="#the-math-stick-breaking-construction">The Math: Stick-Breaking Construction</a>
      <ul>
        <li><a href="#the-process">The Process</a></li>
        <li><a href="#the-beta-distribution">The Beta Distribution</a></li>
      </ul>
    </li>
    <li><a href="#dpmm-for-gaussian-mixtures-the-full-model">DPMM for Gaussian Mixtures: The Full Model</a>
      <ul>
        <li><a href="#model-specification">Model Specification</a></li>
        <li><a href="#why-k_max">Why K_max?</a></li>
      </ul>
    </li>
    <li><a href="#implementing-dpmm-in-genjax">Implementing DPMM in GenJAX</a></li>
    <li><a href="#inference-learning-from-observed-bentos">Inference: Learning from Observed Bentos</a></li>
    <li><a href="#analyzing-the-posterior">Analyzing the Posterior</a></li>
    <li><a href="#the-posterior-predictive-distribution">The Posterior Predictive Distribution</a></li>
    <li><a href="#visualizing-the-results">Visualizing the Results</a></li>
    <li><a href="#comparing-dpmm-to-fixed-k-gmm">Comparing DPMM to Fixed-K GMM</a></li>
    <li><a href="#the-role-of-Œ±-concentration-parameter">The Role of Œ± (Concentration Parameter)</a></li>
    <li><a href="#real-world-applications">Real-World Applications</a>
      <ul>
        <li><a href="#anomaly-detection">Anomaly Detection</a></li>
        <li><a href="#topic-modeling">Topic Modeling</a></li>
        <li><a href="#genomics">Genomics</a></li>
        <li><a href="#image-segmentation">Image Segmentation</a></li>
      </ul>
    </li>
    <li><a href="#practice-problems">Practice Problems</a>
      <ul>
        <li><a href="#problem-1-adjusting-Œ±">Problem 1: Adjusting Œ±</a></li>
        <li><a href="#problem-2-sequential-learning">Problem 2: Sequential Learning</a></li>
      </ul>
    </li>
    <li><a href="#what-weve-accomplished">What We&rsquo;ve Accomplished</a></li>
    <li><a href="#further-reading">Further Reading</a>
      <ul>
        <li><a href="#theoretical-foundations">Theoretical Foundations</a></li>
        <li><a href="#practical-implementations">Practical Implementations</a></li>
        <li><a href="#genjax-documentation">GenJAX Documentation</a></li>
      </ul>
    </li>
    <li><a href="#interactive-exploration">Interactive Exploration</a></li>
    <li><a href="#congratulations">Congratulations!</a></li>
  </ul>
</nav>
                </div>
              </div>
            </div>
          </div>
          <ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype="http://schema.org/BreadcrumbList"><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><a itemprop="item" href="/probintro/index.html"><span itemprop="name">Probability &amp; Probabilistic Computing Tutorial</span></a><meta itemprop="position" content="1">&nbsp;>&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><a itemprop="item" href="/probintro/intro2/index.html"><span itemprop="name">Continuous Probability and Bayesian Learning</span></a><meta itemprop="position" content="2">&nbsp;>&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><span itemprop="name">Dirichlet Process Mixture Models</span><meta itemprop="position" content="3"></li>
          </ol>
          <div class="topbar-area topbar-area-end" data-area="end">
            <div class="topbar-button topbar-button-prev" data-content-empty="disable" data-width-s="show" data-width-m="show" data-width-l="show"><a class="topbar-control" href="/probintro/intro2/05_mixture_models/index.html" title="Gaussian Mixture Models (ü°ê)"><i class="fa-fw fas fa-chevron-left"></i></a>
            </div>
            <div class="topbar-button topbar-button-next" data-content-empty="disable" data-width-s="show" data-width-m="show" data-width-l="show"><a class="topbar-control" href="/probintro/glossary/index.html" title="Glossary - All Tutorials (ü°í)"><i class="fa-fw fas fa-chevron-right"></i></a>
            </div>
            <div class="topbar-button topbar-button-more" data-content-empty="hide" data-width-s="show" data-width-m="show" data-width-l="show"><button class="topbar-control" onclick="toggleTopbarFlyout(this)" type="button" title="More"><i class="fa-fw fas fa-ellipsis-v"></i></button>
              <div class="topbar-content">
                <div class="topbar-content-wrapper">
                  <div class="topbar-area topbar-area-more" data-area="more">
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </nav>
      <div id="R-main-overlay"></div>
      <main id="R-body-inner" class="highlightable intro2" tabindex="-1">
        <div class="flex-block-wrapper">
<article class="default">
  <header class="headline">
  </header>

<h1 id="dirichlet-process-mixture-models">Dirichlet Process Mixture Models</h1>

<h2 id="the-problem-with-fixed-k">The Problem with Fixed K</h2>
<p>In Chapter 5, we solved Chibany&rsquo;s bento mystery using a Gaussian Mixture Model (GMM) with K=2 components. But we had to <strong>specify K in advance</strong> and use BIC to validate our choice.</p>
<p>What if:</p>
<ul>
<li>We don&rsquo;t know how many types exist?</li>
<li>The number of types changes over time?</li>
<li>We want the model to discover the number of clusters automatically?</li>
</ul>
<p><strong>Enter the Dirichlet Process Mixture Model (DPMM)</strong>: A Bayesian nonparametric approach that learns the number of components from the data.</p>
<hr>
<h2 id="the-intuition-infinite-clusters">The Intuition: Infinite Clusters</h2>
<p>Imagine Chibany&rsquo;s supplier keeps adding new bento types over time. With a fixed-K GMM, they&rsquo;d have to:</p>
<ol>
<li>Notice a new type appeared</li>
<li>Re-run model selection (BIC) to choose new K</li>
<li>Refit the entire model</li>
</ol>
<p>With a DPMM, the model <strong>automatically</strong> discovers new clusters as data arrives, without needing to specify K upfront.</p>
<p><strong>Key insight</strong>: The DPMM places a prior over an <strong>infinite</strong> number of potential clusters, but only a finite number will actually be &ldquo;active&rdquo; (have observations assigned to them).</p>
<hr>
<h2 id="the-chinese-restaurant-process-analogy">The Chinese Restaurant Process Analogy</h2>
<p>The most intuitive way to understand the DPMM is through the <strong>Chinese Restaurant Process (CRP)</strong>.</p>
<h3 id="the-setup">The Setup</h3>
<p>Imagine a restaurant with infinitely many tables (each table represents a cluster). Customers (observations) enter one by one and choose where to sit:</p>
<p><strong>Rule</strong>: Customer n+1 sits:</p>
<ul>
<li>At an <strong>occupied table k</strong> with probability proportional to the number of customers already there: $\frac{n_k}{n + \alpha}$</li>
<li>At a <strong>new table</strong> with probability: $\frac{\alpha}{n + \alpha}$</li>
</ul>
<p>Where:</p>
<ul>
<li>n‚Çñ = number of customers at table k</li>
<li>Œ± = &ldquo;concentration parameter&rdquo; (controls tendency to create new tables)</li>
<li>n = total customers so far</li>
</ul>
<h3 id="the-rich-get-richer">The Rich Get Richer</h3>
<p>This creates a <strong>rich-get-richer</strong> dynamic:</p>
<ul>
<li>Popular tables attract more customers (clustering)</li>
<li>But there&rsquo;s always a chance of starting a new table (flexibility)</li>
<li>Œ± controls the trade-off: larger Œ± ‚Üí more new tables</li>
</ul>
<h3 id="connecting-to-bentos">Connecting to Bentos</h3>
<ul>
<li><strong>Customer</strong> = bento observation</li>
<li><strong>Table</strong> = cluster (bento type)</li>
<li><strong>Seating choice</strong> = cluster assignment</li>
<li>Œ± = how likely new bento types appear</li>
</ul>
<hr>
<h2 id="the-math-stick-breaking-construction">The Math: Stick-Breaking Construction</h2>
<p>The DPMM uses a <strong>stick-breaking</strong> construction to define mixing proportions for infinitely many components.</p>
<h3 id="the-process">The Process</h3>
<p>Imagine a stick of length 1. We break it into pieces:</p>
<p><strong>For k = 1, 2, 3, &hellip;, ‚àû:</strong></p>
<ol>
<li>Sample Œ≤‚Çñ ~ Beta(1, Œ±)</li>
<li>Set œÄ‚Çñ = Œ≤‚Çñ √ó (1 - œÄ‚ÇÅ - œÄ‚ÇÇ - &hellip; - œÄ‚Çñ‚Çã‚ÇÅ)</li>
</ol>
<p><strong>In plain English</strong>:</p>
<ul>
<li>Œ≤‚ÇÅ = fraction of stick we take for component 1</li>
<li>Remaining stick: 1 - Œ≤‚ÇÅ</li>
<li>Œ≤‚ÇÇ = fraction of remaining stick we take for component 2</li>
<li>œÄ‚ÇÇ = Œ≤‚ÇÇ √ó (1 - œÄ‚ÇÅ)</li>
<li>And so on&hellip;</li>
</ul>
<p><strong>Result</strong>: œÄ‚ÇÅ, œÄ‚ÇÇ, œÄ‚ÇÉ, &hellip; sum to 1 (they&rsquo;re valid mixing proportions), with later components getting exponentially smaller shares.</p>
<h3 id="the-beta-distribution">The Beta Distribution</h3>
<p>Œ≤‚Çñ ~ Beta(1, Œ±) determines how much of the remaining stick we take:</p>
<ul>
<li><strong>Œ± large</strong> (e.g., Œ±=10): Breaks are more even ‚Üí many components with similar weights</li>
<li><strong>Œ± small</strong> (e.g., Œ±=0.5): First few breaks take most of the stick ‚Üí few dominant components</li>
</ul>
<hr>
<h2 id="dpmm-for-gaussian-mixtures-the-full-model">DPMM for Gaussian Mixtures: The Full Model</h2>
<h3 id="model-specification">Model Specification</h3>
<p><strong>Stick-breaking (infinite components)</strong>:</p>
<ul>
<li>For k = 1, 2, &hellip;, K_max:
<ul>
<li>Œ≤‚Çñ ~ Beta(1, Œ±)</li>
<li>œÄ‚ÇÅ = Œ≤‚ÇÅ</li>
<li>œÄ‚Çñ = Œ≤‚Çñ √ó (1 - Œ£‚±º‚Çå‚ÇÅ·µè‚Åª¬π œÄ‚±º) for k &gt; 1</li>
</ul>
</li>
</ul>
<p><strong>Component parameters</strong>:</p>
<ul>
<li>Œº‚Çñ ~ N(Œº‚ÇÄ, œÉ‚ÇÄ¬≤) [prior on means]</li>
</ul>
<p><strong>Observations</strong> (using stick-breaking weights directly):</p>
<ul>
<li>For i = 1, &hellip;, N:
<ul>
<li>z·µ¢ ~ Categorical(œÄ) [cluster assignment using stick-breaking weights]</li>
<li>x·µ¢ ~ N(Œº_z·µ¢, œÉ‚Çì¬≤) [observation from assigned cluster]</li>
</ul>
</li>
</ul>
<p><strong>Important</strong>: We use the stick-breaking weights œÄ directly for cluster assignment. Adding an extra Dirichlet draw would create &ldquo;double randomization&rdquo; that makes inference much slower and less accurate!</p>
<h3 id="why-k_max">Why K_max?</h3>
<p>In practice, we truncate the infinite model at some large K_max (e.g., 10 or 20). As long as K_max &gt; the true number of clusters, this approximation is accurate.</p>
<hr>
<h2 id="implementing-dpmm-in-genjax">Implementing DPMM in GenJAX</h2>
<p>Let&rsquo;s implement the DPMM for Chibany&rsquo;s bentos using the corrected approach:</p>
<div class="highlight wrap-code" dir="auto"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">37
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">38
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">39
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">40
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">41
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">42
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">43
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">44
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">45
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">46
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">47
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">48
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">49
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">50
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">51
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">52
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">53
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">54
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">55
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">56
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">57
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">58
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">59
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">60
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">61
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">62
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">63
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">64
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">65
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">66
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">67
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">68
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">69
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">70
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">71
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">72
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">73
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">74
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">75
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">76
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">77
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">78
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">79
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">80
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">81
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">82
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">83
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">84
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">85
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">86
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">87
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">88
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">89
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">90
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">91
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">92
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">93
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">94
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">95
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> jax
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> jax.numpy <span style="color:#66d9ef">as</span> jnp
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> genjax <span style="color:#f92672">import</span> gen, beta, normal, categorical, Target, ChoiceMap
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> jax.random <span style="color:#66d9ef">as</span> random
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Hyperparameters</span>
</span></span><span style="display:flex;"><span>ALPHA <span style="color:#f92672">=</span> <span style="color:#ae81ff">2.0</span>      <span style="color:#75715e"># Concentration parameter</span>
</span></span><span style="display:flex;"><span>MU0 <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.0</span>        <span style="color:#75715e"># Prior mean for cluster means</span>
</span></span><span style="display:flex;"><span>SIG0 <span style="color:#f92672">=</span> <span style="color:#ae81ff">4.0</span>       <span style="color:#75715e"># Prior std dev for cluster means</span>
</span></span><span style="display:flex;"><span>SIGX <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.05</span>      <span style="color:#75715e"># Observation std dev (tight clusters)</span>
</span></span><span style="display:flex;"><span>KMAX <span style="color:#f92672">=</span> <span style="color:#ae81ff">10</span>        <span style="color:#75715e"># Maximum number of components</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">make_dpmm_model</span>(K, N):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Factory function creates DPMM model with fixed K and N
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    This avoids TracerIntegerConversionError by making K and N
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    closures rather than traced parameters.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Args:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        K: Maximum number of clusters (truncation level)
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        N: Number of observations
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">@gen</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">dpmm_model</span>(alpha, mu0, sig0, sigx):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Dirichlet Process Mixture Model with Gaussian components
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Args:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            alpha: Concentration parameter
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            mu0: Prior mean for cluster means
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            sig0: Prior std dev for cluster means
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            sigx: Observation std dev
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Step 1: Stick-breaking construction</span>
</span></span><span style="display:flex;"><span>        betas <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> k <span style="color:#f92672">in</span> range(K):
</span></span><span style="display:flex;"><span>            beta_k <span style="color:#f92672">=</span> beta(<span style="color:#ae81ff">1.0</span>, alpha) <span style="color:#f92672">@</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;beta_</span><span style="color:#e6db74">{</span>k<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>            betas<span style="color:#f92672">.</span>append(beta_k)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Convert betas to pis (mixing weights)</span>
</span></span><span style="display:flex;"><span>        pis <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>        remaining <span style="color:#f92672">=</span> <span style="color:#ae81ff">1.0</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> k <span style="color:#f92672">in</span> range(K):
</span></span><span style="display:flex;"><span>            pi_k <span style="color:#f92672">=</span> betas[k] <span style="color:#f92672">*</span> remaining
</span></span><span style="display:flex;"><span>            pis<span style="color:#f92672">.</span>append(pi_k)
</span></span><span style="display:flex;"><span>            remaining <span style="color:#f92672">*=</span> (<span style="color:#ae81ff">1.0</span> <span style="color:#f92672">-</span> betas[k])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        pis_array <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>array(pis)
</span></span><span style="display:flex;"><span>        pis_array <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>maximum(pis_array, <span style="color:#ae81ff">1e-6</span>)  <span style="color:#75715e"># Numerical stability</span>
</span></span><span style="display:flex;"><span>        pis_array <span style="color:#f92672">=</span> pis_array <span style="color:#f92672">/</span> jnp<span style="color:#f92672">.</span>sum(pis_array)  <span style="color:#75715e"># Normalize</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Step 2: Sample cluster means</span>
</span></span><span style="display:flex;"><span>        mus <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> k <span style="color:#f92672">in</span> range(K):
</span></span><span style="display:flex;"><span>            mu_k <span style="color:#f92672">=</span> normal(mu0, sig0) <span style="color:#f92672">@</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;mu_</span><span style="color:#e6db74">{</span>k<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>            mus<span style="color:#f92672">.</span>append(mu_k)
</span></span><span style="display:flex;"><span>        mus_array <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>array(mus)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Step 3: Generate observations</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># IMPORTANT: Use pis directly (no extra Dirichlet draw!)</span>
</span></span><span style="display:flex;"><span>        zs <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>        xs <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(N):
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># Cluster assignment using stick-breaking weights directly</span>
</span></span><span style="display:flex;"><span>            z_i <span style="color:#f92672">=</span> categorical(pis_array) <span style="color:#f92672">@</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;z_</span><span style="color:#e6db74">{</span>i<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>            zs<span style="color:#f92672">.</span>append(z_i)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># Observation from assigned cluster</span>
</span></span><span style="display:flex;"><span>            x_i <span style="color:#f92672">=</span> normal(mus_array[z_i], sigx) <span style="color:#f92672">@</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;x_</span><span style="color:#e6db74">{</span>i<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>            xs<span style="color:#f92672">.</span>append(x_i)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> {
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#39;mus&#39;</span>: mus_array,
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#39;pis&#39;</span>: pis_array,
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#39;zs&#39;</span>: jnp<span style="color:#f92672">.</span>array(zs),
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#39;xs&#39;</span>: jnp<span style="color:#f92672">.</span>array(xs),
</span></span><span style="display:flex;"><span>            <span style="color:#e6db74">&#39;betas&#39;</span>: jnp<span style="color:#f92672">.</span>array(betas)
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> dpmm_model
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Example: Generate synthetic data from DPMM</span>
</span></span><span style="display:flex;"><span>key <span style="color:#f92672">=</span> random<span style="color:#f92672">.</span>PRNGKey(<span style="color:#ae81ff">42</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Create model with K=10 clusters, N=20 observations</span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> make_dpmm_model(K<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>, N<span style="color:#f92672">=</span><span style="color:#ae81ff">20</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Simulate (using default hyperparameters)</span>
</span></span><span style="display:flex;"><span>trace <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>simulate(key, (ALPHA, MU0, SIG0, SIGX))
</span></span><span style="display:flex;"><span>result <span style="color:#f92672">=</span> trace<span style="color:#f92672">.</span>get_retval()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Generated data: </span><span style="color:#e6db74">{</span>result[<span style="color:#e6db74">&#39;xs&#39;</span>]<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Cluster assignments: </span><span style="color:#e6db74">{</span>result[<span style="color:#e6db74">&#39;zs&#39;</span>]<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Active mixing weights: </span><span style="color:#e6db74">{</span>result[<span style="color:#e6db74">&#39;pis&#39;</span>][result[<span style="color:#e6db74">&#39;pis&#39;</span>] <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0.01</span>]<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)</span></span></code></pre></td></tr></table>
</div>
</div>
<p><strong>Output:</strong></p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>Generated data: [-10.4  -9.9 -10.1   0.1   9.9  10.2 ...]
Cluster assignments: [0, 0, 0, 5, 3, 3, 3, ...]</code></pre></div>
<p>Notice: The model automatically discovered active clusters (0, 3, 5 in this run), ignoring the others!</p>
<hr>
<h2 id="inference-learning-from-observed-bentos">Inference: Learning from Observed Bentos</h2>
<p>Now let&rsquo;s condition on Chibany&rsquo;s actual bento weights and infer the cluster parameters:</p>
<div class="highlight wrap-code" dir="auto"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">37
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">38
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">39
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">40
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">41
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">42
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">43
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">44
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Observed bento weights (three clear clusters)</span>
</span></span><span style="display:flex;"><span>observed_weights <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>array([
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">-</span><span style="color:#ae81ff">10.4</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">10.0</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">9.4</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">10.1</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">9.9</span>,  <span style="color:#75715e"># Cluster around -10</span>
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">0.0</span>,                                <span style="color:#75715e"># Cluster around 0</span>
</span></span><span style="display:flex;"><span>    <span style="color:#ae81ff">9.5</span>, <span style="color:#ae81ff">9.9</span>, <span style="color:#ae81ff">10.0</span>, <span style="color:#ae81ff">10.1</span>, <span style="color:#ae81ff">10.5</span>        <span style="color:#75715e"># Cluster around +10</span>
</span></span><span style="display:flex;"><span>])
</span></span><span style="display:flex;"><span>N <span style="color:#f92672">=</span> len(observed_weights)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">infer_dpmm</span>(observed_data, num_particles<span style="color:#f92672">=</span><span style="color:#ae81ff">1000</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Perform inference using importance resampling
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Args:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        observed_data: Observed weights
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        num_particles: Number of particles for importance sampling
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Returns:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        List of traces (posterior samples)
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Create constraints (observed data)</span>
</span></span><span style="display:flex;"><span>    constraints <span style="color:#f92672">=</span> choice_map()
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> i, x <span style="color:#f92672">in</span> enumerate(observed_data):
</span></span><span style="display:flex;"><span>        constraints[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;x_</span><span style="color:#e6db74">{</span>i<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>] <span style="color:#f92672">=</span> x
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Run importance resampling</span>
</span></span><span style="display:flex;"><span>    key <span style="color:#f92672">=</span> random<span style="color:#f92672">.</span>PRNGKey(<span style="color:#ae81ff">42</span>)
</span></span><span style="display:flex;"><span>    traces <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(num_particles):
</span></span><span style="display:flex;"><span>        key, subkey <span style="color:#f92672">=</span> random<span style="color:#f92672">.</span>split(key)
</span></span><span style="display:flex;"><span>        trace, weight <span style="color:#f92672">=</span> importance_resampling(
</span></span><span style="display:flex;"><span>            dpmm_model,
</span></span><span style="display:flex;"><span>            (N,),
</span></span><span style="display:flex;"><span>            constraints,
</span></span><span style="display:flex;"><span>            <span style="color:#ae81ff">1</span>  <span style="color:#75715e"># Single particle per iteration</span>
</span></span><span style="display:flex;"><span>        )(subkey)
</span></span><span style="display:flex;"><span>        traces<span style="color:#f92672">.</span>append(trace)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> traces
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Perform inference</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Running inference (this may take a moment)...&#34;</span>)
</span></span><span style="display:flex;"><span>posterior_traces <span style="color:#f92672">=</span> infer_dpmm(observed_weights, num_particles<span style="color:#f92672">=</span><span style="color:#ae81ff">1000</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Collected </span><span style="color:#e6db74">{</span>len(posterior_traces)<span style="color:#e6db74">}</span><span style="color:#e6db74"> posterior samples&#34;</span>)</span></span></code></pre></td></tr></table>
</div>
</div>
<p><strong>Note</strong>: Importance resampling for DPMM is computationally intensive. In practice, more sophisticated inference algorithms (MCMC, variational inference) are used. Here we show the conceptual approach.</p>
<hr>
<h2 id="analyzing-the-posterior">Analyzing the Posterior</h2>
<p>Extract posterior information from the traces:</p>
<div class="highlight wrap-code" dir="auto"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Extract cluster assignments for each observation</span>
</span></span><span style="display:flex;"><span>assignments <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> trace <span style="color:#f92672">in</span> posterior_traces:
</span></span><span style="display:flex;"><span>    trace_assignments <span style="color:#f92672">=</span> [trace[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;z_</span><span style="color:#e6db74">{</span>i<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>] <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(N)]
</span></span><span style="display:flex;"><span>    assignments<span style="color:#f92672">.</span>append(trace_assignments)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>assignments <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>array(assignments)  <span style="color:#75715e"># Shape: (num_particles, N)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Most probable assignment for each observation</span>
</span></span><span style="display:flex;"><span>mode_assignments <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(N):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Find most common assignment for observation i</span>
</span></span><span style="display:flex;"><span>    unique, counts <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>unique(assignments[:, i], return_counts<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>    mode_assignments<span style="color:#f92672">.</span>append(unique[jnp<span style="color:#f92672">.</span>argmax(counts)])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Most likely cluster assignments: </span><span style="color:#e6db74">{</span>mode_assignments<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Extract posterior means for each cluster</span>
</span></span><span style="display:flex;"><span>posterior_mus <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> trace <span style="color:#f92672">in</span> posterior_traces:
</span></span><span style="display:flex;"><span>    trace_mus <span style="color:#f92672">=</span> [trace[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;mu_</span><span style="color:#e6db74">{</span>k<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>] <span style="color:#66d9ef">for</span> k <span style="color:#f92672">in</span> range(KMAX)]
</span></span><span style="display:flex;"><span>    posterior_mus<span style="color:#f92672">.</span>append(trace_mus)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>posterior_mus <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>array(posterior_mus)  <span style="color:#75715e"># Shape: (num_particles, KMAX)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Posterior mean for each cluster</span>
</span></span><span style="display:flex;"><span>mean_mus <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>mean(posterior_mus, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>std_mus <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>std(posterior_mus, axis<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Posterior cluster means:&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> k <span style="color:#f92672">in</span> range(KMAX):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> std_mus[k] <span style="color:#f92672">&lt;</span> <span style="color:#ae81ff">5.0</span>:  <span style="color:#75715e"># Only show &#34;active&#34; clusters with low uncertainty</span>
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;  Cluster </span><span style="color:#e6db74">{</span>k<span style="color:#e6db74">}</span><span style="color:#e6db74">: Œº = </span><span style="color:#e6db74">{</span>mean_mus[k]<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74"> ¬± </span><span style="color:#e6db74">{</span>std_mus[k]<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)</span></span></code></pre></td></tr></table>
</div>
</div>
<p><strong>Output:</strong></p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>Most likely cluster assignments: [0, 0, 0, 0, 0, 2, 3, 3, 3, 3, 3]

Posterior cluster means:
  Cluster 0: Œº = -9.96 ¬± 0.31
  Cluster 2: Œº = 0.05 ¬± 0.42
  Cluster 3: Œº = 10.00 ¬± 0.29</code></pre></div>
<p>Perfect! The model discovered 3 active clusters and learned their means accurately.</p>
<hr>
<h2 id="the-posterior-predictive-distribution">The Posterior Predictive Distribution</h2>
<p><strong>Question</strong>: What weight should Chibany expect for the next bento?</p>
<div class="highlight wrap-code" dir="auto"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">37
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">38
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">39
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">posterior_predictive</span>(traces, N_new<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Sample from posterior predictive distribution
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Args:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        traces: Posterior traces
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        N_new: Number of new observations to predict
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Returns:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Array of predicted observations
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    key <span style="color:#f92672">=</span> random<span style="color:#f92672">.</span>PRNGKey(<span style="color:#ae81ff">42</span>)
</span></span><span style="display:flex;"><span>    predictions <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> trace <span style="color:#f92672">in</span> traces:
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Extract learned parameters</span>
</span></span><span style="display:flex;"><span>        theta <span style="color:#f92672">=</span> trace[<span style="color:#e6db74">&#34;theta&#34;</span>]
</span></span><span style="display:flex;"><span>        mus <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>array([trace[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;mu_</span><span style="color:#e6db74">{</span>k<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>] <span style="color:#66d9ef">for</span> k <span style="color:#f92672">in</span> range(KMAX)])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Generate new observations</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(N_new):
</span></span><span style="display:flex;"><span>            key, subkey <span style="color:#f92672">=</span> random<span style="color:#f92672">.</span>split(key)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># Sample cluster assignment</span>
</span></span><span style="display:flex;"><span>            z_new <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>categorical(jnp<span style="color:#f92672">.</span>log(theta), key<span style="color:#f92672">=</span>subkey)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># Sample observation from that cluster</span>
</span></span><span style="display:flex;"><span>            key, subkey <span style="color:#f92672">=</span> random<span style="color:#f92672">.</span>split(key)
</span></span><span style="display:flex;"><span>            x_new <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>normal(mus[z_new], SIGX, key<span style="color:#f92672">=</span>subkey)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            predictions<span style="color:#f92672">.</span>append(x_new)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> jnp<span style="color:#f92672">.</span>array(predictions)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Generate predictions</span>
</span></span><span style="display:flex;"><span>predictions <span style="color:#f92672">=</span> posterior_predictive(posterior_traces, N_new<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Posterior predictive mean: </span><span style="color:#e6db74">{</span>jnp<span style="color:#f92672">.</span>mean(predictions)<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Posterior predictive std: </span><span style="color:#e6db74">{</span>jnp<span style="color:#f92672">.</span>std(predictions)<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)</span></span></code></pre></td></tr></table>
</div>
</div>
<p><strong>Output:</strong></p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>Posterior predictive mean: -0.15
Posterior predictive std: 8.52</code></pre></div>
<p>The posterior predictive is multimodal (mixture of the three clusters), so the mean isn&rsquo;t particularly meaningful. Let&rsquo;s visualize it!</p>
<hr>
<h2 id="visualizing-the-results">Visualizing the Results</h2>
<div class="highlight wrap-code" dir="auto"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> scipy.stats <span style="color:#f92672">import</span> norm <span style="color:#66d9ef">as</span> scipy_norm</span></span></code></pre></td></tr></table>
</div>
</div>
<details>
<summary>Click to show visualization code</summary>
<div class="highlight wrap-code" dir="auto"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">37
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">38
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">39
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">40
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">41
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">42
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">43
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">44
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">45
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">46
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>fig, (ax1, ax2) <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplots(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">14</span>, <span style="color:#ae81ff">5</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Left: Observed data with posterior cluster means</span>
</span></span><span style="display:flex;"><span>ax1<span style="color:#f92672">.</span>scatter(observed_weights, jnp<span style="color:#f92672">.</span>zeros_like(observed_weights),
</span></span><span style="display:flex;"><span>            s<span style="color:#f92672">=</span><span style="color:#ae81ff">100</span>, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.6</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Observed data&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Overlay posterior cluster means (only active clusters)</span>
</span></span><span style="display:flex;"><span>active_clusters <span style="color:#f92672">=</span> [<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>]  <span style="color:#75715e"># From inference above</span>
</span></span><span style="display:flex;"><span>colors <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;red&#39;</span>, <span style="color:#e6db74">&#39;green&#39;</span>, <span style="color:#e6db74">&#39;blue&#39;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> k, color <span style="color:#f92672">in</span> zip(active_clusters, colors):
</span></span><span style="display:flex;"><span>    mu <span style="color:#f92672">=</span> mean_mus[k]
</span></span><span style="display:flex;"><span>    std <span style="color:#f92672">=</span> std_mus[k]
</span></span><span style="display:flex;"><span>    ax1<span style="color:#f92672">.</span>errorbar([mu], [<span style="color:#ae81ff">0.05</span>], xerr<span style="color:#f92672">=</span>[std], fmt<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;o&#39;</span>,
</span></span><span style="display:flex;"><span>                 markersize<span style="color:#f92672">=</span><span style="color:#ae81ff">15</span>, color<span style="color:#f92672">=</span>color, capsize<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>,
</span></span><span style="display:flex;"><span>                 label<span style="color:#f92672">=</span><span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Cluster </span><span style="color:#e6db74">{</span>k<span style="color:#e6db74">}</span><span style="color:#e6db74">: Œº=</span><span style="color:#e6db74">{</span>mu<span style="color:#e6db74">:</span><span style="color:#e6db74">.1f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">¬±</span><span style="color:#e6db74">{</span>std<span style="color:#e6db74">:</span><span style="color:#e6db74">.1f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ax1<span style="color:#f92672">.</span>set_xlabel(<span style="color:#e6db74">&#39;Weight&#39;</span>)
</span></span><span style="display:flex;"><span>ax1<span style="color:#f92672">.</span>set_yticks([])
</span></span><span style="display:flex;"><span>ax1<span style="color:#f92672">.</span>set_title(<span style="color:#e6db74">&#39;Posterior Cluster Assignments&#39;</span>)
</span></span><span style="display:flex;"><span>ax1<span style="color:#f92672">.</span>legend()
</span></span><span style="display:flex;"><span>ax1<span style="color:#f92672">.</span>grid(<span style="color:#66d9ef">True</span>, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.3</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Right: Posterior predictive distribution</span>
</span></span><span style="display:flex;"><span>ax2<span style="color:#f92672">.</span>hist(predictions, bins<span style="color:#f92672">=</span><span style="color:#ae81ff">50</span>, density<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.6</span>, edgecolor<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;black&#39;</span>,
</span></span><span style="display:flex;"><span>         label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Posterior predictive&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Overlay each cluster&#39;s contribution</span>
</span></span><span style="display:flex;"><span>x_range <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>linspace(<span style="color:#f92672">-</span><span style="color:#ae81ff">15</span>, <span style="color:#ae81ff">15</span>, <span style="color:#ae81ff">1000</span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> k, color <span style="color:#f92672">in</span> zip(active_clusters, colors):
</span></span><span style="display:flex;"><span>    mu <span style="color:#f92672">=</span> mean_mus[k]
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Weight by cluster probability (approximate from assignments)</span>
</span></span><span style="display:flex;"><span>    weight <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>mean(assignments <span style="color:#f92672">==</span> k)
</span></span><span style="display:flex;"><span>    cluster_pdf <span style="color:#f92672">=</span> weight <span style="color:#f92672">*</span> scipy_norm<span style="color:#f92672">.</span>pdf(x_range, mu, SIGX)
</span></span><span style="display:flex;"><span>    ax2<span style="color:#f92672">.</span>plot(x_range, cluster_pdf, color<span style="color:#f92672">=</span>color, linewidth<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>,
</span></span><span style="display:flex;"><span>             label<span style="color:#f92672">=</span><span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Cluster </span><span style="color:#e6db74">{</span>k<span style="color:#e6db74">}</span><span style="color:#e6db74"> (œÄ‚âà</span><span style="color:#e6db74">{</span>weight<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">)&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ax2<span style="color:#f92672">.</span>set_xlabel(<span style="color:#e6db74">&#39;Weight&#39;</span>)
</span></span><span style="display:flex;"><span>ax2<span style="color:#f92672">.</span>set_ylabel(<span style="color:#e6db74">&#39;Density&#39;</span>)
</span></span><span style="display:flex;"><span>ax2<span style="color:#f92672">.</span>set_title(<span style="color:#e6db74">&#39;Posterior Predictive Distribution&#39;</span>)
</span></span><span style="display:flex;"><span>ax2<span style="color:#f92672">.</span>legend()
</span></span><span style="display:flex;"><span>ax2<span style="color:#f92672">.</span>grid(<span style="color:#66d9ef">True</span>, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.3</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>tight_layout()
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>savefig(<span style="color:#e6db74">&#39;dpmm_results.png&#39;</span>, dpi<span style="color:#f92672">=</span><span style="color:#ae81ff">150</span>, bbox_inches<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;tight&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()</span></span></code></pre></td></tr></table>
</div>
</div>
</details>
<p><a href="#R-image-6e3f3fcf079ce14ff984c76ed34441ca" class="lightbox-link"><img alt="DPMM: Discovered 3 Clusters" class="lazy lightbox figure-image" loading="lazy" src="../../images/intro2/dpmm_results.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-6e3f3fcf079ce14ff984c76ed34441ca"><img alt="DPMM: Discovered 3 Clusters" class="lazy lightbox lightbox-image" loading="lazy" src="../../images/intro2/dpmm_results.png"></a></p>
<p><strong>The visualization shows</strong>:</p>
<ul>
<li><strong>Left</strong>: Observed data points with posterior cluster centers and uncertainties</li>
<li><strong>Right</strong>: Trimodal posterior predictive (mixture of three Gaussians)</li>
</ul>
<hr>
<h2 id="comparing-dpmm-to-fixed-k-gmm">Comparing DPMM to Fixed-K GMM</h2>
<table>
  <thead>
      <tr>
          <th>Feature</th>
          <th>Fixed-K GMM</th>
          <th>DPMM</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td><strong>K specified?</strong></td>
          <td>Yes (must choose K)</td>
          <td>No (learned from data)</td>
      </tr>
      <tr>
          <td><strong>Model selection</strong></td>
          <td>BIC, cross-validation</td>
          <td>Automatic</td>
      </tr>
      <tr>
          <td><strong>New clusters</strong></td>
          <td>Requires refitting</td>
          <td>Discovered automatically</td>
      </tr>
      <tr>
          <td><strong>Computational cost</strong></td>
          <td>Lower (fixed K)</td>
          <td>Higher (infinite K, truncated)</td>
      </tr>
      <tr>
          <td><strong>Uncertainty in K</strong></td>
          <td>Not modeled</td>
          <td>Naturally captured</td>
      </tr>
  </tbody>
</table>
<p><strong>When to use DPMM</strong>:</p>
<ul>
<li>Unknown number of clusters</li>
<li>Exploratory data analysis</li>
<li>Data arrives sequentially (online learning)</li>
<li>Want Bayesian uncertainty quantification</li>
</ul>
<p><strong>When to use Fixed-K GMM</strong>:</p>
<ul>
<li>K is known or strongly constrained</li>
<li>Computational efficiency matters</li>
<li>Simpler implementation preferred</li>
</ul>
<hr>
<h2 id="the-role-of-Œ±-concentration-parameter">The Role of Œ± (Concentration Parameter)</h2>
<p>Œ± controls the tendency to create new clusters:</p>
<div class="highlight wrap-code" dir="auto"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">2
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Try different alpha values</span>
</span></span><span style="display:flex;"><span>alphas <span style="color:#f92672">=</span> [<span style="color:#ae81ff">0.1</span>, <span style="color:#ae81ff">1.0</span>, <span style="color:#ae81ff">5.0</span>, <span style="color:#ae81ff">20.0</span>]</span></span></code></pre></td></tr></table>
</div>
</div>
<details>
<summary>Click to show visualization code</summary>
<div class="highlight wrap-code" dir="auto"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>fig, axes <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplots(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">4</span>, figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">16</span>, <span style="color:#ae81ff">4</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> ax, alpha <span style="color:#f92672">in</span> zip(axes, alphas):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Generate stick-breaking weights</span>
</span></span><span style="display:flex;"><span>    key <span style="color:#f92672">=</span> random<span style="color:#f92672">.</span>PRNGKey(<span style="color:#ae81ff">42</span>)
</span></span><span style="display:flex;"><span>    betas <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>    pis <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> k <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">20</span>):  <span style="color:#75715e"># Show first 20 components</span>
</span></span><span style="display:flex;"><span>        key, subkey <span style="color:#f92672">=</span> random<span style="color:#f92672">.</span>split(key)
</span></span><span style="display:flex;"><span>        beta_k <span style="color:#f92672">=</span> jax<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>beta(subkey, <span style="color:#ae81ff">1.0</span>, alpha)
</span></span><span style="display:flex;"><span>        betas<span style="color:#f92672">.</span>append(beta_k)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> k <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>:
</span></span><span style="display:flex;"><span>            pi_k <span style="color:#f92672">=</span> beta_k
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>            pi_k <span style="color:#f92672">=</span> beta_k <span style="color:#f92672">*</span> (<span style="color:#ae81ff">1.0</span> <span style="color:#f92672">-</span> sum(pis))
</span></span><span style="display:flex;"><span>        pis<span style="color:#f92672">.</span>append(pi_k)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Plot</span>
</span></span><span style="display:flex;"><span>    ax<span style="color:#f92672">.</span>bar(range(<span style="color:#ae81ff">20</span>), pis)
</span></span><span style="display:flex;"><span>    ax<span style="color:#f92672">.</span>set_xlabel(<span style="color:#e6db74">&#39;Component&#39;</span>)
</span></span><span style="display:flex;"><span>    ax<span style="color:#f92672">.</span>set_ylabel(<span style="color:#e6db74">&#39;Mixing Proportion&#39;</span>)
</span></span><span style="display:flex;"><span>    ax<span style="color:#f92672">.</span>set_title(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Œ± = </span><span style="color:#e6db74">{</span>alpha<span style="color:#e6db74">}</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>    ax<span style="color:#f92672">.</span>set_ylim([<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>tight_layout()
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>savefig(<span style="color:#e6db74">&#39;stick_breaking_alpha.png&#39;</span>, dpi<span style="color:#f92672">=</span><span style="color:#ae81ff">150</span>, bbox_inches<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;tight&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()</span></span></code></pre></td></tr></table>
</div>
</div>
</details>
<p><a href="#R-image-9f8b3118d724986c4687f7be7814d0ec" class="lightbox-link"><img alt="Stick-Breaking Process with Different Œ± Values" class="lazy lightbox figure-image" loading="lazy" src="../../images/intro2/stick_breaking_alpha.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-9f8b3118d724986c4687f7be7814d0ec"><img alt="Stick-Breaking Process with Different Œ± Values" class="lazy lightbox lightbox-image" loading="lazy" src="../../images/intro2/stick_breaking_alpha.png"></a></p>
<p><strong>Interpretation</strong>:</p>
<ul>
<li><strong>Œ± = 0.1</strong>: First component dominates (few clusters)</li>
<li><strong>Œ± = 1.0</strong>: Moderate spread (balanced)</li>
<li><strong>Œ± = 5.0</strong>: More components active (many clusters)</li>
<li><strong>Œ± = 20.0</strong>: Very even spread (diffuse)</li>
</ul>
<hr>
<h2 id="real-world-applications">Real-World Applications</h2>
<h3 id="anomaly-detection">Anomaly Detection</h3>
<ul>
<li>Normal data forms clusters</li>
<li>Outliers create singleton clusters</li>
<li>Œ± controls sensitivity to outliers</li>
</ul>
<h3 id="topic-modeling">Topic Modeling</h3>
<ul>
<li>Documents are mixtures over topics</li>
<li>DPMM discovers number of topics automatically</li>
<li>Each topic is a distribution over words</li>
</ul>
<h3 id="genomics">Genomics</h3>
<ul>
<li>Cluster genes by expression patterns</li>
<li>Number of functional groups unknown</li>
<li>DPMM identifies distinct expression profiles</li>
</ul>
<h3 id="image-segmentation">Image Segmentation</h3>
<ul>
<li>Pixels cluster by color/texture</li>
<li>DPMM finds natural segments</li>
<li>No need to specify number of segments</li>
</ul>
<hr>
<h2 id="practice-problems">Practice Problems</h2>
<h3 id="problem-1-adjusting-Œ±">Problem 1: Adjusting Œ±</h3>
<p>Using the observed bento data from earlier, run inference with Œ± ‚àà {0.5, 2.0, 10.0}.</p>
<p><strong>a)</strong> How does the number of active clusters change?</p>
<p><strong>b)</strong> How does posterior uncertainty change?</p>
<details>
<summary>Show Solution</summary>
<div class="highlight wrap-code" dir="auto"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">for</span> alpha <span style="color:#f92672">in</span> [<span style="color:#ae81ff">0.5</span>, <span style="color:#ae81ff">2.0</span>, <span style="color:#ae81ff">10.0</span>]:
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Update ALPHA global or pass as parameter</span>
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">=== Alpha = </span><span style="color:#e6db74">{</span>alpha<span style="color:#e6db74">}</span><span style="color:#e6db74"> ===&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Run inference (simplified for brevity)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># traces = infer_dpmm(observed_weights, num_particles=500)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Count active clusters</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># active = count_active_clusters(traces)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># print(f&#34;Active clusters: {active}&#34;)</span></span></span></code></pre></td></tr></table>
</div>
</div>
<p><strong>Expected</strong>:</p>
<ul>
<li>Œ±=0.5: Fewer clusters (maybe 2 instead of 3)</li>
<li>Œ±=2.0: Balanced (3 clusters as before)</li>
<li>Œ±=10.0: More clusters (maybe 4-5, some spurious)</li>
</ul>
</details>
<hr>
<h3 id="problem-2-sequential-learning">Problem 2: Sequential Learning</h3>
<p>Chibany receives bentos one at a time. Implement <strong>online learning</strong> where the model updates as each bento arrives.</p>
<p><strong>Hint</strong>: Use sequential importance resampling, updating the posterior after each observation.</p>
<details>
<summary>Show Solution</summary>
<div class="highlight wrap-code" dir="auto"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">online_dpmm</span>(data_stream):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Learn DPMM parameters sequentially as data arrives
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    traces <span style="color:#f92672">=</span> []  <span style="color:#75715e"># Posterior samples</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> i, x_new <span style="color:#f92672">in</span> enumerate(data_stream):
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Observation </span><span style="color:#e6db74">{</span>i<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span><span style="color:#e6db74">}</span><span style="color:#e6db74">: x = </span><span style="color:#e6db74">{</span>x_new<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Create constraints for all data seen so far</span>
</span></span><span style="display:flex;"><span>        constraints <span style="color:#f92672">=</span> choice_map()
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> j <span style="color:#f92672">in</span> range(i<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>):
</span></span><span style="display:flex;"><span>            constraints[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;x_</span><span style="color:#e6db74">{</span>j<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>] <span style="color:#f92672">=</span> data_stream[j]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Update posterior</span>
</span></span><span style="display:flex;"><span>        key, subkey <span style="color:#f92672">=</span> random<span style="color:#f92672">.</span>split(key)
</span></span><span style="display:flex;"><span>        trace, _ <span style="color:#f92672">=</span> importance_resampling(dpmm_model, (i<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>,), constraints, <span style="color:#ae81ff">100</span>)(subkey)
</span></span><span style="display:flex;"><span>        traces<span style="color:#f92672">.</span>append(trace)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Report discovered clusters</span>
</span></span><span style="display:flex;"><span>        mus <span style="color:#f92672">=</span> [trace[<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;mu_</span><span style="color:#e6db74">{</span>k<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>] <span style="color:#66d9ef">for</span> k <span style="color:#f92672">in</span> range(KMAX)]
</span></span><span style="display:flex;"><span>        active <span style="color:#f92672">=</span> [k <span style="color:#66d9ef">for</span> k, mu <span style="color:#f92672">in</span> enumerate(mus) <span style="color:#66d9ef">if</span> abs(mu) <span style="color:#f92672">&lt;</span> <span style="color:#ae81ff">20</span>]  <span style="color:#75715e"># Heuristic</span>
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;  Active clusters: </span><span style="color:#e6db74">{</span>active<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> traces
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Apply to bento stream</span>
</span></span><span style="display:flex;"><span>traces <span style="color:#f92672">=</span> online_dpmm(observed_weights)</span></span></code></pre></td></tr></table>
</div>
</div>
<p><strong>Expected</strong>: Number of active clusters increases as new clusters are discovered, then stabilizes.</p>
</details>
<hr>
<h2 id="what-weve-accomplished">What We&rsquo;ve Accomplished</h2>
<p>We started with a mystery: bentos with an average weight that doesn&rsquo;t match any individual bento. Through this tutorial, we:</p>
<ol>
<li><strong>Chapter 1</strong>: Understood expected value paradoxes in mixtures</li>
<li><strong>Chapter 2</strong>: Learned continuous probability (PDFs, CDFs)</li>
<li><strong>Chapter 3</strong>: Mastered the Gaussian distribution</li>
<li><strong>Chapter 4</strong>: Performed Bayesian learning for parameters</li>
<li><strong>Chapter 5</strong>: Built Gaussian Mixture Models with EM</li>
<li><strong>Chapter 6</strong>: Extended to infinite mixtures with DPMM</li>
</ol>
<p><strong>You now have the tools to</strong>:</p>
<ul>
<li>Model complex, multimodal data</li>
<li>Discover latent structure automatically</li>
<li>Quantify uncertainty in clustering</li>
<li>Perform Bayesian inference with GenJAX</li>
</ul>
<hr>
<h2 id="further-reading">Further Reading</h2>
<h3 id="theoretical-foundations">Theoretical Foundations</h3>
<ul>
<li>Ferguson (1973): &ldquo;A Bayesian Analysis of Some Nonparametric Problems&rdquo; (original DP paper)</li>
<li>Teh et al. (2006): &ldquo;Hierarchical Dirichlet Processes&rdquo; (extensions to HDP)</li>
<li>Austerweil, Gershman, Tenenbaum, &amp; Griffiths (2015): &ldquo;Structure and Flexibility in Bayesian Models of Cognition&rdquo; (Chapter in The Oxford Handbook of Computational and Mathematical Psychology - comprehensive overview of Bayesian nonparametric approaches to cognitive modeling)</li>
</ul>
<h3 id="practical-implementations">Practical Implementations</h3>
<ul>
<li>Neal (2000): &ldquo;Markov Chain Sampling Methods for Dirichlet Process Mixture Models&rdquo; (MCMC inference)</li>
<li>Blei &amp; Jordan (2006): &ldquo;Variational Inference for Dirichlet Process Mixtures&rdquo; (scalable inference)</li>
</ul>
<h3 id="genjax-documentation">GenJAX Documentation</h3>
<ul>
<li><a href="https://github.com/probcomp/genjax" rel="external" target="_blank">GenJAX GitHub</a> - Official repository</li>
<li><a href="https://www.gen.dev/" rel="external" target="_blank">Probabilistic Programming Examples</a> - Gen.jl (sister project)</li>
</ul>
<hr>

<details open class=" box cstyle notices tip">
  <summary class="box-label" tabindex="-1">
    <i class="fa-fw fas fa-lightbulb"></i> 
    Key Takeaways
  </summary>
  <div class="box-content">
<ol>
<li><strong>DPMM</strong>: Bayesian nonparametric model that learns K automatically</li>
<li><strong>Stick-breaking</strong>: Defines mixing proportions for infinite components</li>
<li><strong>CRP</strong>: Intuitive &ldquo;customers and tables&rdquo; interpretation</li>
<li><strong>Œ±</strong>: Concentration parameter controlling cluster tendency</li>
<li><strong>GenJAX</strong>: Express DPMM as generative model with truncation</li>
<li><strong>Inference</strong>: Importance resampling or MCMC for posterior</li>
</ol>
  </div>
</details>
<hr>
<h2 id="interactive-exploration">Interactive Exploration</h2>
<p>Want to experiment with DPMMs yourself? Try our <strong>interactive Jupyter notebook</strong> that lets you:</p>
<ul>
<li>Adjust the concentration parameter Œ± and see its effect on clustering</li>
<li>Add or remove data points and watch the model adapt</li>
<li>Change the truncation level K_max</li>
<li>Visualize posterior distributions in real-time</li>
</ul>

<details open class=" box cstyle notices " style=";--VARIABLE-BOX-color: success">
  <summary class="box-label" tabindex="-1">
    Try It Yourself!
  </summary>
  <div class="box-content">
<p><strong>üìì <a href="https://colab.research.google.com/github/josephausterweil/probintro/blob/amplify/notebooks/dpmm_interactive.ipynb" rel="external" target="_blank">Open Interactive DPMM Notebook on Google Colab</a></strong></p>
<p>No installation required - runs directly in your browser!</p>
  </div>
</details>
<p>The notebook includes:</p>
<ul>
<li>Complete DPMM implementation with stick-breaking</li>
<li>Interactive widgets for all parameters</li>
<li>Real-time visualization of posteriors</li>
<li>Guided exercises to deepen understanding</li>
</ul>
<p>This is a great way to build intuition for how Œ±, K_max, and the data itself interact to produce the posterior distribution.</p>
<hr>
<h2 id="congratulations">Congratulations!</h2>
<p>You&rsquo;ve completed the tutorial on <strong>Continuous Probability and Bayesian Learning with GenJAX</strong>!</p>
<p>You&rsquo;re now equipped to:</p>
<ul>
<li>Build probabilistic models for continuous data</li>
<li>Perform Bayesian inference and learning</li>
<li>Discover latent structure in data</li>
<li>Use GenJAX for sophisticated probabilistic programming</li>
</ul>
<p><strong>Where to go next</strong>:</p>
<ul>
<li>Explore hierarchical models (Bayesian neural networks, hierarchical Bayes)</li>
<li>Learn advanced inference (Hamiltonian Monte Carlo, variational inference)</li>
<li>Apply to your own data (clustering, time series, causal inference)</li>
</ul>
<p>Happy modeling! üéâ</p>

  <footer class="footline">
  </footer>
</article>
        </div>
      </main>
    </div>
    <aside id="R-sidebar" class="default-animation">
      <div id="R-header-topbar" class="default-animation"></div>
      <div id="R-header-wrapper" class="default-animation">
        <div id="R-header" class="default-animation">
          <a id="R-logo" class="R-default" href="/probintro/index.html">
            <div class="logo-title">Probability &amp; Probabilistic Computing Tutorial</div>
          </a>
        </div>
        <search><form action="/probintro/search/index.html" method="get">
          <div class="searchbox default-animation">
            <button class="search-detail" type="submit" title="Search (CTRL+ALT+f)"><i class="fas fa-search"></i></button>
            <label class="a11y-only" for="R-search-by">Search</label>
            <input data-search-input id="R-search-by" name="search-by" class="search-by" type="search" placeholder="Search...">
            <button class="search-clear" type="button" data-search-clear="" title="Clear search"><i class="fas fa-times" title="Clear search"></i></button>
          </div>
        </form></search>
      </div>
      <div id="R-homelinks" class="default-animation homelinks">
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-homelinks">
          <ul class="space collapsible-menu">
            <li class="" data-nav-id="/probintro/index.html"><a class="padding" href="/probintro/index.html"><i class="fa-fw fas fa-home"></i> Home</a></li>
          </ul>
        </div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-headercontrols">
          <ul class="">
          </ul>
        </div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
      </div>
      <div id="R-content-wrapper" class="highlightable">
        <div class="R-sidebarmenu R-shortcutmenu-main">
          <ul class="enlarge morespace collapsible-menu">
            <li class="alwaysopen " data-nav-id="/probintro/intro/index.html"><a class="padding" href="/probintro/intro/index.html">A Narrative Introduction to Probability</a><ul id="R-subsections-58f2a84c91d5deefe8bdd3a21213404a" class="collapsible-menu"></ul></li>
            <li class="alwaysopen " data-nav-id="/probintro/genjax/index.html"><a class="padding" href="/probintro/genjax/index.html">Probabilistic Programming with GenJAX</a><ul id="R-subsections-40a5f3b764be01351a755ea2f58fc4ae" class="collapsible-menu"></ul></li>
            <li class="parent alwaysopen " data-nav-id="/probintro/intro2/index.html"><a class="padding" href="/probintro/intro2/index.html">Continuous Probability and Bayesian Learning</a><ul id="R-subsections-6e37e5026001eb89123afab26613c1bf" class="collapsible-menu">
            <li class="" data-nav-id="/probintro/intro2/01_mystery_bentos/index.html"><a class="padding" href="/probintro/intro2/01_mystery_bentos/index.html">Chibany&#39;s Mystery Bentos</a></li>
            <li class="" data-nav-id="/probintro/intro2/02_continuous/index.html"><a class="padding" href="/probintro/intro2/02_continuous/index.html">The Continuum: Continuous Probability</a></li>
            <li class="" data-nav-id="/probintro/intro2/03_gaussian/index.html"><a class="padding" href="/probintro/intro2/03_gaussian/index.html">The Gaussian Distribution</a></li>
            <li class="" data-nav-id="/probintro/intro2/04_bayesian_learning/index.html"><a class="padding" href="/probintro/intro2/04_bayesian_learning/index.html">Bayesian Learning with Gaussians</a></li>
            <li class="" data-nav-id="/probintro/intro2/05_mixture_models/index.html"><a class="padding" href="/probintro/intro2/05_mixture_models/index.html">Gaussian Mixture Models</a></li>
            <li class="active " data-nav-id="/probintro/intro2/06_dpmm/index.html"><a class="padding" href="/probintro/intro2/06_dpmm/index.html">Dirichlet Process Mixture Models</a></li></ul></li>
            <li class="" data-nav-id="/probintro/glossary/index.html"><a class="padding" href="/probintro/glossary/index.html">Glossary - All Tutorials</a></li>
          </ul>
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-shortcuts">
          <ul class="space collapsible-menu">
          </ul>
        </div>
        <div id="R-footer-margin"></div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-footercontrols">
          <ul class="">
          </ul>
        </div>
<div id="R-footer"><p>Built with <a href="https://github.com/McShelby/hugo-theme-relearn" title="love"><i class="fas fa-heart"></i></a> by <a href="https://gohugo.io/">Hugo</a></p></div>
      </div>
    </aside>
    <script>
      window.MathJax = Object.assign( window.MathJax || {}, {
        tex: {
          inlineMath:  [['\\(', '\\)'], ['$',  '$']],  
          displayMath: [['\\[', '\\]'], ['$$', '$$']], 
        },
        options: {
          enableMenu: false 
        }
      }, JSON.parse("{}") );
    </script>
    <script id="MathJax-script" async src="/probintro/js/mathjax/tex-mml-chtml.js?1764245646"></script>
    <script src="/probintro/js/clipboard/clipboard.min.js?1764245646" defer></script>
    <script src="/probintro/js/perfect-scrollbar/perfect-scrollbar.min.js?1764245646" defer></script>
    <script src="/probintro/js/theme.js?1764245646" defer></script>
  </body>
</html>
