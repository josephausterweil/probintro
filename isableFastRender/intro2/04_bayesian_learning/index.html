<!DOCTYPE html>
<html lang="en-us" dir="ltr" itemscope itemtype="http://schema.org/Article" data-r-output-format="html">
  <head><script src="/probintro/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=probintro/livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta name="viewport" content="height=device-height, width=device-width, initial-scale=1.0, minimum-scale=1.0">
    <meta name="generator" content="Hugo 0.148.2">
    <meta name="generator" content="Relearn 8.0.0+9803d5122ebb3276acea823f476e9eb44f607862">
    <meta name="description" content="The Learning Problem Chibany has a new challenge. They receive shipments from a new supplier, but don‚Äôt know the mean weight of their tonkatsu bentos. They believe the supplier is trying to hit 500g (like their usual supplier), but they‚Äôre not certain. Maybe the supplier aims for 495g? Or 505g?
The question: How can they learn the true mean weight from observations?
This is Bayesian learning: starting with a prior belief, observing data, and updating to a posterior belief.">
    <meta name="author" content="Joseph Austerweil">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Bayesian Learning with Gaussians :: Probability & Probabilistic Computing Tutorial">
    <meta name="twitter:description" content="The Learning Problem Chibany has a new challenge. They receive shipments from a new supplier, but don‚Äôt know the mean weight of their tonkatsu bentos. They believe the supplier is trying to hit 500g (like their usual supplier), but they‚Äôre not certain. Maybe the supplier aims for 495g? Or 505g?
The question: How can they learn the true mean weight from observations?
This is Bayesian learning: starting with a prior belief, observing data, and updating to a posterior belief.">
    <meta property="og:url" content="http://localhost:1313/probintro/intro2/04_bayesian_learning/index.html">
    <meta property="og:site_name" content="Probability & Probabilistic Computing Tutorial">
    <meta property="og:title" content="Bayesian Learning with Gaussians :: Probability & Probabilistic Computing Tutorial">
    <meta property="og:description" content="The Learning Problem Chibany has a new challenge. They receive shipments from a new supplier, but don‚Äôt know the mean weight of their tonkatsu bentos. They believe the supplier is trying to hit 500g (like their usual supplier), but they‚Äôre not certain. Maybe the supplier aims for 495g? Or 505g?
The question: How can they learn the true mean weight from observations?
This is Bayesian learning: starting with a prior belief, observing data, and updating to a posterior belief.">
    <meta property="og:locale" content="en_us">
    <meta property="og:type" content="article">
    <meta property="article:section" content="Continuous Probability and Bayesian Learning">
    <meta property="article:published_time" content="2025-12-06T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-12-06T00:00:00+00:00">
    <meta itemprop="name" content="Bayesian Learning with Gaussians :: Probability & Probabilistic Computing Tutorial">
    <meta itemprop="description" content="The Learning Problem Chibany has a new challenge. They receive shipments from a new supplier, but don‚Äôt know the mean weight of their tonkatsu bentos. They believe the supplier is trying to hit 500g (like their usual supplier), but they‚Äôre not certain. Maybe the supplier aims for 495g? Or 505g?
The question: How can they learn the true mean weight from observations?
This is Bayesian learning: starting with a prior belief, observing data, and updating to a posterior belief.">
    <meta itemprop="datePublished" content="2025-12-06T00:00:00+00:00">
    <meta itemprop="dateModified" content="2025-12-06T00:00:00+00:00">
    <meta itemprop="wordCount" content="3408">
    <title>Bayesian Learning with Gaussians :: Probability &amp; Probabilistic Computing Tutorial</title>
    <link href="/probintro/images/favicon.png?1765004538" rel="icon" type="image/png">
    <link href="/probintro/css/auto-complete/auto-complete.min.css?1765004538" rel="stylesheet">
    <script src="/probintro/js/auto-complete/auto-complete.min.js?1765004538" defer></script>
    <script src="/probintro/js/search-lunr.js?1765004538" defer></script>
    <script src="/probintro/js/search.js?1765004538" defer></script>
    <script>
      window.relearn = window.relearn || {};
      window.relearn.index_js_url="/probintro/searchindex.en.js?1765004538";
    </script>
    <script src="/probintro/js/lunr/lunr.min.js?1765004538" defer></script>
    <script src="/probintro/js/lunr/lunr.stemmer.support.min.js?1765004538" defer></script>
    <script src="/probintro/js/lunr/lunr.multi.min.js?1765004538" defer></script>
    <script src="/probintro/js/lunr/lunr.en.min.js?1765004538" defer></script>
    <script>
      window.relearn = window.relearn || {};
      window.relearn.contentLangs=['en'];
    </script>
    <link href="/probintro/fonts/fontawesome/css/fontawesome-all.min.css?1765004538" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/probintro/fonts/fontawesome/css/fontawesome-all.min.css?1765004538" rel="stylesheet"></noscript>
    <link href="/probintro/css/perfect-scrollbar/perfect-scrollbar.min.css?1765004538" rel="stylesheet">
    <link href="/probintro/css/theme.css?1765004538" rel="stylesheet">
    <link href="/probintro/css/format-html.css?1765004538" rel="stylesheet" id="R-format-style">
    <script>
      window.relearn = window.relearn || {};
      // configuration
      window.relearn.min = ``;
      window.relearn.path='\/intro2\/04_bayesian_learning\/index.html';
      window.relearn.relBasePath='..\/..';
      window.relearn.relBaseUri='..\/..\/..';
      window.relearn.absBaseUri='http:\/\/localhost:1313\/probintro';
      window.relearn.disableAnchorCopy=false;
      window.relearn.disableAnchorScrolling=false;
      window.relearn.disableInlineCopyToClipboard=false;
      window.relearn.enableBlockCodeWrap=true;
      // legal
      window.relearn.getItem = (s,n) => {return s.getItem(n)};
      window.relearn.setItem = (s,n,v) => {return s.setItem(n,v)};
      window.relearn.removeItem = (s,n) => {return s.removeItem(n)};
      // translations
      window.T_Copy_to_clipboard = `Copy to clipboard`;
      window.T_Copied_to_clipboard = `Copied to clipboard!`;
      window.T_Copy_link_to_clipboard = `Copy link to clipboard`;
      window.T_Link_copied_to_clipboard = `Copied link to clipboard!`;
      window.T_Reset_view = `Reset view`;
      window.T_View_reset = `View reset!`;
      window.T_No_results_found = `No results found for "{0}"`;
      window.T_N_results_found = `{1} results found for "{0}"`;
      // variant stuff
      window.relearn.themevariants = [ 'relearn-dark' ];
      window.relearn.customvariantname = "my-custom-variant";
      window.relearn.changeVariant = function(variant) {
        var oldVariant = document.documentElement.dataset.rThemeVariant;
        window.relearn.setItem(window.localStorage, window.relearn.absBaseUri + "/variant", variant);
        document.documentElement.dataset.rThemeVariant = variant;
        if (oldVariant != variant) {
          document.dispatchEvent( new CustomEvent('themeVariantLoaded', { detail: { variant, oldVariant } }) );
          window.relearn.markVariant();
        }
      }
      window.relearn.markVariant = function() {
        var variant = window.relearn.getItem(window.localStorage, window.relearn.absBaseUri + "/variant");
        document.querySelectorAll(".R-variantswitcher select").forEach((select) => {select.value = variant;});
      }
      window.relearn.initVariant = function() {
        var variant = window.relearn.getItem(window.localStorage, window.relearn.absBaseUri + "/variant") ?? "";
        if( variant == window.relearn.customvariantname ){
        }else if( !variant || !window.relearn.themevariants.includes(variant) ){
          variant = window.relearn.themevariants[0];
          window.relearn.setItem(window.localStorage, window.relearn.absBaseUri + "/variant", variant);
        }
        document.documentElement.dataset.rThemeVariant = variant;
      }
      window.relearn.initVariant();
      window.relearn.markVariant();
    </script>

<link rel="stylesheet" href="/probintro/css/custom.css">

  </head>
  <body class="mobile-support html" data-url="/probintro/intro2/04_bayesian_learning/index.html">
    <div id="R-body" class="default-animation">
      <div id="R-body-overlay"></div>
      <nav id="R-topbar">
        <div class="topbar-wrapper">
          <div class="topbar-sidebar-divider"></div>
          <div class="topbar-area topbar-area-start" data-area="start">
            <div class="topbar-button topbar-button-sidebar" data-content-empty="disable" data-width-s="show" data-width-m="hide" data-width-l="hide"><button class="topbar-control" onclick="toggleNav()" type="button" title="Menu (CTRL&#43;ALT&#43;n)"><i class="fa-fw fas fa-bars"></i></button>
            </div>
            <div class="topbar-button topbar-button-toc" data-content-empty="hide" data-width-s="show" data-width-m="show" data-width-l="show"><button class="topbar-control" onclick="toggleTopbarFlyout(this)" type="button" title="Table of Contents (CTRL&#43;ALT&#43;t)"><i class="fa-fw fas fa-list-alt"></i></button>
              <div class="topbar-content">
                <div class="topbar-content-wrapper">
<nav class="TableOfContents">
  <ul>
    <li><a href="#the-learning-problem">The Learning Problem</a></li>
    <li><a href="#the-setup-unknown-mean-known-variance">The Setup: Unknown Mean, Known Variance</a></li>
    <li><a href="#observing-data">Observing Data</a></li>
    <li><a href="#bayesian-update-the-math">Bayesian Update: The Math</a>
      <ul>
        <li><a href="#the-gaussian-gaussian-conjugate-prior">The Gaussian-Gaussian Conjugate Prior</a></li>
      </ul>
    </li>
    <li><a href="#the-intuition-precision-weighted-average">The Intuition: Precision-Weighted Average</a>
      <ul>
        <li><a href="#in-plain-english">In Plain English</a></li>
      </ul>
    </li>
    <li><a href="#working-through-the-example">Working Through the Example</a></li>
    <li><a href="#implementing-in-genjax">Implementing in GenJAX</a></li>
    <li><a href="#sequential-learning-more-data">Sequential Learning: More Data</a></li>
    <li><a href="#visualizing-the-learning-process">Visualizing the Learning Process</a></li>
    <li><a href="#-exploration-exercise-how-parameters-affect-learning">üî¨ Exploration Exercise: How Parameters Affect Learning</a>
      <ul>
        <li><a href="#interactive-exploration">Interactive Exploration</a></li>
        <li><a href="#assignment-problems">Assignment Problems</a></li>
      </ul>
    </li>
    <li><a href="#the-predictive-distribution">The Predictive Distribution</a>
      <ul>
        <li><a href="#the-math">The Math</a></li>
        <li><a href="#example">Example</a></li>
      </ul>
    </li>
    <li><a href="#implementing-predictive-distribution-in-genjax">Implementing Predictive Distribution in GenJAX</a></li>
    <li><a href="#why-conjugacy-matters">Why Conjugacy Matters</a></li>
    <li><a href="#the-complete-picture-parameters-vs-observations">The Complete Picture: Parameters vs. Observations</a></li>
    <li><a href="#practice-problems">Practice Problems</a>
      <ul>
        <li><a href="#problem-1-new-coffee-shop">Problem 1: New Coffee Shop</a></li>
        <li><a href="#problem-2-learning-from-contradictory-data">Problem 2: Learning from Contradictory Data</a></li>
      </ul>
    </li>
    <li><a href="#-preview-categorization-with-gaussian-mixtures">üéØ Preview: Categorization with Gaussian Mixtures</a>
      <ul>
        <li><a href="#the-categorization-problem">The Categorization Problem</a></li>
        <li><a href="#interactive-exploration-1">Interactive Exploration</a></li>
        <li><a href="#why-this-matters">Why This Matters</a></li>
      </ul>
    </li>
    <li><a href="#whats-next">What&rsquo;s Next?</a></li>
  </ul>
</nav>
                </div>
              </div>
            </div>
          </div>
          <ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype="http://schema.org/BreadcrumbList"><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><a itemprop="item" href="/probintro/index.html"><span itemprop="name">Probability &amp; Probabilistic Computing Tutorial</span></a><meta itemprop="position" content="1">&nbsp;>&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><a itemprop="item" href="/probintro/intro2/index.html"><span itemprop="name">Continuous Probability and Bayesian Learning</span></a><meta itemprop="position" content="2">&nbsp;>&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><span itemprop="name">Bayesian Learning with Gaussians</span><meta itemprop="position" content="3"></li>
          </ol>
          <div class="topbar-area topbar-area-end" data-area="end">
            <div class="topbar-button topbar-button-prev" data-content-empty="disable" data-width-s="show" data-width-m="show" data-width-l="show"><a class="topbar-control" href="/probintro/intro2/03_gaussian/index.html" title="The Gaussian Distribution (ü°ê)"><i class="fa-fw fas fa-chevron-left"></i></a>
            </div>
            <div class="topbar-button topbar-button-next" data-content-empty="disable" data-width-s="show" data-width-m="show" data-width-l="show"><a class="topbar-control" href="/probintro/intro2/05_mixture_models/index.html" title="Gaussian Mixture Models (ü°í)"><i class="fa-fw fas fa-chevron-right"></i></a>
            </div>
            <div class="topbar-button topbar-button-more" data-content-empty="hide" data-width-s="show" data-width-m="show" data-width-l="show"><button class="topbar-control" onclick="toggleTopbarFlyout(this)" type="button" title="More"><i class="fa-fw fas fa-ellipsis-v"></i></button>
              <div class="topbar-content">
                <div class="topbar-content-wrapper">
                  <div class="topbar-area topbar-area-more" data-area="more">
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </nav>
      <div id="R-main-overlay"></div>
      <main id="R-body-inner" class="highlightable intro2" tabindex="-1">
        <div class="flex-block-wrapper">
<article class="default">
  <header class="headline">
  </header>

<h1 id="bayesian-learning-with-gaussians">Bayesian Learning with Gaussians</h1>

<h2 id="the-learning-problem">The Learning Problem</h2>
<p>Chibany has a new challenge. They receive shipments from a new supplier, but don&rsquo;t know the mean weight of their tonkatsu bentos. They believe the supplier is trying to hit 500g (like their usual supplier), but they&rsquo;re not certain. Maybe the supplier aims for 495g? Or 505g?</p>
<p><strong>The question</strong>: How can they learn the true mean weight from observations?</p>
<p>This is <strong>Bayesian learning</strong>: starting with a prior belief, observing data, and updating to a posterior belief.</p>
<hr>
<h2 id="the-setup-unknown-mean-known-variance">The Setup: Unknown Mean, Known Variance</h2>
<p>Let&rsquo;s start simple. Assume:</p>
<ul>
<li>Individual bento weights follow X ~ N(Œº, œÉ¬≤)</li>
<li>We <strong>know</strong> the variance œÉ¬≤ = 4 (std dev = 2g) [consistent precision]</li>
<li>We <strong>don&rsquo;t know</strong> the mean Œº [what we want to learn]</li>
</ul>
<p><strong>Prior belief</strong>: Before seeing any data, Chibany thinks Œº ~ N(500, 25)</p>
<ul>
<li>Their best guess: 500g (the mean of their prior)</li>
<li>Their uncertainty: std dev of 5g (so variance = 25)</li>
</ul>
<p>This says: &ldquo;I think the mean is around 500g, but I&rsquo;m uncertain by about ¬±5g.&rdquo;</p>
<hr>
<h2 id="observing-data">Observing Data</h2>
<p>Chibany weighs the first bento from the new supplier: <strong>x‚ÇÅ = 497g</strong></p>
<p><strong>Key insight</strong>: This single observation contains information about Œº!</p>
<ul>
<li>If Œº were 500g, seeing 497g is reasonably likely (within 1.5œÉ)</li>
<li>If Œº were 510g, seeing 497g would be quite unlikely (6.5œÉ away!)</li>
<li>If Œº were 495g, seeing 497g would be very likely (only 1œÉ away)</li>
</ul>
<p>The observation <strong>shifts</strong> our belief about Œº toward values that make the data more plausible.</p>
<hr>
<h2 id="bayesian-update-the-math">Bayesian Update: The Math</h2>
<p><strong>Bayes&rsquo; Rule</strong> for the unknown parameter:</p>
<p>$$p(\mu | x_1, &hellip;, x_n) = \frac{p(x_1, &hellip;, x_n | \mu) \cdot p(\mu)}{p(x_1, &hellip;, x_n)}$$</p>
<p><strong>In words</strong>:</p>
<ul>
<li><strong>Posterior</strong> ‚àù <strong>Likelihood</strong> √ó <strong>Prior</strong></li>
<li>What we believe after seeing data ‚àù (How likely the data is) √ó (What we believed before)</li>
</ul>

<details open class=" box cstyle notices info">
  <summary class="box-label" tabindex="-1">
    <i class="fa-fw fas fa-info-circle"></i> 
    üìò Foundation Concept: Bayes&rsquo; Rule Extended
  </summary>
  <div class="box-content">
<p><strong>Remember from Tutorial 1, Chapter 5</strong> that Bayes&rsquo; Rule lets us update beliefs with evidence:</p>
<p>$$P(H | E) = \frac{P(E | H) \cdot P(H)}{P(E)}$$</p>
<p>We used it for <strong>discrete events</strong> like &ldquo;Was the taxi blue?&rdquo; given &ldquo;Chibany said it was blue.&rdquo;</p>
<p><strong>Now we&rsquo;re extending it to continuous parameters!</strong></p>
<p><strong>The structure is identical:</strong></p>
<table>
  <thead>
      <tr>
          <th>Tutorial 1 (Discrete)</th>
          <th>Tutorial 3 (Continuous)</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>$P(H \mid E)$ ‚Äî Posterior belief about hypothesis</td>
          <td>$p(\mu \mid x_1, &hellip;, x_n)$ ‚Äî Posterior belief about parameter</td>
      </tr>
      <tr>
          <td>$P(E \mid H)$ ‚Äî Likelihood of evidence given hypothesis</td>
          <td>$p(x_1, &hellip;, x_n \mid \mu)$ ‚Äî Likelihood of data given parameter</td>
      </tr>
      <tr>
          <td>$P(H)$ ‚Äî Prior belief about hypothesis</td>
          <td>$p(\mu)$ ‚Äî Prior belief about parameter</td>
      </tr>
      <tr>
          <td>$P(E)$ ‚Äî Total probability of evidence</td>
          <td>$p(x_1, &hellip;, x_n)$ ‚Äî Total probability of data</td>
      </tr>
  </tbody>
</table>
<p><strong>The logic hasn&rsquo;t changed:</strong></p>
<ul>
<li>Start with prior beliefs (before seeing data)</li>
<li>Update with evidence (likelihood of observations)</li>
<li>Get posterior beliefs (after seeing data)</li>
</ul>
<p><strong>What&rsquo;s new:</strong> Instead of discrete probabilities (0.15, 0.85), we&rsquo;re working with continuous densities (Gaussians). But the <strong>belief-updating principle</strong> is exactly the same!</p>
<p><a href="/probintro/intro/05_bayes/index.html">‚Üê Review Bayes&rsquo; Theorem in Tutorial 1, Chapter 5</a></p>
  </div>
</details>
<h3 id="the-gaussian-gaussian-conjugate-prior">The Gaussian-Gaussian Conjugate Prior</h3>
<p>Here&rsquo;s the magic: <strong>When the prior is Gaussian and the likelihood is Gaussian, the posterior is also Gaussian!</strong></p>
<p>This is called <strong>conjugacy</strong>, and it makes computation elegant.</p>
<p><strong>Prior</strong>: Œº ~ N(Œº‚ÇÄ, œÉ‚ÇÄ¬≤)
<strong>Likelihood</strong>: X | Œº ~ N(Œº, œÉ¬≤) [known œÉ¬≤]</p>
<p><strong>After observing x‚ÇÅ, x‚ÇÇ, &hellip;, x‚Çô:</strong></p>
<p>$$\mu | x_1, &hellip;, x_n \sim N(\mu_n, \sigma_n^2)$$</p>
<p>Where:</p>
<p>$$\mu_n = \frac{\frac{\mu_0}{\sigma_0^2} + \frac{n\bar{x}}{\sigma^2}}{\frac{1}{\sigma_0^2} + \frac{n}{\sigma^2}}$$</p>
<p>$$\frac{1}{\sigma_n^2} = \frac{1}{\sigma_0^2} + \frac{n}{\sigma^2}$$</p>
<p><strong>Don&rsquo;t panic!</strong> GenJAX will handle this. But let&rsquo;s understand the intuition.</p>
<hr>
<h2 id="the-intuition-precision-weighted-average">The Intuition: Precision-Weighted Average</h2>
<p>The posterior mean Œº‚Çô is a <strong>weighted average</strong> of:</p>
<ul>
<li>The prior mean Œº‚ÇÄ</li>
<li>The sample mean $\bar{x}$</li>
</ul>
<p>The weights depend on <strong>precision</strong> (inverse variance):</p>
<ul>
<li>Prior precision: $\frac{1}{\sigma_0^2}$</li>
<li>Data precision: $\frac{n}{\sigma^2}$ (more data = more precision)</li>
</ul>
<h3 id="in-plain-english">In Plain English</h3>
<p>&ldquo;My updated belief is a compromise between what I thought before (prior) and what the data says (sample mean). The more certain I was initially (small œÉ‚ÇÄ¬≤) or the less data I have (small n), the more I stick to my prior. The more data I see (large n) or the less certain I was initially (large œÉ‚ÇÄ¬≤), the more I trust the data.&rdquo;</p>
<hr>
<h2 id="working-through-the-example">Working Through the Example</h2>
<p><strong>Prior</strong>: Œº ~ N(500, 25) [Œº‚ÇÄ = 500, œÉ‚ÇÄ¬≤ = 25]
<strong>Data variance</strong>: œÉ¬≤ = 4
<strong>Observation</strong>: x‚ÇÅ = 497g, so $\bar{x}$ = 497, n = 1</p>
<p><strong>Posterior variance</strong>:
$$\frac{1}{\sigma_1^2} = \frac{1}{25} + \frac{1}{4} = 0.04 + 0.25 = 0.29$$
$$\sigma_1^2 = \frac{1}{0.29} \approx 3.45$$
$$\sigma_1 \approx 1.86$$</p>
<p><strong>Posterior mean</strong>:
$$\mu_1 = \frac{\frac{500}{25} + \frac{1 \cdot 497}{4}}{\frac{1}{25} + \frac{1}{4}} = \frac{20 + 124.25}{0.29} = \frac{144.25}{0.29} \approx 497.4$$</p>
<p><strong>Result</strong>: After seeing 497g, Chibany&rsquo;s belief updates to Œº ~ N(497.4, 3.45)</p>
<p><strong>Interpretation</strong>:</p>
<ul>
<li>His best guess shifted from 500g to 497.4g (moved toward the data)</li>
<li>His uncertainty decreased from œÉ‚ÇÄ = 5g to œÉ‚ÇÅ ‚âà 1.86g (more confident)</li>
</ul>
<hr>
<h2 id="implementing-in-genjax">Implementing in GenJAX</h2>
<p>Let&rsquo;s build a Bayesian learning model:</p>
<div class="highlight wrap-code" dir="auto"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">37
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">38
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">39
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">40
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">41
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">42
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">43
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">44
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">45
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">46
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">47
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">48
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">49
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">50
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">51
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">52
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">53
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">54
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> jax
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> jax.numpy <span style="color:#66d9ef">as</span> jnp
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> genjax <span style="color:#f92672">import</span> gen, simulate, importance_resampling
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> jax.random <span style="color:#66d9ef">as</span> random
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Known parameters</span>
</span></span><span style="display:flex;"><span>DATA_VARIANCE <span style="color:#f92672">=</span> <span style="color:#ae81ff">4.0</span>
</span></span><span style="display:flex;"><span>DATA_STD <span style="color:#f92672">=</span> <span style="color:#ae81ff">2.0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">@gen</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">prior_belief</span>():
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Prior: we think mean is around 500g with uncertainty&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    mu <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">500.0</span>, <span style="color:#ae81ff">5.0</span>) <span style="color:#f92672">@</span> <span style="color:#e6db74">&#34;mu&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> mu
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">@gen</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">generative_model</span>(observations):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Full model: prior + likelihood&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Prior belief about the mean</span>
</span></span><span style="display:flex;"><span>    mu <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">500.0</span>, <span style="color:#ae81ff">5.0</span>) <span style="color:#f92672">@</span> <span style="color:#e6db74">&#34;mu&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Generate each observation from N(mu, 4)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> i, obs <span style="color:#f92672">in</span> enumerate(observations):
</span></span><span style="display:flex;"><span>        weight <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>normal(mu, DATA_STD) <span style="color:#f92672">@</span> <span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;weight_</span><span style="color:#e6db74">{</span>i<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> mu
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Observe one bento: 497g</span>
</span></span><span style="display:flex;"><span>observed_data <span style="color:#f92672">=</span> [<span style="color:#ae81ff">497.0</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Condition the model on the observed data</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> genjax <span style="color:#f92672">import</span> choice_map
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>observations <span style="color:#f92672">=</span> choice_map()
</span></span><span style="display:flex;"><span>observations[<span style="color:#e6db74">&#34;weight_0&#34;</span>] <span style="color:#f92672">=</span> <span style="color:#ae81ff">497.0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Run importance sampling to approximate the posterior</span>
</span></span><span style="display:flex;"><span>key <span style="color:#f92672">=</span> random<span style="color:#f92672">.</span>PRNGKey(<span style="color:#ae81ff">42</span>)
</span></span><span style="display:flex;"><span>num_samples <span style="color:#f92672">=</span> <span style="color:#ae81ff">10000</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Generate traces conditioned on observed data</span>
</span></span><span style="display:flex;"><span>traces <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(num_samples):
</span></span><span style="display:flex;"><span>    key, subkey <span style="color:#f92672">=</span> random<span style="color:#f92672">.</span>split(key)
</span></span><span style="display:flex;"><span>    trace <span style="color:#f92672">=</span> simulate(generative_model, observations)(subkey, observed_data)
</span></span><span style="display:flex;"><span>    traces<span style="color:#f92672">.</span>append(trace)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Extract posterior samples for mu</span>
</span></span><span style="display:flex;"><span>posterior_mu_samples <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>array([trace[<span style="color:#e6db74">&#34;mu&#34;</span>] <span style="color:#66d9ef">for</span> trace <span style="color:#f92672">in</span> traces])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Posterior mean: </span><span style="color:#e6db74">{</span>jnp<span style="color:#f92672">.</span>mean(posterior_mu_samples)<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">g&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Posterior std dev: </span><span style="color:#e6db74">{</span>jnp<span style="color:#f92672">.</span>std(posterior_mu_samples)<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">g&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Theoretical posterior mean: 497.4g&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Theoretical posterior std dev: 1.86g&#34;</span>)</span></span></code></pre></td></tr></table>
</div>
</div>
<p><strong>Note</strong>: The above shows the conceptual structure. In practice, GenJAX&rsquo;s importance sampling might need weight normalization. Let&rsquo;s simplify with a direct analytical update:</p>
<div class="highlight wrap-code" dir="auto"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">37
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">38
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">39
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">40
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">41
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> jax.numpy <span style="color:#66d9ef">as</span> jnp
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">gaussian_gaussian_update</span>(prior_mu, prior_var, data, data_var):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Analytical Bayesian update for Gaussian-Gaussian conjugate prior
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Args:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        prior_mu: Prior mean
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        prior_var: Prior variance
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        data: List of observations
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        data_var: Known data variance
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Returns:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        posterior_mu, posterior_var
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    n <span style="color:#f92672">=</span> len(data)
</span></span><span style="display:flex;"><span>    sample_mean <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>mean(jnp<span style="color:#f92672">.</span>array(data))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Precision-weighted update</span>
</span></span><span style="display:flex;"><span>    prior_precision <span style="color:#f92672">=</span> <span style="color:#ae81ff">1.0</span> <span style="color:#f92672">/</span> prior_var
</span></span><span style="display:flex;"><span>    data_precision <span style="color:#f92672">=</span> n <span style="color:#f92672">/</span> data_var
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    posterior_precision <span style="color:#f92672">=</span> prior_precision <span style="color:#f92672">+</span> data_precision
</span></span><span style="display:flex;"><span>    posterior_var <span style="color:#f92672">=</span> <span style="color:#ae81ff">1.0</span> <span style="color:#f92672">/</span> posterior_precision
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    posterior_mu <span style="color:#f92672">=</span> posterior_var <span style="color:#f92672">*</span> (prior_precision <span style="color:#f92672">*</span> prior_mu <span style="color:#f92672">+</span>
</span></span><span style="display:flex;"><span>                                     data_precision <span style="color:#f92672">*</span> sample_mean)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> posterior_mu, posterior_var
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Apply to our example</span>
</span></span><span style="display:flex;"><span>prior_mu, prior_var <span style="color:#f92672">=</span> <span style="color:#ae81ff">500.0</span>, <span style="color:#ae81ff">25.0</span>
</span></span><span style="display:flex;"><span>data <span style="color:#f92672">=</span> [<span style="color:#ae81ff">497.0</span>]
</span></span><span style="display:flex;"><span>data_var <span style="color:#f92672">=</span> <span style="color:#ae81ff">4.0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>post_mu, post_var <span style="color:#f92672">=</span> gaussian_gaussian_update(prior_mu, prior_var, data, data_var)
</span></span><span style="display:flex;"><span>post_std <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>sqrt(post_var)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;After 1 observation:&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;  Posterior mean: </span><span style="color:#e6db74">{</span>post_mu<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">g&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;  Posterior std dev: </span><span style="color:#e6db74">{</span>post_std<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">g&#34;</span>)</span></span></code></pre></td></tr></table>
</div>
</div>
<p><strong>Output:</strong></p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>After 1 observation:
  Posterior mean: 497.41g
  Posterior std dev: 1.86g</code></pre></div>
<p>Perfect match to our manual calculation!</p>
<hr>
<h2 id="sequential-learning-more-data">Sequential Learning: More Data</h2>
<p>Now Chibany weighs 9 more bentos from the same supplier:</p>
<div class="highlight wrap-code" dir="auto"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Additional observations</span>
</span></span><span style="display:flex;"><span>all_data <span style="color:#f92672">=</span> [<span style="color:#ae81ff">497.0</span>, <span style="color:#ae81ff">498.5</span>, <span style="color:#ae81ff">496.0</span>, <span style="color:#ae81ff">499.0</span>, <span style="color:#ae81ff">497.5</span>, <span style="color:#ae81ff">498.0</span>, <span style="color:#ae81ff">496.5</span>, <span style="color:#ae81ff">497.0</span>, <span style="color:#ae81ff">498.5</span>, <span style="color:#ae81ff">497.5</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Start with prior</span>
</span></span><span style="display:flex;"><span>mu, var <span style="color:#f92672">=</span> <span style="color:#ae81ff">500.0</span>, <span style="color:#ae81ff">25.0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Prior: N(</span><span style="color:#e6db74">{</span>mu<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">, </span><span style="color:#e6db74">{</span>var<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">)&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;  Mean: </span><span style="color:#e6db74">{</span>mu<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">g, Std dev: </span><span style="color:#e6db74">{</span>jnp<span style="color:#f92672">.</span>sqrt(var)<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">g</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Update with each observation sequentially</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i, obs <span style="color:#f92672">in</span> enumerate(all_data, <span style="color:#ae81ff">1</span>):
</span></span><span style="display:flex;"><span>    mu, var <span style="color:#f92672">=</span> gaussian_gaussian_update(mu, var, [obs], data_var)
</span></span><span style="display:flex;"><span>    std <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>sqrt(var)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;After observation </span><span style="color:#e6db74">{</span>i<span style="color:#e6db74">}</span><span style="color:#e6db74"> (x=</span><span style="color:#e6db74">{</span>obs<span style="color:#e6db74">}</span><span style="color:#e6db74">g):&#34;</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;  Posterior: N(</span><span style="color:#e6db74">{</span>mu<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">, </span><span style="color:#e6db74">{</span>var<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">)&#34;</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;  Mean: </span><span style="color:#e6db74">{</span>mu<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">g, Std dev: </span><span style="color:#e6db74">{</span>std<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">g&#34;</span>)</span></span></code></pre></td></tr></table>
</div>
</div>
<p><strong>Output:</strong></p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>Prior: N(500.00, 25.00)
  Mean: 500.00g, Std dev: 5.00g

After observation 1 (x=497.0g):
  Posterior: N(497.41, 3.45)
  Mean: 497.41g, Std dev: 1.86g
After observation 2 (x=498.5g):
  Posterior: N(497.71, 2.11)
  Mean: 497.71g, Std dev: 1.45g
After observation 3 (x=496.0g):
  Posterior: N(497.27, 1.48)
  Mean: 497.27g, Std dev: 1.22g
...
After observation 10 (x=497.5g):
  Posterior: N(497.65, 0.37)
  Mean: 497.65g, Std dev: 0.61g</code></pre></div>
<p><strong>Key observations</strong>:</p>
<ol>
<li>The mean shifts toward the average of the data (~497.6g)</li>
<li>The uncertainty decreases with each observation</li>
<li>After 10 observations, œÉ drops from 5.0g to 0.61g (much more confident!)</li>
</ol>
<hr>
<h2 id="visualizing-the-learning-process">Visualizing the Learning Process</h2>
<div class="highlight wrap-code" dir="auto"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> scipy.stats <span style="color:#f92672">import</span> norm <span style="color:#66d9ef">as</span> scipy_norm
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Prior</span>
</span></span><span style="display:flex;"><span>x_range <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>linspace(<span style="color:#ae81ff">490</span>, <span style="color:#ae81ff">505</span>, <span style="color:#ae81ff">1000</span>)
</span></span><span style="display:flex;"><span>prior_pdf <span style="color:#f92672">=</span> scipy_norm<span style="color:#f92672">.</span>pdf(x_range, <span style="color:#ae81ff">500</span>, <span style="color:#ae81ff">5</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># After 1, 5, and 10 observations</span>
</span></span><span style="display:flex;"><span>results <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>mu, var <span style="color:#f92672">=</span> <span style="color:#ae81ff">500.0</span>, <span style="color:#ae81ff">25.0</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i, obs <span style="color:#f92672">in</span> enumerate(all_data):
</span></span><span style="display:flex;"><span>    mu, var <span style="color:#f92672">=</span> gaussian_gaussian_update(mu, var, [obs], data_var)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> i <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span> <span style="color:#f92672">in</span> [<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">10</span>]:
</span></span><span style="display:flex;"><span>        results<span style="color:#f92672">.</span>append((i <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>, mu, jnp<span style="color:#f92672">.</span>sqrt(var)))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Plot</span></span></span></code></pre></td></tr></table>
</div>
</div>
<details>
<summary>Click to show visualization code</summary>
<div class="highlight wrap-code" dir="auto"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>fig, ax <span style="color:#f92672">=</span> plt<span style="color:#f92672">.</span>subplots(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">12</span>, <span style="color:#ae81ff">6</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ax<span style="color:#f92672">.</span>plot(x_range, prior_pdf, <span style="color:#e6db74">&#39;k--&#39;</span>, linewidth<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Prior: N(500, 25)&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>colors <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;blue&#39;</span>, <span style="color:#e6db74">&#39;green&#39;</span>, <span style="color:#e6db74">&#39;red&#39;</span>]
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> (n_obs, mu, std), color <span style="color:#f92672">in</span> zip(results, colors):
</span></span><span style="display:flex;"><span>    post_pdf <span style="color:#f92672">=</span> scipy_norm<span style="color:#f92672">.</span>pdf(x_range, mu, std)
</span></span><span style="display:flex;"><span>    ax<span style="color:#f92672">.</span>plot(x_range, post_pdf, color<span style="color:#f92672">=</span>color, linewidth<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>,
</span></span><span style="display:flex;"><span>            label<span style="color:#f92672">=</span><span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;After </span><span style="color:#e6db74">{</span>n_obs<span style="color:#e6db74">}</span><span style="color:#e6db74"> obs: N(</span><span style="color:#e6db74">{</span>mu<span style="color:#e6db74">:</span><span style="color:#e6db74">.1f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">, </span><span style="color:#e6db74">{</span>std<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span><span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">)&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Mark the true sample mean</span>
</span></span><span style="display:flex;"><span>sample_mean <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>mean(jnp<span style="color:#f92672">.</span>array(all_data))
</span></span><span style="display:flex;"><span>ax<span style="color:#f92672">.</span>axvline(sample_mean, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;purple&#39;</span>, linestyle<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;:&#39;</span>, linewidth<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>,
</span></span><span style="display:flex;"><span>           label<span style="color:#f92672">=</span><span style="color:#e6db74">f</span><span style="color:#e6db74">&#39;Sample mean: </span><span style="color:#e6db74">{</span>sample_mean<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">g&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>ax<span style="color:#f92672">.</span>set_xlabel(<span style="color:#e6db74">&#39;Mean weight Œº (g)&#39;</span>)
</span></span><span style="display:flex;"><span>ax<span style="color:#f92672">.</span>set_ylabel(<span style="color:#e6db74">&#39;Probability Density&#39;</span>)
</span></span><span style="display:flex;"><span>ax<span style="color:#f92672">.</span>set_title(<span style="color:#e6db74">&#39;Bayesian Learning: Posterior Distribution Updates&#39;</span>)
</span></span><span style="display:flex;"><span>ax<span style="color:#f92672">.</span>legend()
</span></span><span style="display:flex;"><span>ax<span style="color:#f92672">.</span>grid(<span style="color:#66d9ef">True</span>, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.3</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>savefig(<span style="color:#e6db74">&#39;bayesian_learning_posterior.png&#39;</span>, dpi<span style="color:#f92672">=</span><span style="color:#ae81ff">150</span>, bbox_inches<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;tight&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()</span></span></code></pre></td></tr></table>
</div>
</div>
</details>
<p><a href="#R-image-cbe4d67066a9dd3daa69d5fe3639c000" class="lightbox-link"><img alt="Bayesian Learning: Posterior Updates" class="lazy lightbox figure-image" loading="lazy" src="../../images/intro2/posterior_updates.png" style=" height: auto; width: auto;"></a>
<a href="javascript:history.back();" class="lightbox-back" id="R-image-cbe4d67066a9dd3daa69d5fe3639c000"><img alt="Bayesian Learning: Posterior Updates" class="lazy lightbox lightbox-image" loading="lazy" src="../../images/intro2/posterior_updates.png"></a></p>
<p><strong>The story in the plot</strong>:</p>
<ul>
<li><strong>Black dashed</strong>: Prior belief (wide, centered at 500g)</li>
<li><strong>Blue</strong>: After 1 observation (shifted toward data, narrower)</li>
<li><strong>Green</strong>: After 5 observations (closer to sample mean, much narrower)</li>
<li><strong>Red</strong>: After 10 observations (very close to sample mean, very narrow)</li>
<li><strong>Purple dotted</strong>: True sample mean (497.65g)</li>
</ul>
<p>As data accumulates, the posterior converges to the truth!</p>
<hr>
<h2 id="-exploration-exercise-how-parameters-affect-learning">üî¨ Exploration Exercise: How Parameters Affect Learning</h2>
<p>Now that you understand the mechanics of Bayesian updates, let&rsquo;s systematically explore how key parameters affect the learning process:</p>
<ol>
<li><strong>Likelihood variance</strong> (œÉ¬≤_x): How precise are our measurements?</li>
<li><strong>Number of observations</strong> (N): How much data do we have?</li>
</ol>
<h3 id="interactive-exploration">Interactive Exploration</h3>
<p><strong>üìì Open the interactive notebook</strong>: <a href="https://colab.research.google.com/github/josephausterweil/probintro/blob/main/notebooks/gaussian_bayesian_interactive_exploration.ipynb" rel="external" target="_blank">Open in Colab: <code>gaussian_bayesian_interactive_exploration.ipynb</code></a></p>
<p>This notebook provides:</p>
<ul>
<li><strong>Interactive sliders</strong> to adjust parameters in real-time</li>
<li><strong>Visual comparisons</strong> of prior ‚Üí posterior ‚Üí predictive evolution</li>
<li><strong>Sequential learning visualization</strong> showing convergence</li>
<li><strong>GenJAX implementations</strong> for hands-on experience</li>
</ul>
<p><strong>Key questions to explore</strong>:</p>
<ul>
<li>What happens when œÉ¬≤_x is very small (precise measurements) vs. very large (noisy measurements)?</li>
<li>How does the posterior change as N increases from 1 to 10 observations?</li>
<li>When does the data &ldquo;overpower&rdquo; the prior?</li>
<li>Why is the predictive distribution always wider than the posterior?</li>
</ul>
<h3 id="assignment-problems">Assignment Problems</h3>
<p><strong>üìù Work through the detailed solutions</strong>: <a href="https://colab.research.google.com/github/josephausterweil/probintro/blob/main/notebooks/solution_1_gaussian_bayesian_update.ipynb" rel="external" target="_blank">Open in Colab: <code>solution_1_gaussian_bayesian_update.ipynb</code></a></p>
<p>This assignment systematically explores:</p>
<ul>
<li><strong>Part (a)</strong>: Visualizing the prior distribution</li>
<li><strong>Part (b)</strong>: Effect of likelihood variance (œÉ¬≤_x = 0.25 vs. 4)</li>
<li><strong>Part (c)</strong>: Effect of number of observations (N=1 vs. N=5)</li>
<li><strong>GenJAX verification</strong>: Comparing analytical formulas with simulations</li>
</ul>
<p><strong>Learning goals</strong>:</p>
<ul>
<li>Build intuition for precision-weighted averaging</li>
<li>Understand how variance and sample size trade off</li>
<li>See the Law of Large Numbers in action (posterior ‚Üí sample mean as N ‚Üí ‚àû)</li>
<li>Practice translating mathematical formulas into code</li>
</ul>

<details open class=" box cstyle notices " style=";--VARIABLE-BOX-color: success">
  <summary class="box-label" tabindex="-1">
    üí° Why This Matters
  </summary>
  <div class="box-content">
<p>Understanding these parameter effects is crucial for:</p>
<ul>
<li><strong>Experimental design</strong>: How many samples do you need?</li>
<li><strong>Sensor calibration</strong>: How does measurement noise affect inference?</li>
<li><strong>Prior selection</strong>: When does your prior dominate vs. get overwhelmed?</li>
<li><strong>Uncertainty quantification</strong>: How confident should you be in your estimates?</li>
</ul>
<p>These notebooks give you hands-on experience with concepts that appear in every real-world Bayesian application!</p>
  </div>
</details>
<hr>
<h2 id="the-predictive-distribution">The Predictive Distribution</h2>
<p>Chibany now asks: <strong>&ldquo;What weight should I expect for the next bento?&rdquo;</strong></p>
<p>This requires the <strong>posterior predictive distribution</strong>:</p>
<p>$$p(x_{new} | x_1, &hellip;, x_n)$$</p>
<p>&ldquo;What&rsquo;s the probability distribution for a new observation, given what I&rsquo;ve learned?&rdquo;</p>
<h3 id="the-math">The Math</h3>
<p>We integrate over our uncertainty in Œº:</p>
<p>$$p(x_{new} | data) = \int p(x_{new} | \mu) \cdot p(\mu | data) , d\mu$$</p>
<p>For the Gaussian-Gaussian model, this is also Gaussian!</p>
<p>$$X_{new} | data \sim N(\mu_n, \sigma^2 + \sigma_n^2)$$</p>
<p><strong>Key insight</strong>: The predictive variance combines:</p>
<ul>
<li>Data variance œÉ¬≤ (inherent bento variation)</li>
<li>Posterior variance œÉ‚Çô¬≤ (our remaining uncertainty about Œº)</li>
</ul>
<h3 id="example">Example</h3>
<p>After 10 observations, we have posterior N(497.65, 0.37):</p>
<div class="highlight wrap-code" dir="auto"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Posterior from before</span>
</span></span><span style="display:flex;"><span>post_mu <span style="color:#f92672">=</span> <span style="color:#ae81ff">497.65</span>
</span></span><span style="display:flex;"><span>post_var <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.37</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Predictive distribution</span>
</span></span><span style="display:flex;"><span>pred_mu <span style="color:#f92672">=</span> post_mu  <span style="color:#75715e"># Same mean</span>
</span></span><span style="display:flex;"><span>pred_var <span style="color:#f92672">=</span> data_var <span style="color:#f92672">+</span> post_var  <span style="color:#75715e"># 4.0 + 0.37 = 4.37</span>
</span></span><span style="display:flex;"><span>pred_std <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>sqrt(pred_var)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Posterior for Œº: N(</span><span style="color:#e6db74">{</span>post_mu<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">, </span><span style="color:#e6db74">{</span>post_var<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">)&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Predictive for next X: N(</span><span style="color:#e6db74">{</span>pred_mu<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">, </span><span style="color:#e6db74">{</span>pred_var<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">)&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;  Predictive std dev: </span><span style="color:#e6db74">{</span>pred_std<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">g&#34;</span>)</span></span></code></pre></td></tr></table>
</div>
</div>
<p><strong>Output:</strong></p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>Posterior for Œº: N(497.65, 0.37)
Predictive for next X: N(497.65, 4.37)
  Predictive std dev: 2.09g</code></pre></div>
<p><strong>Interpretation</strong>: The next bento will likely weigh around 497.65g ¬± 2.09g.</p>
<hr>
<h2 id="implementing-predictive-distribution-in-genjax">Implementing Predictive Distribution in GenJAX</h2>
<div class="highlight wrap-code" dir="auto"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> genjax <span style="color:#f92672">import</span> gen
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> jax.numpy <span style="color:#66d9ef">as</span> jnp
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> jax.random <span style="color:#66d9ef">as</span> random
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">@gen</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">posterior_predictive</span>(post_mu, post_var, data_var):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Sample from posterior predictive distribution
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># First, sample a Œº from the posterior</span>
</span></span><span style="display:flex;"><span>    mu <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>normal(post_mu, jnp<span style="color:#f92672">.</span>sqrt(post_var)) <span style="color:#f92672">@</span> <span style="color:#e6db74">&#34;mu&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Then, sample a new observation given that Œº</span>
</span></span><span style="display:flex;"><span>    x_new <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>normal(mu, jnp<span style="color:#f92672">.</span>sqrt(data_var)) <span style="color:#f92672">@</span> <span style="color:#e6db74">&#34;x_new&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> x_new
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Simulate 10,000 predictions</span>
</span></span><span style="display:flex;"><span>key <span style="color:#f92672">=</span> random<span style="color:#f92672">.</span>PRNGKey(<span style="color:#ae81ff">42</span>)
</span></span><span style="display:flex;"><span>predictions <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">10000</span>):
</span></span><span style="display:flex;"><span>    key, subkey <span style="color:#f92672">=</span> random<span style="color:#f92672">.</span>split(key)
</span></span><span style="display:flex;"><span>    trace <span style="color:#f92672">=</span> simulate(posterior_predictive)(subkey, post_mu, post_var, data_var)
</span></span><span style="display:flex;"><span>    predictions<span style="color:#f92672">.</span>append(trace<span style="color:#f92672">.</span>get_retval())
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>predictions <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>array(predictions)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Simulated predictive mean: </span><span style="color:#e6db74">{</span>jnp<span style="color:#f92672">.</span>mean(predictions)<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">g&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Simulated predictive std: </span><span style="color:#e6db74">{</span>jnp<span style="color:#f92672">.</span>std(predictions)<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">g&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Theoretical predictive mean: </span><span style="color:#e6db74">{</span>pred_mu<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">g&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Theoretical predictive std: </span><span style="color:#e6db74">{</span>pred_std<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">g&#34;</span>)</span></span></code></pre></td></tr></table>
</div>
</div>
<p><strong>Output:</strong></p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>Simulated predictive mean: 497.63g
Simulated predictive std: 2.08g
Theoretical predictive mean: 497.65g
Theoretical predictive std: 2.09g</code></pre></div>
<p>Perfect match!</p>
<hr>
<h2 id="why-conjugacy-matters">Why Conjugacy Matters</h2>
<p>The Gaussian-Gaussian setup is <strong>conjugate</strong>, meaning:</p>
<ul>
<li>Prior is Gaussian</li>
<li>Likelihood is Gaussian</li>
<li><strong>Posterior is also Gaussian</strong></li>
</ul>
<p>This has huge advantages:</p>
<ol>
<li><strong>Closed-form updates</strong>: No need for complex inference algorithms</li>
<li><strong>Sequential learning</strong>: Update with one observation at a time</li>
<li><strong>Interpretable</strong>: Precision-weighted average has clear meaning</li>
<li><strong>Computationally efficient</strong>: Just update two parameters (Œº‚Çô, œÉ‚Çô¬≤)</li>
</ol>
<p>Not all prior-likelihood pairs are conjugate. When they&rsquo;re not, we need approximation methods (which we&rsquo;ll see in later tutorials).</p>
<hr>
<h2 id="the-complete-picture-parameters-vs-observations">The Complete Picture: Parameters vs. Observations</h2>
<p>It&rsquo;s crucial to distinguish:</p>
<p><strong>Parameters</strong> (unknown, we learn about):</p>
<ul>
<li>Œº (the mean weight the supplier aims for)</li>
<li>Described by posterior distribution after seeing data</li>
</ul>
<p><strong>Observations</strong> (known, we collect):</p>
<ul>
<li>x‚ÇÅ, x‚ÇÇ, &hellip;, x‚Çô (actual bento weights we measure)</li>
<li>Described by likelihood distribution given parameters</li>
</ul>
<p><strong>The Bayesian approach</strong>: Treat unknown parameters as random variables with distributions, then update those distributions with data.</p>
<hr>
<h2 id="practice-problems">Practice Problems</h2>
<h3 id="problem-1-new-coffee-shop">Problem 1: New Coffee Shop</h3>
<p>A new coffee shop claims their espresso shots average 30ml. You believe them but are uncertain. Your prior: Œº ~ N(30, 9) (std dev = 3ml).</p>
<p>You measure 5 shots: [28.5, 29.0, 31.0, 29.5, 30.5] ml.</p>
<p>Known: Each shot has variance 4 (std dev = 2ml).</p>
<p><strong>a)</strong> What&rsquo;s your posterior distribution for Œº after these 5 observations?</p>
<p><strong>b)</strong> What&rsquo;s the 95% credible interval for Œº?</p>
<p><strong>c)</strong> What&rsquo;s the predictive distribution for the next shot?</p>
<details>
<summary>Show Solution</summary>
<div class="highlight wrap-code" dir="auto"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Prior</span>
</span></span><span style="display:flex;"><span>prior_mu, prior_var <span style="color:#f92672">=</span> <span style="color:#ae81ff">30.0</span>, <span style="color:#ae81ff">9.0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Data</span>
</span></span><span style="display:flex;"><span>data <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>array([<span style="color:#ae81ff">28.5</span>, <span style="color:#ae81ff">29.0</span>, <span style="color:#ae81ff">31.0</span>, <span style="color:#ae81ff">29.5</span>, <span style="color:#ae81ff">30.5</span>])
</span></span><span style="display:flex;"><span>data_var <span style="color:#f92672">=</span> <span style="color:#ae81ff">4.0</span>
</span></span><span style="display:flex;"><span>n <span style="color:#f92672">=</span> len(data)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Posterior calculation</span>
</span></span><span style="display:flex;"><span>post_mu, post_var <span style="color:#f92672">=</span> gaussian_gaussian_update(prior_mu, prior_var, data, data_var)
</span></span><span style="display:flex;"><span>post_std <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>sqrt(post_var)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Part a</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;a) Posterior: N(</span><span style="color:#e6db74">{</span>post_mu<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">, </span><span style="color:#e6db74">{</span>post_var<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">)&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;   Mean: </span><span style="color:#e6db74">{</span>post_mu<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">ml, Std dev: </span><span style="color:#e6db74">{</span>post_std<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">ml&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Part b: 95% credible interval (¬±1.96œÉ)</span>
</span></span><span style="display:flex;"><span>lower <span style="color:#f92672">=</span> post_mu <span style="color:#f92672">-</span> <span style="color:#ae81ff">1.96</span> <span style="color:#f92672">*</span> post_std
</span></span><span style="display:flex;"><span>upper <span style="color:#f92672">=</span> post_mu <span style="color:#f92672">+</span> <span style="color:#ae81ff">1.96</span> <span style="color:#f92672">*</span> post_std
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;b) 95% credible interval: [</span><span style="color:#e6db74">{</span>lower<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">, </span><span style="color:#e6db74">{</span>upper<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">] ml&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Part c: Predictive distribution</span>
</span></span><span style="display:flex;"><span>pred_var <span style="color:#f92672">=</span> data_var <span style="color:#f92672">+</span> post_var
</span></span><span style="display:flex;"><span>pred_std <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>sqrt(pred_var)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;c) Predictive: N(</span><span style="color:#e6db74">{</span>post_mu<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">, </span><span style="color:#e6db74">{</span>pred_var<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">)&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;   Mean: </span><span style="color:#e6db74">{</span>post_mu<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">ml, Std dev: </span><span style="color:#e6db74">{</span>pred_std<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">ml&#34;</span>)</span></span></code></pre></td></tr></table>
</div>
</div>
<p><strong>Output:</strong></p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>a) Posterior: N(29.78, 0.67)
   Mean: 29.78ml, Std dev: 0.82ml
b) 95% credible interval: [28.18, 31.38] ml
c) Predictive: N(29.78, 4.67)
   Mean: 29.78ml, Std dev: 2.16ml</code></pre></div>
</details>
<hr>
<h3 id="problem-2-learning-from-contradictory-data">Problem 2: Learning from Contradictory Data</h3>
<p>You have a strong prior belief: Œº ~ N(500, 1) (very confident at 500g).</p>
<p>You observe 3 bentos: [490, 491, 489] (all much lighter!).</p>
<p>Data variance: 4.</p>
<p><strong>a)</strong> What&rsquo;s your posterior?</p>
<p><strong>b)</strong> Why didn&rsquo;t the posterior shift more toward 490g?</p>
<p><strong>c)</strong> How many observations would you need before trusting the data over your prior?</p>
<details>
<summary>Show Solution</summary>
<div class="highlight wrap-code" dir="auto"><div style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">
<table style="border-spacing:0;padding:0;margin:0;border:0;"><tr><td style="vertical-align:top;padding:0;margin:0;border:0;">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 1
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 2
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 3
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 4
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 5
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 6
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 7
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 8
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f"> 9
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">10
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">11
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">12
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">13
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">14
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">15
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">16
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">17
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">18
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">19
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">20
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">21
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">22
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">23
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">24
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">25
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">26
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">27
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">28
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">29
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">30
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">31
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">32
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">33
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">34
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">35
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">36
</span><span style="white-space:pre;-webkit-user-select:none;user-select:none;margin-right:0.4em;padding:0 0.4em 0 0.4em;color:#7f7f7f">37
</span></code></pre></td>
<td style="vertical-align:top;padding:0;margin:0;border:0;;width:100%">
<pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Strong prior</span>
</span></span><span style="display:flex;"><span>prior_mu, prior_var <span style="color:#f92672">=</span> <span style="color:#ae81ff">500.0</span>, <span style="color:#ae81ff">1.0</span>  <span style="color:#75715e"># Very confident!</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Contradictory data</span>
</span></span><span style="display:flex;"><span>data <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>array([<span style="color:#ae81ff">490.0</span>, <span style="color:#ae81ff">491.0</span>, <span style="color:#ae81ff">489.0</span>])
</span></span><span style="display:flex;"><span>data_var <span style="color:#f92672">=</span> <span style="color:#ae81ff">4.0</span>
</span></span><span style="display:flex;"><span>n <span style="color:#f92672">=</span> len(data)
</span></span><span style="display:flex;"><span>sample_mean <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>mean(data)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Posterior</span>
</span></span><span style="display:flex;"><span>post_mu, post_var <span style="color:#f92672">=</span> gaussian_gaussian_update(prior_mu, prior_var, data, data_var)
</span></span><span style="display:flex;"><span>post_std <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>sqrt(post_var)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Part a</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;a) Prior: N(</span><span style="color:#e6db74">{</span>prior_mu<span style="color:#e6db74">:</span><span style="color:#e6db74">.0f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">, </span><span style="color:#e6db74">{</span>prior_var<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">) [very confident]&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;   Sample mean: </span><span style="color:#e6db74">{</span>sample_mean<span style="color:#e6db74">:</span><span style="color:#e6db74">.1f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">g&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;   Posterior: N(</span><span style="color:#e6db74">{</span>post_mu<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">, </span><span style="color:#e6db74">{</span>post_var<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">)&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;   Mean: </span><span style="color:#e6db74">{</span>post_mu<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">g, Std dev: </span><span style="color:#e6db74">{</span>post_std<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">g&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Part b</span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">b) Prior precision: </span><span style="color:#e6db74">{</span><span style="color:#ae81ff">1</span><span style="color:#f92672">/</span>prior_var<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;   Data precision (n=3): </span><span style="color:#e6db74">{</span>n<span style="color:#f92672">/</span>data_var<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;   Prior precision is stronger, so posterior stays near 500g&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Part c: When would data dominate?</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># We want data precision &gt; prior precision</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># n/data_var &gt; 1/prior_var</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># n &gt; data_var/prior_var</span>
</span></span><span style="display:flex;"><span>n_needed <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>ceil(data_var <span style="color:#f92672">/</span> prior_var)<span style="color:#f92672">.</span>astype(int)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">c) Need n &gt; </span><span style="color:#e6db74">{</span>n_needed<span style="color:#e6db74">}</span><span style="color:#e6db74"> observations for data to dominate&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Verify with n=5</span>
</span></span><span style="display:flex;"><span>data_more <span style="color:#f92672">=</span> jnp<span style="color:#f92672">.</span>array([<span style="color:#ae81ff">490.0</span>, <span style="color:#ae81ff">491.0</span>, <span style="color:#ae81ff">489.0</span>, <span style="color:#ae81ff">490.5</span>, <span style="color:#ae81ff">489.5</span>])
</span></span><span style="display:flex;"><span>post_mu_more, post_var_more <span style="color:#f92672">=</span> gaussian_gaussian_update(
</span></span><span style="display:flex;"><span>    prior_mu, prior_var, data_more, data_var
</span></span><span style="display:flex;"><span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;   With n=5: Posterior mean = </span><span style="color:#e6db74">{</span>post_mu_more<span style="color:#e6db74">:</span><span style="color:#e6db74">.2f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">g (shifted more)&#34;</span>)</span></span></code></pre></td></tr></table>
</div>
</div>
<p><strong>Output:</strong></p>
<div class="highlight wrap-code" dir="auto"><pre tabindex="0"><code>a) Prior: N(500, 1.00) [very confident]
   Sample mean: 490.0g
   Posterior: N(496.47, 0.59)
   Mean: 496.47g, Std dev: 0.77g

b) Prior precision: 1.00
   Data precision (n=3): 0.75
   Prior precision is stronger, so posterior stays near 500g

c) Need n &gt; 4 observations for data to dominate
   With n=5: Posterior mean = 493.81g (shifted more)</code></pre></div>
</details>
<hr>
<h2 id="-preview-categorization-with-gaussian-mixtures">üéØ Preview: Categorization with Gaussian Mixtures</h2>
<p>We&rsquo;ve learned how to update beliefs about a <strong>single Gaussian</strong>. But remember Chibany&rsquo;s mystery bentos from Chapter 1? They came from a <strong>mixture</strong> of two types (tonkatsu and hamburger).</p>
<h3 id="the-categorization-problem">The Categorization Problem</h3>
<p>Imagine Chibany receives an opaque bento weighing 425g. Which type is it?</p>
<ul>
<li><strong>Tonkatsu bentos</strong>: Weights ~ N(500, 100)</li>
<li><strong>Hamburger bentos</strong>: Weights ~ N(350, 100)</li>
<li><strong>Prior belief</strong>: 70% tonkatsu, 30% hamburger</li>
</ul>
<p>This is a <strong>mixture model</strong> problem where we need to:</p>
<ol>
<li><strong>Infer category</strong> given observed weight: P(category | weight)</li>
<li><strong>Use Bayes&rsquo; rule</strong> with continuous likelihoods</li>
<li><strong>Understand decision boundaries</strong>: Where does P(tonkatsu | x) = 0.5?</li>
</ol>
<h3 id="interactive-exploration-1">Interactive Exploration</h3>
<p><strong>üìì Explore mixture models</strong>: <a href="https://colab.research.google.com/github/josephausterweil/probintro/blob/main/notebooks/gaussian_bayesian_interactive_exploration.ipynb" rel="external" target="_blank">Open in Colab: <code>gaussian_bayesian_interactive_exploration.ipynb</code></a> (Part 2)</p>
<p>This section provides:</p>
<ul>
<li><strong>Interactive categorization</strong>: See how P(c=1|x) changes with x</li>
<li><strong>Effect of priors</strong>: How does Œ∏ (prior probability) shift decision boundaries?</li>
<li><strong>Effect of variance</strong>: What happens when categories have different spreads?</li>
<li><strong>Marginal distribution</strong>: Visualize the weighted mixture p(x)</li>
</ul>
<p><strong>üìù Detailed solutions</strong>: <a href="https://colab.research.google.com/github/josephausterweil/probintro/blob/main/notebooks/solution_2_gaussian_clusters.ipynb" rel="external" target="_blank">Open in Colab: <code>solution_2_gaussian_clusters.ipynb</code></a></p>
<p>This assignment covers:</p>
<ul>
<li><strong>Part (a)</strong>: Deriving P(c=1|x) using Bayes&rsquo; rule</li>
<li><strong>Part (b)</strong>: How priors and variances affect categorization</li>
<li><strong>Part (c)</strong>: Deriving the marginal distribution p(x)</li>
<li><strong>Part (d)</strong>: Understanding bimodal vs. unimodal mixtures</li>
</ul>

<details open class=" box cstyle notices info">
  <summary class="box-label" tabindex="-1">
    <i class="fa-fw fas fa-info-circle"></i> 
    üîó Connecting the Concepts
  </summary>
  <div class="box-content">
<p><strong>From Chapter 1</strong>: We computed E[X] for discrete mixtures (70% √ó 500g + 30% √ó 350g)</p>
<p><strong>Now</strong>: We&rsquo;re computing P(category | observation) for continuous mixtures!</p>
<p><strong>The progression</strong>:</p>
<ol>
<li><strong>Chapter 1</strong>: Discrete mixture, known categories ‚Üí compute expected value</li>
<li><strong>Chapter 4 (this chapter)</strong>: Single Gaussian ‚Üí learn parameters from data</li>
<li><strong>Preview (Problem 2)</strong>: Known mixture parameters ‚Üí infer hidden category</li>
<li><strong>Chapter 5</strong> (coming): Unknown mixture parameters ‚Üí learn everything!</li>
</ol>
<p>This preview problem bridges single-component learning to full mixture model inference.</p>
  </div>
</details>
<h3 id="why-this-matters">Why This Matters</h3>
<p>Mixture models appear everywhere:</p>
<ul>
<li><strong>Biology</strong>: Classifying cell types from measurements</li>
<li><strong>Finance</strong>: Identifying market regimes (bull vs. bear)</li>
<li><strong>Computer Vision</strong>: Segmenting images by color clusters</li>
<li><strong>Natural Language</strong>: Topic modeling in documents</li>
</ul>
<p>Understanding categorization with Gaussians is the foundation for clustering, classification, and unsupervised learning!</p>
<hr>
<h2 id="whats-next">What&rsquo;s Next?</h2>
<p>We now understand:</p>
<ul>
<li>Bayesian learning with conjugate priors</li>
<li>How to update beliefs as data arrives</li>
<li>The posterior predictive distribution</li>
<li>Why conjugacy makes computation elegant</li>
<li><strong>Preview</strong>: How to categorize observations in mixture models</li>
</ul>
<p>But we&rsquo;ve only learned about <strong>one component</strong> (a single Gaussian) OR <strong>known mixture parameters</strong>. What if we have <strong>multiple components with unknown parameters</strong>?</p>
<p>In Chapter 5, we&rsquo;ll tackle the full problem: learning which bentos are tonkatsu vs. hamburger AND learning the mean weight of each type simultaneously!</p>
<hr>

<details open class=" box cstyle notices tip">
  <summary class="box-label" tabindex="-1">
    <i class="fa-fw fas fa-lightbulb"></i> 
    Key Takeaways
  </summary>
  <div class="box-content">
<ol>
<li><strong>Bayesian learning</strong>: Start with prior ‚Üí observe data ‚Üí update to posterior</li>
<li><strong>Conjugacy</strong>: Gaussian prior + Gaussian likelihood = Gaussian posterior</li>
<li><strong>Precision weighting</strong>: Posterior is weighted average of prior and data</li>
<li><strong>Sequential learning</strong>: Update one observation at a time</li>
<li><strong>Predictive distribution</strong>: Combines posterior uncertainty + data variance</li>
<li><strong>GenJAX</strong>: Implement with analytical updates or importance sampling</li>
</ol>
  </div>
</details>
<hr>
<p><strong>Next Chapter</strong>: <a href="/probintro/intro2/05_mixture_models/index.html">Gaussian Mixture Models ‚Üí</a></p>

  <footer class="footline">
              <i class='fa-fw fas fa-calendar'></i> Dec 6, 2025
  </footer>
</article>
        </div>
      </main>
    </div>
    <aside id="R-sidebar" class="default-animation">
      <div id="R-header-topbar" class="default-animation"></div>
      <div id="R-header-wrapper" class="default-animation">
        <div id="R-header" class="default-animation">
          <a id="R-logo" class="R-default" href="/probintro/index.html">
            <div class="logo-title">Probability &amp; Probabilistic Computing Tutorial</div>
          </a>
        </div>
        <search><form action="/probintro/search/index.html" method="get">
          <div class="searchbox default-animation">
            <button class="search-detail" type="submit" title="Search (CTRL+ALT+f)"><i class="fas fa-search"></i></button>
            <label class="a11y-only" for="R-search-by">Search</label>
            <input data-search-input id="R-search-by" name="search-by" class="search-by" type="search" placeholder="Search...">
            <button class="search-clear" type="button" data-search-clear="" title="Clear search"><i class="fas fa-times" title="Clear search"></i></button>
          </div>
        </form></search>
      </div>
      <div id="R-homelinks" class="default-animation homelinks">
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-homelinks">
          <ul class="space collapsible-menu">
            <li class="" data-nav-id="/probintro/index.html"><a class="padding" href="/probintro/index.html"><i class="fa-fw fas fa-home"></i> Home</a></li>
          </ul>
        </div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-headercontrols">
          <ul class="">
          </ul>
        </div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
      </div>
      <div id="R-content-wrapper" class="highlightable">
        <div class="R-sidebarmenu R-shortcutmenu-main">
          <ul class="enlarge morespace collapsible-menu">
            <li class="alwaysopen " data-nav-id="/probintro/intro/index.html"><a class="padding" href="/probintro/intro/index.html">A Narrative Introduction to Probability</a><ul id="R-subsections-58f2a84c91d5deefe8bdd3a21213404a" class="collapsible-menu"></ul></li>
            <li class="alwaysopen " data-nav-id="/probintro/genjax/index.html"><a class="padding" href="/probintro/genjax/index.html">Probabilistic Programming with GenJAX</a><ul id="R-subsections-40a5f3b764be01351a755ea2f58fc4ae" class="collapsible-menu"></ul></li>
            <li class="parent alwaysopen " data-nav-id="/probintro/intro2/index.html"><a class="padding" href="/probintro/intro2/index.html">Continuous Probability and Bayesian Learning</a><ul id="R-subsections-6e37e5026001eb89123afab26613c1bf" class="collapsible-menu">
            <li class="" data-nav-id="/probintro/intro2/01_mystery_bentos/index.html"><a class="padding" href="/probintro/intro2/01_mystery_bentos/index.html">Chibany&#39;s Mystery Bentos</a></li>
            <li class="" data-nav-id="/probintro/intro2/02_continuous/index.html"><a class="padding" href="/probintro/intro2/02_continuous/index.html">The Continuum: Continuous Probability</a></li>
            <li class="" data-nav-id="/probintro/intro2/03_gaussian/index.html"><a class="padding" href="/probintro/intro2/03_gaussian/index.html">The Gaussian Distribution</a></li>
            <li class="active " data-nav-id="/probintro/intro2/04_bayesian_learning/index.html"><a class="padding" href="/probintro/intro2/04_bayesian_learning/index.html">Bayesian Learning with Gaussians</a></li>
            <li class="" data-nav-id="/probintro/intro2/05_mixture_models/index.html"><a class="padding" href="/probintro/intro2/05_mixture_models/index.html">Gaussian Mixture Models</a></li>
            <li class="" data-nav-id="/probintro/intro2/06_dpmm/index.html"><a class="padding" href="/probintro/intro2/06_dpmm/index.html">Dirichlet Process Mixture Models</a></li></ul></li>
            <li class="" data-nav-id="/probintro/notebook_guide/index.html"><a class="padding" href="/probintro/notebook_guide/index.html">Interactive Notebooks - All Tutorials</a></li>
            <li class="" data-nav-id="/probintro/glossary/index.html"><a class="padding" href="/probintro/glossary/index.html">Glossary - All Tutorials</a></li>
          </ul>
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-shortcuts">
          <ul class="space collapsible-menu">
          </ul>
        </div>
        <div id="R-footer-margin"></div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-footercontrols">
          <ul class="">
          </ul>
        </div>
<div id="R-footer"><p>Built with <a href="https://github.com/McShelby/hugo-theme-relearn" title="love"><i class="fas fa-heart"></i></a> by <a href="https://gohugo.io/">Hugo</a></p></div>
      </div>
    </aside>
    <script>
      window.MathJax = Object.assign( window.MathJax || {}, {
        tex: {
          inlineMath:  [['\\(', '\\)'], ['$',  '$']],  
          displayMath: [['\\[', '\\]'], ['$$', '$$']], 
        },
        options: {
          enableMenu: false 
        }
      }, JSON.parse("{}") );
    </script>
    <script id="MathJax-script" async src="/probintro/js/mathjax/tex-mml-chtml.js?1765004538"></script>
    <script src="/probintro/js/clipboard/clipboard.min.js?1765004538" defer></script>
    <script src="/probintro/js/perfect-scrollbar/perfect-scrollbar.min.js?1765004538" defer></script>
    <script src="/probintro/js/theme.js?1765004538" defer></script>
  </body>
</html>
