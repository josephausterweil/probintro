{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Probability: Learning from Evidence\n",
    "\n",
    "**What changes when you learn something new?**\n",
    "\n",
    "This interactive notebook explores conditional probability through Chibany's meals!\n",
    "\n",
    "**You'll discover:**\n",
    "- ðŸ” How observations change probabilities\n",
    "- ðŸŽ¯ Three ways to compute P(A|B)\n",
    "- ðŸ“Š Visualizing how evidence restricts possibilities\n",
    "- ðŸŽ® Interactive exploration of conditioning\n",
    "\n",
    "**Get ready for some \"aha!\" moments!** ðŸ’¡\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš€ Setup\n",
    "\n",
    "First, let's install and load everything we need.\n",
    "\n",
    "**Note**: After running the installation cell below, you may need to restart the runtime (Runtime â†’ Restart runtime) before proceeding with the rest of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install genjax ipywidgets matplotlib seaborn -q\n",
    "\n",
    "print(\"âœ… Installation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Ready to explore conditional probability!\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from genjax import gen, flip, ChoiceMap, Target\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import numpy as np\n",
    "\n",
    "jax.config.update('jax_enable_x64', True)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(\"âœ… Ready to explore conditional probability!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ± The Model: Chibany's Meals\n",
    "\n",
    "Same model as before, but now we'll **condition** on observations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model defined!\n"
     ]
    }
   ],
   "source": [
    "@gen\n",
    "def chibany_day(lunch_prob=0.5, dinner_prob=0.5):\n",
    "    \"\"\"Simulate Chibany's meals for one day.\"\"\"\n",
    "    lunch = flip(lunch_prob) @ \"lunch\"\n",
    "    dinner = flip(dinner_prob) @ \"dinner\"\n",
    "    return (lunch, dinner)\n",
    "\n",
    "MEAL_NAMES = {0: \"Hamburger\", 1: \"Tonkatsu\"}\n",
    "OUTCOME_NAMES = {\n",
    "    (0, 0): \"HH\", (0, 1): \"HT\",\n",
    "    (1, 0): \"TH\", (1, 1): \"TT\"\n",
    "}\n",
    "\n",
    "print(\"âœ… Model defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“š The Question\n",
    "\n",
    "**Scenario**: You observe that Chibany got **Tonkatsu for dinner**.\n",
    "\n",
    "**Question**: What's the probability he also got **Tonkatsu for lunch**?\n",
    "\n",
    "Mathematically: $P(\\text{lunch}=T \\mid \\text{dinner}=T) = ?$\n",
    "\n",
    "Let's calculate this **three different ways** and see they all give the same answer!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Method 1: Filtering Simulations\n",
    "\n",
    "**Idea**: Generate many days, keep only those where dinner=T, count how many have lunch=T.\n",
    "\n",
    "This is like **crossing out** outcomes that don't match the evidence!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Method 1: Filtering Simulations\n",
      "==================================================\n",
      "Total simulations: 10,000\n",
      "Days with dinner=T: 4,987\n",
      "Days with both=T: 2,484\n",
      "\n",
      "P(lunch=T | dinner=T) = 2484/4987 = 0.4981\n",
      "\n",
      "ðŸ’¡ About 50%! Makes sense: lunch and dinner are independent.\n"
     ]
    }
   ],
   "source": [
    "# Generate 10,000 days\n",
    "n_sims = 10000\n",
    "key = jax.random.key(42)\n",
    "keys = jax.random.split(key, n_sims)\n",
    "\n",
    "def run_day(k):\n",
    "    trace = chibany_day.simulate(k, (0.5, 0.5))\n",
    "    return trace.get_retval()\n",
    "\n",
    "days = jax.vmap(run_day)(keys)\n",
    "lunch_results, dinner_results = days\n",
    "\n",
    "# Filter: Keep only days where dinner=T\n",
    "dinner_is_T = (dinner_results == 1)\n",
    "n_dinner_T = jnp.sum(dinner_is_T)\n",
    "\n",
    "# Among those, count lunch=T\n",
    "both_T = jnp.logical_and(lunch_results == 1, dinner_results == 1)\n",
    "n_both_T = jnp.sum(both_T)\n",
    "\n",
    "# Calculate conditional probability\n",
    "prob_lunch_T_given_dinner_T = n_both_T / n_dinner_T\n",
    "\n",
    "print(\"ðŸ“Š Method 1: Filtering Simulations\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total simulations: {n_sims:,}\")\n",
    "print(f\"Days with dinner=T: {int(n_dinner_T):,}\")\n",
    "print(f\"Days with both=T: {int(n_both_T):,}\")\n",
    "print(f\"\\nP(lunch=T | dinner=T) = {int(n_both_T)}/{int(n_dinner_T)} = {prob_lunch_T_given_dinner_T:.4f}\")\n",
    "print(\"\\nðŸ’¡ About 50%! Makes sense: lunch and dinner are independent.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ðŸŽ¯ Method 2: Using Conditional Sampling (Alternative Approach)\n\n**Note**: The GenJAX API for direct conditioning with ChoiceMap has changed significantly. For this tutorial, we'll use the filtering method (Method 1) as the primary approach, which is conceptually clearer anyway!\n\nIf you're interested in advanced GenJAX conditioning patterns, see the DPMM notebook which uses the `Target` API for more complex inference scenarios."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create observation: dinner=T\nobservation = ChoiceMap.d({\"dinner\": 1})\n\n# Generate samples conditional on observation\nn_samples = 10000\nkey = jax.random.key(42)\nkeys = jax.random.split(key, n_samples)\n\ndef sample_conditional(k):\n    trace, weight = chibany_day.generate(k, observation, (0.5, 0.5))\n    meals = trace.get_retval()\n    return meals[0]  # Return lunch value (keep as JAX array)\n\nlunch_samples = jax.vmap(sample_conditional)(keys)\nprob_conditional = jnp.mean(lunch_samples)\n\nprint(\"ðŸ“Š Method 2: Using ChoiceMap\")\nprint(\"=\" * 50)\nprint(f\"Observation: dinner = Tonkatsu\")\nprint(f\"Generated {n_samples:,} conditional samples\")\nprint(f\"\\nP(lunch=T | dinner=T) = {prob_conditional:.4f}\")\nprint(\"\\nðŸ’¡ Same answer! Different method, same math.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Method 3: Direct Formula\n",
    "\n",
    "**Idea**: Use the mathematical definition:\n",
    "\n",
    "$$P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}$$\n",
    "\n",
    "For independent events (like lunch and dinner):\n",
    "\n",
    "$$P(\\text{lunch}=T \\mid \\text{dinner}=T) = \\frac{P(\\text{both}=T)}{P(\\text{dinner}=T)} = \\frac{0.5 \\times 0.5}{0.5} = 0.5$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate using formula\n",
    "P_lunch_T = 0.5\n",
    "P_dinner_T = 0.5\n",
    "P_both_T = P_lunch_T * P_dinner_T  # Independent!\n",
    "\n",
    "P_lunch_T_given_dinner_T = P_both_T / P_dinner_T\n",
    "\n",
    "print(\"ðŸ“Š Method 3: Mathematical Formula\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"P(lunch=T) = {P_lunch_T}\")\n",
    "print(f\"P(dinner=T) = {P_dinner_T}\")\n",
    "print(f\"P(both=T) = {P_both_T} (independent!)\")\n",
    "print(f\"\\nP(lunch=T | dinner=T) = {P_both_T}/{P_dinner_T} = {P_lunch_T_given_dinner_T:.4f}\")\n",
    "print(\"\\nðŸ’¡ All three methods agree!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ® Interactive Exploration!\n",
    "\n",
    "Now let's explore **dependent** events! What if getting tonkatsu for lunch makes you more likely to get it for dinner?\n",
    "\n",
    "**Try these scenarios:**\n",
    "1. **Independent**: Both probs = 0.50, Dinner given Lunch = 0.50\n",
    "2. **Positive correlation**: If lunch=T, dinner=T more likely (0.80)\n",
    "3. **Negative correlation**: If lunch=T, dinner=T less likely (0.20)\n",
    "4. **Strong dependence**: If lunch=T, dinner=T almost certain (0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create dependent model\n@gen\ndef chibany_dependent(lunch_prob, dinner_if_lunch_H, dinner_if_lunch_T):\n    \"\"\"Model where dinner depends on lunch.\"\"\"\n    lunch = flip(lunch_prob) @ \"lunch\"\n    \n    # Dinner probability depends on lunch!\n    # Use jnp.where instead of if/else for JAX compatibility\n    dinner_prob = jnp.where(lunch == 1, dinner_if_lunch_T, dinner_if_lunch_H)\n    dinner = flip(dinner_prob) @ \"dinner\"\n    \n    return (lunch, dinner)\n\n# Create controls\nlunch_prob_slider = widgets.FloatSlider(\n    value=0.5, min=0.0, max=1.0, step=0.05,\n    description='P(Lunch=T):',\n    style={'description_width': '140px'}\n)\n\ndinner_H_slider = widgets.FloatSlider(\n    value=0.5, min=0.0, max=1.0, step=0.05,\n    description='P(Dinner=T | Lunch=H):',\n    style={'description_width': '140px'}\n)\n\ndinner_T_slider = widgets.FloatSlider(\n    value=0.5, min=0.0, max=1.0, step=0.05,\n    description='P(Dinner=T | Lunch=T):',\n    style={'description_width': '140px'}\n)\n\noutput_widget = widgets.Output()\n\ndef explore_conditioning(lunch_prob, dinner_H, dinner_T):\n    \"\"\"Explore conditional probabilities with dependent events.\"\"\"\n    with output_widget:\n        clear_output(wait=True)\n        \n        # Convert to Python floats to avoid formatting issues\n        lunch_prob = float(lunch_prob)\n        dinner_H = float(dinner_H)\n        dinner_T = float(dinner_T)\n        \n        n_sims = 10000\n        key = jax.random.key(42)\n        keys = jax.random.split(key, n_sims)\n        \n        # Simulate\n        def run_day(k):\n            trace = chibany_dependent.simulate(k, (lunch_prob, dinner_H, dinner_T))\n            return trace.get_retval()\n        \n        days = jax.vmap(run_day)(keys)\n        lunch_results, dinner_results = days\n        \n        # Calculate conditional probabilities\n        # P(Dinner=T | Lunch=T)\n        lunch_T = (lunch_results == 1)\n        both_T = jnp.logical_and(lunch_T, dinner_results == 1)\n        p_dinner_T_given_lunch_T = jnp.sum(both_T) / jnp.sum(lunch_T) if jnp.sum(lunch_T) > 0 else 0\n        \n        # P(Dinner=T | Lunch=H)\n        lunch_H = (lunch_results == 0)\n        lunch_H_dinner_T = jnp.logical_and(lunch_H, dinner_results == 1)\n        p_dinner_T_given_lunch_H = jnp.sum(lunch_H_dinner_T) / jnp.sum(lunch_H) if jnp.sum(lunch_H) > 0 else 0\n        \n        # P(Lunch=T | Dinner=T) - Reverse direction!\n        dinner_T_mask = (dinner_results == 1)\n        p_lunch_T_given_dinner_T = jnp.sum(both_T) / jnp.sum(dinner_T_mask) if jnp.sum(dinner_T_mask) > 0 else 0\n        \n        # Create visualization\n        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n        \n        # Bar chart: Joint distribution\n        counts = {\n            'HH': int(jnp.sum((lunch_results == 0) & (dinner_results == 0))),\n            'HT': int(jnp.sum((lunch_results == 0) & (dinner_results == 1))),\n            'TH': int(jnp.sum((lunch_results == 1) & (dinner_results == 0))),\n            'TT': int(jnp.sum((lunch_results == 1) & (dinner_results == 1)))\n        }\n        \n        colors = ['#95a5a6' if outcome[0] == 'H' and outcome[1] == 'H' else\n                 '#3498db' if outcome[1] == 'T' else\n                 '#e74c3c' for outcome in counts.keys()]\n        \n        ax1.bar(counts.keys(), counts.values(), color=colors, alpha=0.7, edgecolor='black')\n        ax1.set_xlabel('Outcome', fontsize=12, fontweight='bold')\n        ax1.set_ylabel('Count', fontsize=12, fontweight='bold')\n        ax1.set_title(f'Joint Distribution ({n_sims:,} simulations)', fontsize=13, fontweight='bold')\n        ax1.grid(axis='y', alpha=0.3)\n        \n        # Add count labels\n        for i, (outcome, count) in enumerate(counts.items()):\n            ax1.text(i, count, str(count), ha='center', va='bottom', fontweight='bold')\n        \n        # Conditional probability comparison\n        conditions = ['P(D=T|L=H)', 'P(D=T|L=T)', 'P(L=T|D=T)']\n        observed = [\n            float(p_dinner_T_given_lunch_H),\n            float(p_dinner_T_given_lunch_T),\n            float(p_lunch_T_given_dinner_T)\n        ]\n        theoretical = [dinner_H, dinner_T, None]  # Last one calculated from Bayes'\n        \n        x = range(len(conditions))\n        ax2.bar(x, observed, color=['#9b59b6', '#e74c3c', '#2ecc71'], alpha=0.7, edgecolor='black')\n        ax2.set_xticks(x)\n        ax2.set_xticklabels(conditions, fontsize=10)\n        ax2.set_ylabel('Probability', fontsize=12, fontweight='bold')\n        ax2.set_title('Conditional Probabilities', fontsize=13, fontweight='bold')\n        ax2.set_ylim([0, 1])\n        ax2.grid(axis='y', alpha=0.3)\n        \n        # Add value labels\n        for i, val in enumerate(observed):\n            ax2.text(i, val + 0.02, f'{val:.3f}', ha='center', fontweight='bold')\n        \n        plt.tight_layout()\n        plt.show()\n        \n        # Print results\n        print(\"ðŸ“Š Conditional Probability Results:\")\n        print(\"=\" * 60)\n        print(f\"P(Dinner=T | Lunch=H) = {p_dinner_T_given_lunch_H:.4f} (Theory: {dinner_H:.4f})\")\n        print(f\"P(Dinner=T | Lunch=T) = {p_dinner_T_given_lunch_T:.4f} (Theory: {dinner_T:.4f})\")\n        print(f\"P(Lunch=T | Dinner=T)  = {p_lunch_T_given_dinner_T:.4f}\")\n        \n        # Check independence\n        if abs(dinner_H - dinner_T) < 0.01:\n            print(\"\\nðŸ’¡ Lunch and dinner are INDEPENDENT!\")\n            print(\"   Learning lunch doesn't change dinner probability.\")\n        elif dinner_T > dinner_H:\n            print(\"\\nðŸ“ˆ POSITIVE correlation: Tonkatsu for lunch â†’ more likely for dinner\")\n            print(f\"   {dinner_T:.0%} vs {dinner_H:.0%}\")\n        else:\n            print(\"\\nðŸ“‰ NEGATIVE correlation: Tonkatsu for lunch â†’ less likely for dinner\")\n            print(f\"   {dinner_T:.0%} vs {dinner_H:.0%}\")\n\n# Create interactive widget\ninteractive_cond = widgets.interactive(\n    explore_conditioning,\n    lunch_prob=lunch_prob_slider,\n    dinner_H=dinner_H_slider,\n    dinner_T=dinner_T_slider\n)\n\ndisplay(interactive_cond)\ndisplay(output_widget)\n\n# Run initial\nexplore_conditioning(0.5, 0.5, 0.5)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§® Exercise: Bayes' Rule!\n",
    "\n",
    "**Challenge**: Using the simulations above, verify Bayes' rule:\n",
    "\n",
    "$$P(\\text{Lunch}=T \\mid \\text{Dinner}=T) = \\frac{P(\\text{Dinner}=T \\mid \\text{Lunch}=T) \\cdot P(\\text{Lunch}=T)}{P(\\text{Dinner}=T)}$$\n",
    "\n",
    "Calculate each component and verify the formula!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "lunch_prob = 0.6\n",
    "dinner_H = 0.3\n",
    "dinner_T = 0.8\n",
    "\n",
    "# Simulate\n",
    "n_sims = 10000\n",
    "key = jax.random.key(42)\n",
    "keys = jax.random.split(key, n_sims)\n",
    "\n",
    "days = jax.vmap(lambda k: chibany_dependent.simulate(k, (lunch_prob, dinner_H, dinner_T)).get_retval())(keys)\n",
    "lunch_results, dinner_results = days\n",
    "\n",
    "# Calculate components of Bayes' rule\n",
    "# TODO: Calculate these from the simulation:\n",
    "# P_lunch_T = ...\n",
    "# P_dinner_T = ...\n",
    "# P_dinner_T_given_lunch_T = ...\n",
    "# P_lunch_T_given_dinner_T = ...\n",
    "\n",
    "# Verify Bayes' rule\n",
    "# bayes_left = P_lunch_T_given_dinner_T\n",
    "# bayes_right = (P_dinner_T_given_lunch_T * P_lunch_T) / P_dinner_T\n",
    "\n",
    "# print(f\"Left side:  {bayes_left:.4f}\")\n",
    "# print(f\"Right side: {bayes_right:.4f}\")\n",
    "# print(f\"Difference: {abs(bayes_left - bayes_right):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>ðŸ’¡ Click to see solution</b></summary>\n",
    "\n",
    "```python\n",
    "# Calculate components\n",
    "P_lunch_T = jnp.mean(lunch_results == 1)\n",
    "P_dinner_T = jnp.mean(dinner_results == 1)\n",
    "\n",
    "lunch_T_mask = (lunch_results == 1)\n",
    "dinner_T_mask = (dinner_results == 1)\n",
    "\n",
    "P_dinner_T_given_lunch_T = jnp.sum((lunch_T_mask) & (dinner_T_mask)) / jnp.sum(lunch_T_mask)\n",
    "P_lunch_T_given_dinner_T = jnp.sum((lunch_T_mask) & (dinner_T_mask)) / jnp.sum(dinner_T_mask)\n",
    "\n",
    "# Verify Bayes' rule\n",
    "bayes_left = float(P_lunch_T_given_dinner_T)\n",
    "bayes_right = float((P_dinner_T_given_lunch_T * P_lunch_T) / P_dinner_T)\n",
    "\n",
    "print(f\"Left side:  {bayes_left:.4f}\")\n",
    "print(f\"Right side: {bayes_right:.4f}\")\n",
    "print(f\"Difference: {abs(bayes_left - bayes_right):.4f}\")\n",
    "print(\"\\nâœ¨ They match! Bayes' rule verified!\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ“ What You've Learned\n",
    "\n",
    "Congratulations! You now understand:\n",
    "\n",
    "âœ… **Conditional probability**: P(A|B) restricts to outcomes where B happened  \n",
    "âœ… **Three methods**: Filtering, ChoiceMap, and formulas all agree  \n",
    "âœ… **Independence**: When P(A|B) = P(A)  \n",
    "âœ… **Dependence**: When learning B changes probability of A  \n",
    "âœ… **Bayes' rule**: Connects forward and reverse conditioning  \n",
    "\n",
    "**Key insight:**\n",
    "> *Conditioning is like restricting the outcome space. We cross out impossible outcomes and recalculate probabilities!*\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸš€ Next Steps\n",
    "\n",
    "Ready to dive deeper?\n",
    "- **`bayesian_learning.ipynb`**: Update beliefs with evidence (Bayes' theorem in action!)\n",
    "- **Tutorial 1, Chapter 5**: The Taxicab Problem\n",
    "- **GenJAX Tutorial Chapter 5**: Inference with importance sampling\n",
    "\n",
    "---\n",
    "\n",
    "**Questions?** Try different slider combinations to build intuition. The best way to understand conditioning is to *see* how probabilities change! ðŸŽ®"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}