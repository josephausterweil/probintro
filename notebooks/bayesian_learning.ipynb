{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Learning: Updating Beliefs with Evidence\n",
    "\n",
    "**How do beliefs change when you learn something new?**\n",
    "\n",
    "This notebook explores Bayes' theorem through interactive examples!\n",
    "\n",
    "**You'll discover:**\n",
    "- üß† How to update beliefs with evidence\n",
    "- üöï The famous Taxicab Problem\n",
    "- üìä Why base rates matter SO MUCH\n",
    "- üéÆ Interactive belief updating\n",
    "\n",
    "**Prepare for some surprising results!** ü§Ø\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## üöÄ Setup\n\nLet's get everything ready!\n\n**Note**: After running the installation cell below, you may need to restart the runtime (Runtime ‚Üí Restart runtime) before proceeding with the rest of the notebook."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install genjax ipywidgets matplotlib seaborn -q\n",
    "\n",
    "print(\"‚úÖ Installation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import jax\nimport jax.numpy as jnp\nfrom genjax import gen, flip, ChoiceMap\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport ipywidgets as widgets\nfrom IPython.display import display, clear_output\nimport numpy as np\n\njax.config.update('jax_enable_x64', True)\nsns.set_style(\"whitegrid\")\n\nprint(\"‚úÖ Ready to learn Bayesian inference!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöï The Taxicab Problem\n",
    "\n",
    "**The Story**:\n",
    "\n",
    "Chibany witnesses a hit-and-run accident at night. He says the taxi was **blue**.\n",
    "\n",
    "**What we know**:\n",
    "- 85% of taxis are **green**, 15% are **blue**\n",
    "- Chibany identifies colors correctly 80% of the time\n",
    "\n",
    "**The Question**: What's the probability it was actually a blue taxi?\n",
    "\n",
    "**Your intuition**: Before we calculate, what do YOU think?\n",
    "- 80% (matching Chibany's accuracy)?\n",
    "- 15% (matching the base rate)?\n",
    "- Something else?\n",
    "\n",
    "Let's find out! üîç"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Method 1: Simulation\n",
    "\n",
    "Let's simulate thousands of scenarios and count!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "@gen\ndef taxicab_scenario(base_rate_blue=0.15, accuracy=0.80):\n    \"\"\"\n    Simulate one taxicab scenario.\n    \n    Args:\n        base_rate_blue: P(taxi is blue)\n        accuracy: P(identifies correctly)\n    \n    Returns:\n        True if taxi is blue, False if green\n    \"\"\"\n    # True color\n    is_blue = flip(base_rate_blue) @ \"is_blue\"\n    \n    # What Chibany says depends on true color\n    if is_blue:\n        says_blue = flip(accuracy) @ \"says_blue\"  # Correct 80%\n    else:\n        says_blue = flip(1 - accuracy) @ \"says_blue\"  # Mistake 20%\n    \n    return is_blue\n\n# Simulate 100,000 scenarios\nn_sims = 100000\nkey = jax.random.key(42)\nkeys = jax.random.split(key, n_sims)\n\ndef run_scenario(k):\n    trace = taxicab_scenario.simulate(k, (0.15, 0.80))\n    choices = trace.get_choices()\n    return (int(choices['is_blue']), int(choices['says_blue']))\n\nresults = jax.vmap(run_scenario)(keys)\nis_blue_results, says_blue_results = results\n\n# Filter: Keep only cases where Chibany says \"blue\"\nsays_blue_mask = (says_blue_results == 1)\nn_says_blue = jnp.sum(says_blue_mask)\n\n# Among those, count actually blue\nactually_blue_and_says_blue = jnp.logical_and(is_blue_results == 1, says_blue_results == 1)\nn_actually_blue = jnp.sum(actually_blue_and_says_blue)\n\n# Calculate posterior\nprob_blue_given_says_blue = n_actually_blue / n_says_blue\n\nprint(\"üöï Taxicab Problem: Simulation Results\")\nprint(\"=\" * 60)\nprint(f\"Total scenarios: {n_sims:,}\")\nprint(f\"Chibany says 'blue': {int(n_says_blue):,} times\")\nprint(f\"Actually blue: {int(n_actually_blue):,} times\")\nprint(\"\\n\" + \"=\" * 60)\nprint(f\"P(Blue | Says Blue) = {prob_blue_given_says_blue:.4f}\")\nprint(\"=\" * 60)\nprint(\"\\nü§î Surprised? Only ~41%!\")\nprint(\"   Even though Chibany is 80% accurate!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßÆ Method 2: Bayes' Theorem\n",
    "\n",
    "Let's verify with the formula:\n",
    "\n",
    "$$P(\\text{Blue} \\mid \\text{Says Blue}) = \\frac{P(\\text{Says Blue} \\mid \\text{Blue}) \\cdot P(\\text{Blue})}{P(\\text{Says Blue})}$$\n",
    "\n",
    "Breaking it down step by step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prior probabilities\n",
    "P_blue = 0.15\n",
    "P_green = 0.85\n",
    "\n",
    "# Likelihoods\n",
    "P_says_blue_given_blue = 0.80  # Correct identification\n",
    "P_says_blue_given_green = 0.20  # Mistake\n",
    "\n",
    "# Evidence (total probability of saying \"blue\")\n",
    "P_says_blue = (P_blue * P_says_blue_given_blue + \n",
    "               P_green * P_says_blue_given_green)\n",
    "\n",
    "# Posterior (Bayes' theorem)\n",
    "P_blue_given_says_blue = (P_says_blue_given_blue * P_blue) / P_says_blue\n",
    "\n",
    "print(\"üßÆ Bayes' Theorem Calculation\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Step 1: Prior\")\n",
    "print(f\"   P(Blue) = {P_blue}  (base rate)\")\n",
    "print(f\"   P(Green) = {P_green}\")\n",
    "print(\"\\nStep 2: Likelihood\")\n",
    "print(f\"   P(Says Blue | Blue) = {P_says_blue_given_blue}  (accuracy)\")\n",
    "print(f\"   P(Says Blue | Green) = {P_says_blue_given_green}  (mistake rate)\")\n",
    "print(\"\\nStep 3: Evidence\")\n",
    "print(f\"   P(Says Blue) = {P_blue} √ó {P_says_blue_given_blue} + {P_green} √ó {P_says_blue_given_green}\")\n",
    "print(f\"                = {P_blue * P_says_blue_given_blue} + {P_green * P_says_blue_given_green}\")\n",
    "print(f\"                = {P_says_blue}\")\n",
    "print(\"\\nStep 4: Posterior (Bayes' Theorem)\")\n",
    "print(f\"   P(Blue | Says Blue) = ({P_says_blue_given_blue} √ó {P_blue}) / {P_says_blue}\")\n",
    "print(f\"                       = {P_says_blue_given_blue * P_blue} / {P_says_blue}\")\n",
    "print(f\"                       = {P_blue_given_says_blue:.4f}\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚ú® Matches simulation! Math works!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° Why So Low?\n",
    "\n",
    "**The insight**: Even with 80% accuracy, there are **more false positives than true positives**!\n",
    "\n",
    "Let's break it down with numbers (out of 100 taxis):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imagine 100 taxis\n",
    "total_taxis = 100\n",
    "\n",
    "# True colors\n",
    "n_blue = int(total_taxis * 0.15)  # 15 blue\n",
    "n_green = int(total_taxis * 0.85)  # 85 green\n",
    "\n",
    "# What Chibany identifies\n",
    "blue_identified_correctly = n_blue * 0.80  # 12\n",
    "green_misidentified_as_blue = n_green * 0.20  # 17\n",
    "\n",
    "total_says_blue = blue_identified_correctly + green_misidentified_as_blue\n",
    "\n",
    "# Visualize\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# True distribution\n",
    "ax1.bar(['Blue Taxis', 'Green Taxis'], [n_blue, n_green], \n",
    "        color=['#3498db', '#2ecc71'], alpha=0.7, edgecolor='black')\n",
    "ax1.set_ylabel('Count (out of 100)', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('TRUE Distribution', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylim([0, 100])\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for i, v in enumerate([n_blue, n_green]):\n",
    "    ax1.text(i, v + 2, str(v), ha='center', fontsize=14, fontweight='bold')\n",
    "\n",
    "# What Chibany says \"blue\"\n",
    "categories = ['True Positives\\n(Actually Blue)', 'False Positives\\n(Actually Green)']\n",
    "counts = [blue_identified_correctly, green_misidentified_as_blue]\n",
    "colors_bar = ['#3498db', '#e74c3c']\n",
    "\n",
    "bars = ax2.bar(categories, counts, color=colors_bar, alpha=0.7, edgecolor='black')\n",
    "ax2.set_ylabel('Count', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('When Chibany Says \"Blue\"', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylim([0, max(counts) * 1.3])\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "            f'{height:.0f}',\n",
    "            ha='center', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üí° The Key Insight:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Blue taxis correctly identified: {blue_identified_correctly:.0f}\")\n",
    "print(f\"Green taxis misidentified: {green_misidentified_as_blue:.0f}\")\n",
    "print(f\"\\nTotal 'says blue': {total_says_blue:.0f}\")\n",
    "print(f\"\\nProbability actually blue: {blue_identified_correctly}/{total_says_blue:.0f} ‚âà {blue_identified_correctly/total_says_blue:.2%}\")\n",
    "print(\"\\nüéØ MORE false positives than true positives!\")\n",
    "print(\"   This is why the probability is only ~41%!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéÆ Interactive Exploration!\n",
    "\n",
    "**Now it's your turn!** Explore how changing parameters affects the posterior.\n",
    "\n",
    "**Try these scenarios:**\n",
    "1. **Equal taxis**: Base rate = 0.50 ‚Üí What happens?\n",
    "2. **Mostly blue**: Base rate = 0.85 ‚Üí Now what?\n",
    "3. **Perfect witness**: Accuracy = 1.00 ‚Üí As expected?\n",
    "4. **Worse witness**: Accuracy = 0.60 ‚Üí Still useful?\n",
    "\n",
    "Watch how the **base rate** and **accuracy** interact!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive controls\n",
    "base_rate_slider = widgets.FloatSlider(\n",
    "    value=0.15, min=0.01, max=0.99, step=0.01,\n",
    "    description='P(Blue):',\n",
    "    style={'description_width': '120px'}\n",
    ")\n",
    "\n",
    "accuracy_slider = widgets.FloatSlider(\n",
    "    value=0.80, min=0.50, max=1.00, step=0.01,\n",
    "    description='Accuracy:',\n",
    "    style={'description_width': '120px'}\n",
    ")\n",
    "\n",
    "output_widget = widgets.Output()\n",
    "\n",
    "def explore_bayes(base_rate_blue, accuracy):\n",
    "    \"\"\"Explore Bayesian updating with different parameters.\"\"\"\n",
    "    with output_widget:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        # Calculate using Bayes' theorem\n",
    "        P_blue = base_rate_blue\n",
    "        P_green = 1 - base_rate_blue\n",
    "        P_says_blue_given_blue = accuracy\n",
    "        P_says_blue_given_green = 1 - accuracy\n",
    "        \n",
    "        P_says_blue = (P_blue * P_says_blue_given_blue + \n",
    "                      P_green * P_says_blue_given_green)\n",
    "        \n",
    "        P_blue_given_says_blue = (P_says_blue_given_blue * P_blue) / P_says_blue\n",
    "        \n",
    "        # Simulate to verify\n",
    "        n_sims = 10000\n",
    "        key = jax.random.key(42)\n",
    "        keys = jax.random.split(key, n_sims)\n",
    "        \n",
    "        results = jax.vmap(lambda k: run_scenario(k))(keys)\n",
    "        \n",
    "        def run_scenario(k):\n",
    "            trace = taxicab_scenario.simulate(k, (base_rate_blue, accuracy))\n",
    "            choices = trace.get_choices()\n",
    "            return (int(choices['is_blue']), int(choices['says_blue']))\n",
    "        \n",
    "        results = jax.vmap(run_scenario)(keys)\n",
    "        is_blue_sims, says_blue_sims = results\n",
    "        \n",
    "        says_blue_mask = (says_blue_sims == 1)\n",
    "        both_mask = jnp.logical_and(is_blue_sims == 1, says_blue_sims == 1)\n",
    "        P_blue_given_says_blue_sim = jnp.sum(both_mask) / jnp.sum(says_blue_mask)\n",
    "        \n",
    "        # Create visualization\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        \n",
    "        # Prior vs Posterior\n",
    "        categories = ['Prior\\nP(Blue)', 'Posterior\\nP(Blue|Says Blue)']\n",
    "        probs = [P_blue, P_blue_given_says_blue]\n",
    "        colors_comp = ['#95a5a6', '#3498db']\n",
    "        \n",
    "        bars1 = ax1.bar(categories, probs, color=colors_comp, alpha=0.7, edgecolor='black')\n",
    "        ax1.set_ylabel('Probability', fontsize=12, fontweight='bold')\n",
    "        ax1.set_title('Prior vs Posterior', fontsize=13, fontweight='bold')\n",
    "        ax1.set_ylim([0, 1])\n",
    "        ax1.grid(axis='y', alpha=0.3)\n",
    "        ax1.axhline(y=0.5, color='red', linestyle='--', alpha=0.5, label='50%')\n",
    "        ax1.legend()\n",
    "        \n",
    "        for bar in bars1:\n",
    "            height = bar.get_height()\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "                    f'{height:.3f}',\n",
    "                    ha='center', fontsize=12, fontweight='bold')\n",
    "        \n",
    "        # Belief update arrow\n",
    "        change = P_blue_given_says_blue - P_blue\n",
    "        arrow_color = '#2ecc71' if change > 0 else '#e74c3c'\n",
    "        ax1.annotate('', xy=(1, P_blue_given_says_blue), xytext=(0, P_blue),\n",
    "                    arrowprops=dict(arrowstyle='->', lw=2, color=arrow_color))\n",
    "        \n",
    "        # Break down of \"says blue\"\n",
    "        true_pos = P_blue * P_says_blue_given_blue\n",
    "        false_pos = P_green * P_says_blue_given_green\n",
    "        \n",
    "        labels_pie = ['True Positives\\n(Blue ‚Üí Says Blue)', \n",
    "                     'False Positives\\n(Green ‚Üí Says Blue)']\n",
    "        sizes = [true_pos, false_pos]\n",
    "        colors_pie = ['#3498db', '#e74c3c']\n",
    "        explode = (0.05, 0.05)\n",
    "        \n",
    "        wedges, texts, autotexts = ax2.pie(sizes, labels=labels_pie, autopct='%1.1f%%',\n",
    "                                           colors=colors_pie, explode=explode,\n",
    "                                           shadow=True, startangle=90)\n",
    "        for autotext in autotexts:\n",
    "            autotext.set_color('white')\n",
    "            autotext.set_fontsize(11)\n",
    "            autotext.set_fontweight('bold')\n",
    "        ax2.set_title('Breakdown of \"Says Blue\"', fontsize=13, fontweight='bold')\n",
    "        \n",
    "        # Comparison chart\n",
    "        comparison_data = {\n",
    "            'Prior': P_blue,\n",
    "            'Likelihood\\n(Accuracy)': P_says_blue_given_blue,\n",
    "            'Posterior': P_blue_given_says_blue\n",
    "        }\n",
    "        \n",
    "        bars3 = ax3.bar(comparison_data.keys(), comparison_data.values(),\n",
    "                       color=['#95a5a6', '#f39c12', '#3498db'],\n",
    "                       alpha=0.7, edgecolor='black')\n",
    "        ax3.set_ylabel('Probability', fontsize=12, fontweight='bold')\n",
    "        ax3.set_title('Three Key Probabilities', fontsize=13, fontweight='bold')\n",
    "        ax3.set_ylim([0, 1])\n",
    "        ax3.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        for bar in bars3:\n",
    "            height = bar.get_height()\n",
    "            ax3.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "                    f'{height:.3f}',\n",
    "                    ha='center', fontsize=11, fontweight='bold')\n",
    "        \n",
    "        # Theory vs Simulation\n",
    "        comparison_vals = [P_blue_given_says_blue, float(P_blue_given_says_blue_sim)]\n",
    "        comparison_labels = ['Theory\\n(Bayes)', 'Simulation\\n(10k runs)']\n",
    "        \n",
    "        bars4 = ax4.bar(comparison_labels, comparison_vals,\n",
    "                       color=['#9b59b6', '#1abc9c'],\n",
    "                       alpha=0.7, edgecolor='black')\n",
    "        ax4.set_ylabel('P(Blue | Says Blue)', fontsize=12, fontweight='bold')\n",
    "        ax4.set_title('Verification: Theory vs Simulation', fontsize=13, fontweight='bold')\n",
    "        ax4.set_ylim([0, 1])\n",
    "        ax4.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        for bar in bars4:\n",
    "            height = bar.get_height()\n",
    "            ax4.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "                    f'{height:.4f}',\n",
    "                    ha='center', fontsize=11, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"üìä Bayesian Update Summary\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Base rate (prior): P(Blue) = {P_blue:.3f}\")\n",
    "        print(f\"Accuracy: {accuracy:.3f}\")\n",
    "        print(f\"\\nEvidence: P(Says Blue) = {P_says_blue:.3f}\")\n",
    "        print(f\"  - True positives: {true_pos:.3f}\")\n",
    "        print(f\"  - False positives: {false_pos:.3f}\")\n",
    "        print(f\"\\nPosterior: P(Blue | Says Blue) = {P_blue_given_says_blue:.4f}\")\n",
    "        print(f\"Simulation: {float(P_blue_given_says_blue_sim):.4f}\")\n",
    "        print(f\"\\nBelief change: {P_blue:.3f} ‚Üí {P_blue_given_says_blue:.3f}\")\n",
    "        print(f\"Œî = {change:+.3f} ({change/P_blue*100:+.1f}%)\")\n",
    "        \n",
    "        # Interpretation\n",
    "        if abs(P_blue_given_says_blue - P_blue) < 0.01:\n",
    "            print(\"\\nüí° Evidence barely changed beliefs!\")\n",
    "        elif P_blue_given_says_blue > 0.5:\n",
    "            print(\"\\n‚úÖ Posterior > 50%: More likely blue than green!\")\n",
    "        else:\n",
    "            print(\"\\n‚ö†Ô∏è Posterior < 50%: Still more likely green!\")\n",
    "        \n",
    "        if false_pos > true_pos:\n",
    "            print(\"   üî¥ More false positives than true positives!\")\n",
    "            print(\"   This is why base rates matter SO MUCH.\")\n",
    "\n",
    "# Create interactive widget\n",
    "interactive_bayes = widgets.interactive(\n",
    "    explore_bayes,\n",
    "    base_rate_blue=base_rate_slider,\n",
    "    accuracy=accuracy_slider\n",
    ")\n",
    "\n",
    "display(interactive_bayes)\n",
    "display(output_widget)\n",
    "\n",
    "# Run initial\n",
    "explore_bayes(0.15, 0.80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Exercise: Medical Testing\n",
    "\n",
    "**Scenario**: A disease affects 1% of the population. A test is 99% accurate.\n",
    "\n",
    "**You test positive**. What's the probability you have the disease?\n",
    "\n",
    "Use the tools above to calculate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medical test scenario\n",
    "prevalence = 0.01  # 1% have disease\n",
    "test_accuracy = 0.99  # 99% accurate\n",
    "\n",
    "# TODO: Calculate P(Disease | Positive Test)\n",
    "# Hint: Use Bayes' theorem like the taxicab problem!\n",
    "\n",
    "# P_disease = ...\n",
    "# P_positive_given_disease = ...\n",
    "# P_positive_given_healthy = ...\n",
    "# P_positive = ...\n",
    "# P_disease_given_positive = ...\n",
    "\n",
    "# print(f\"P(Disease | Positive) = {P_disease_given_positive:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>üí° Click to see solution</b></summary>\n",
    "\n",
    "```python\n",
    "P_disease = 0.01\n",
    "P_healthy = 0.99\n",
    "P_positive_given_disease = 0.99  # True positive rate\n",
    "P_positive_given_healthy = 0.01  # False positive rate (1 - accuracy)\n",
    "\n",
    "# Total probability of testing positive\n",
    "P_positive = (P_disease * P_positive_given_disease + \n",
    "              P_healthy * P_positive_given_healthy)\n",
    "\n",
    "# Bayes' theorem\n",
    "P_disease_given_positive = (P_positive_given_disease * P_disease) / P_positive\n",
    "\n",
    "print(f\"P(Disease | Positive) = {P_disease_given_positive:.4f}\")\n",
    "print(f\"\\nSurprising result: Only ~50%!\")\n",
    "print(f\"Even with 99% accurate test!\")\n",
    "print(f\"\\nWhy? The disease is so rare (1%) that:\")\n",
    "print(f\"  True positives: {P_disease * P_positive_given_disease:.4f}\")\n",
    "print(f\"  False positives: {P_healthy * P_positive_given_healthy:.4f}\")\n",
    "print(f\"\\nAlmost equal amounts of true and false positives!\")\n",
    "```\n",
    "\n",
    "**The lesson**: Base rates dominate! A 99% accurate test on a 1% disease gives 50/50 odds.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì What You've Learned\n",
    "\n",
    "Congratulations! You now understand:\n",
    "\n",
    "‚úÖ **Bayes' theorem**: How to update beliefs with evidence  \n",
    "‚úÖ **Base rate importance**: Why prior probabilities matter enormously  \n",
    "‚úÖ **False positives**: How they can outnumber true positives  \n",
    "‚úÖ **Posterior probability**: Combining prior beliefs with new evidence  \n",
    "‚úÖ **Real-world applications**: Medical tests, witness testimony, and more  \n",
    "\n",
    "**The KEY insight:**\n",
    "> *Accuracy isn't everything! Base rates (how common something is) dramatically affect posterior probabilities. This is why rare diseases remain unlikely even after positive tests, and why common things stay common even with imperfect evidence.*\n",
    "\n",
    "**Why this matters:**\n",
    "- Medical testing: Don't panic from one positive result\n",
    "- Justice: Witness testimony needs context\n",
    "- Machine learning: Class imbalance affects predictions\n",
    "- Daily life: Common explanations are usually correct\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "Ready to go deeper?\n",
    "- **Tutorial 2**: Continuous distributions and Gaussian processes\n",
    "- **GenJAX Tutorial**: Build sophisticated probabilistic models\n",
    "- **Practice**: Find real-world scenarios to apply Bayes' theorem!\n",
    "\n",
    "---\n",
    "\n",
    "**Remember**: Your intuition about probabilities is often wrong. Trust the math, run the simulations, and always consider base rates! üéØ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}